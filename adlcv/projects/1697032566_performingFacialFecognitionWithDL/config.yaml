pretrain_model_eval: False  # or True, if you plan to use it

model:
  use_pretained_weights: True
  name: 'ResNet50V2'
  input_shape: [128, 128, 3]
  initial_learning_rate: 0.001
  decay_steps: 100
  decay_rate: 0.96
  dense_units: 512
  dropout_rate: 0.5
  additional_metrics: ['Precision', 'Recall', 'AUC', 'F1Score']

augmentation:
  rotation_range: 5  # degrees, ensure it's <= 360
  width_shift_range: 0.1  # fraction, ensure it's <= 1.0
  height_shift_range: 0.1  # fraction, ensure it's <= 1.0
  horizontal_flip: true
  vertical_flip: false
  zoom_range: 0.2  # fraction, ensure it's <= 1.0
  brightness_range: 0.8 # adjust as needed
  # contrast_range: 0.1 # adjust as needed
  # saturation_range: 0.1
  # hue_range: 0.05
  # gaussian_blur: 0.5
  # shear_range: 0.2
  # cutout_size: [10, 10]

data:
  pre_split: True  # Set to False if using a single directory
  dataset_path: 'dataset'  # Used if pre_split is False
  dataset_dir: 'att_faces'  # Used if pre_split is True
  train_dir: 'train_dataset'
  test_dir: 'test_dataset'
  validation_dir: 'validation_dataset'
  batch_size: 32
  target_size: [128, 128]
  preprocessing_function: 'resnet_preprocess'

tuning:
  perform_tuning: False  # Set to false to skip hyperparameter tuning

training:
  initial_epochs: 2
  fine_tune_epochs: 2
  fine_tune_learning_rate: 1e-5  # Lower learning rate for fine-tuning
  patience: 5
  target_accuracy: 0.99 
  find_lr: False
  model_checkpoint_path: 'checkpoint.h5.keras'

tuner:
  max_trials: 5
  executions_per_trial: 1

# Hyperparameters for pre-trained models
#
hyperparameters:
  learning_rate_pretrained:
    min: 1e-5
    max: 1e-3
    default: 1e-4
  learning_rate:
    min: 1e-4
    max: 1e-2
    default: 1e-3
  dense_units:
    min: 128
    max: 1024
    step: 128
    default: 128
  dropout_rate:
    min: 0.0
    max: 0.7
    step: 0.1
    default: 0.1
  unfreeze_layers:
    min: 0
    max: 100
    step: 10
    default: 0
  optimizer:
    choices: ['adam', 'sgd']
    default: 'adam'

  # Hyperparameters for scratch models
  #
  dense_units_scratch:
    min: 64
    max: 512
    step: 64
    default: 128
  dropout_rate_scratch:
    min: 0.1
    max: 0.5
    step: 0.1
    default: 0.3
  learning_rate_scratch:
    min: 1e-5
    max: 1e-2
    default: 1e-3
  optimizer_scratch:
    choices: ['adam', 'sgd']
    default: 'adam'

reduce_lr_on_plateau:
  monitor: 'val_loss' # Metric to monitor
  factor: 0.2         # Factor by which the learning rate will be reduced
  patience: 10        # Number of epochs with no improvement after which learning rate will be reduced
  min_lr: 1e-6        # Lower bound on the learning rate
  verbose: 1          # Verbosity mode, 0 or 1

visualization:
  figure_size: [12, 4]
  history_plot_path: 'history_plot.png'

gpu:
  memory_growth: true
  allow_growth: true

# ARCHITECTURES = {
#   'ResNet50V2': ResNet50V2,
#   'VGG16': VGG16,
#   'InceptionV3': InceptionV3,
#   'MobileNetV2': MobileNetV2,
#   'EfficientNetB0': EfficientNetB0
# }
#
# ARCHITECTURE_INPUT_SHAPES = {
#   'ResNet50V2': (128, 128, 3),
#   'VGG16': (224, 224, 3),
#   'InceptionV3': (299, 299, 3),
#   'MobileNetV2': (224, 224, 3),
#   'EfficientNetB0': (224, 224, 3)
# }
#
# PREPROCESSING_FUNCTIONS = {
#   'ResNet50V2': resnet_preprocess,
#   'VGG16': vgg_preprocess,
#   'InceptionV3': inception_preprocess,
#   'MobileNetV2': mobilenet_preprocess,
#   'EfficientNetB0': efficientnet_preprocess
# }
