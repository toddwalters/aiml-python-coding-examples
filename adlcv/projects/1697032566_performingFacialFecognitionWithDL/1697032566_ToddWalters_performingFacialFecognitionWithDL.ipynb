{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toddwalters/aiml-python-coding-examples/blob/feature%2Fvggface-ptm/adlcv/projects/1697032566_performingFacialFecognitionWithDL/1697032566_ToddWalters_performingFacialFecognitionWithDL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNzx3hSM0xSy",
        "outputId": "8b480fe7-a7ca-4c7a-9862-f47acba20854"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TDhL5oG0xSy"
      },
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- 1. [**Performing Facial Recognition with Deep Learning**](#toc1_)    \n",
        "  - 1.1. [**Project Context**](#toc1_1_)    \n",
        "  - 1.2. [**Project Objectives**](#toc1_2_)    \n",
        "  - 1.3. [**Project Dataset Description**](#toc1_3_)    \n",
        "  - 1.4. [**Project Analysis Steps To Perform**](#toc1_4_)    \n",
        "    - 1.4.1. [**Preliminary analysis**](#toc1_4_1_)    \n",
        "      - 1.4.1.1. [**Import Modules and Set Default Environment Variables**](#toc1_4_1_1_)    \n",
        "      - 1.4.1.2. [**Look for corrupt files [Optional]**    ](#toc1_4_1_2_)    \n",
        "      - 1.4.1.3. [**Rename Files [Optional]** ](#toc1_4_1_3_)    \n",
        "      - 1.4.1.4. [**Convert File Type [Optional]** ](#toc1_4_1_4_)    \n",
        "      - 1.4.1.5. [**Plot Sample Images**](#toc1_4_1_5_)    \n",
        "      - 1.4.1.6. [**Create a validation framework and split the data into train, test, and validation datasets**](#toc1_4_1_6_)    \n",
        "      - 1.4.1.7. [**Perform necessary transformations to prepare the data for input to the CNN model**](#toc1_4_1_7_)    \n",
        "      - 1.4.1.8. [**Thing G**](#toc1_4_1_8_)    \n",
        "      - 1.4.1.9. [**Thing H**](#toc1_4_1_9_)    \n",
        "      - 1.4.1.10. [**Thing I**](#toc1_4_1_10_)    \n",
        "    - 1.4.2. [**Train Model with Augmentation**](#toc1_4_2_)    \n",
        "      - 1.4.2.1. [**Thing A**](#toc1_4_2_1_)    \n",
        "        - 1.4.2.1.1. [**Plot Hyperparameter Search Results**](#toc1_4_2_1_1_)    \n",
        "        - 1.4.2.1.2. [**Test Trained Model**](#toc1_4_2_1_2_)    \n",
        "        - 1.4.2.1.3. [**Thing A.B**](#toc1_4_2_1_3_)    \n",
        "        - 1.4.2.1.4. [**Thing A.C**](#toc1_4_2_1_4_)    \n",
        "        - 1.4.2.1.5. [**Thing A.D**](#toc1_4_2_1_5_)    \n",
        "    - 1.4.3. [**Part 3**](#toc1_4_3_)    \n",
        "      - 1.4.3.1. [**Thing A**](#toc1_4_3_1_)    \n",
        "      - 1.4.3.2. [**Thing B**](#toc1_4_3_2_)    \n",
        "        - 1.4.3.2.1. [**Thing B.A**](#toc1_4_3_2_1_)    \n",
        "        - 1.4.3.2.2. [**Thing B.A**](#toc1_4_3_2_2_)    \n",
        "        - 1.4.3.2.3. [**Thing B.C**](#toc1_4_3_2_3_)    \n",
        "        - 1.4.3.2.4. [**Thing B.D**](#toc1_4_3_2_4_)    \n",
        "      - 1.4.3.3. [**Thing C**](#toc1_4_3_3_)    \n",
        "      - 1.4.3.4. [**Thing D**](#toc1_4_3_4_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=true\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGCV1a3J0xSz"
      },
      "source": [
        "Table of Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMjKUf9f0xSz"
      },
      "source": [
        "-----\n",
        "\n",
        "# 1. <a id='toc1_'></a>[**Performing Facial Recognition with Deep Learning**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18hh_q6p0xSz"
      },
      "source": [
        "-----------------------------\n",
        "## 1.1. <a id='toc1_1_'></a>[**Project Context**](#toc0_)\n",
        "-----------------------------\n",
        "\n",
        "You are working for Face2Gene, an American AI company that has developed a\n",
        "healthcare app for doctors. The app utilizes deep learning algorithms to aid in diagnosing\n",
        "patients for genetic disorders and their variants. It converts patient photos into de-identified\n",
        "mathematical facial descriptors, which are then compared to syndrome-specific computational-\n",
        "based classifiers to determine similarity. The app provides a prioritized list of syndromes with\n",
        "similar morphology and suggests phenotypic traits and genes for feature annotation and\n",
        "syndrome prioritization.\n",
        "  \n",
        "Management has given priority to empowering and entrusting the in-house AI team. As a new\n",
        "member of the team, your task is to build a baseline model for facial recognition. The goal is to\n",
        "further enhance the app's existing features and add more value to the business based on this\n",
        "baseline model.\n",
        "\n",
        "-----------------------------\n",
        "## 1.2. <a id='toc1_2_'></a>[**Project Objectives**](#toc0_)\n",
        "-----------------------------\n",
        "\n",
        "Create a facial recognition tool using a relevant deep learning algorithm, leveraging\n",
        "the provided resources.\n",
        "\n",
        "-----------------------------\n",
        "## 1.3. <a id='toc1_3_'></a>[**Project Dataset Description**](#toc0_)\n",
        "-----------------------------\n",
        "\n",
        "The ORL Database of Faces consists of 400 images from 40 different subjects.\n",
        "The images were captured at different times, under varying lighting conditions, with different\n",
        "facial expressions (open, closed eyes, smiling, not smiling), and with or without glasses. All the\n",
        "images have a dark homogeneous background, and the subjects are positioned upright and\n",
        "frontal with some tolerance for side movement. Each image has a size of 92x112 pixels and 256\n",
        "grey levels per pixel.\n",
        "  \n",
        "Data can be downloaded from the following link:\n",
        "https://www.kaggle.com/datasets/kasikrit/att-database-of-faces\n",
        "\n",
        "-----------------------------------\n",
        "## 1.4. <a id='toc1_4_'></a>[**Project Analysis Steps To Perform**](#toc0_)\n",
        "-----------------------------------\n",
        "\n",
        "The following steps will guide you in building the model.\n",
        "  \n",
        "1. Import the relevant packages and collect all the necessary dependencies.\n",
        "  \n",
        "2. Upload and import the data.\n",
        "  \n",
        "3. View a few images to get a sense of the data.\n",
        "  \n",
        "4. Create a validation framework and split the data into train, test, and validation datasets.\n",
        "  \n",
        "5. Perform necessary transformations to prepare the data for input to the CNN model.\n",
        "  \n",
        "6. Build a CNN model with three main layers: a convolutional layer, a pooling layer, and a fully\n",
        "connected layer. You can also consider utilizing state-of-the-art architectures using transfer\n",
        "learning.\n",
        "  \n",
        "7. Train the model using the prepared data.\n",
        "  \n",
        "8. Plot the results to evaluate the model's performance.\n",
        "  \n",
        "9. Iterate on the model, making adjustments and improvements, until you achieve an accuracy\n",
        "above 90%.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJeVr2PQ0xSz"
      },
      "source": [
        "### 1.4.1. <a id='toc1_4_1_'></a>[**Preliminary analysis**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujTBGng50xSz"
      },
      "source": [
        "#### 1.4.1.1. <a id='toc1_4_1_1_'></a>[**Import Modules and Set Default Environment Variables**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXpfBpOC1MY_",
        "outputId": "f6e8575e-7671-4b66-e214-6d9349be8e53"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv keras_tuner keras_vggface\n",
        "# /usr/local/lib/python3.10/dist-packages/keras_vggface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHJGFTla0xSz",
        "outputId": "e9ed8166-a3c2-410d-9813-6d632ae6c1ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:09:15,946 - INFO - Logging level set to: DEBUG\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MF Running in local environment\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import traceback\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "from dotenv import load_dotenv\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications import (\n",
        "    EfficientNetB0,\n",
        "    InceptionV3,\n",
        "    MobileNetV2,\n",
        "    ResNet50V2,\n",
        "    VGG16\n",
        ")\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.callbacks import (\n",
        "    Callback,\n",
        "    EarlyStopping,\n",
        "    LambdaCallback,\n",
        "    LearningRateScheduler,\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization,\n",
        "    Conv2D,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    GlobalAveragePooling2D,\n",
        "    Input,\n",
        "    MaxPooling2D,\n",
        "    RandomRotation,\n",
        "    RandomFlip,\n",
        "    RandomZoom,\n",
        "    RandomContrast,\n",
        "    RandomBrightness,\n",
        "    RandomTranslation,\n",
        "    Rescaling\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC, Metric\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input as vggface_preprocess_input\n",
        "\n",
        "# Import Keras Tuner modules\n",
        "from keras_tuner import (\n",
        "    Hyperband,\n",
        "    HyperModel,\n",
        "    HyperParameters,\n",
        "    BayesianOptimization,\n",
        "    RandomSearch\n",
        ")\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('COLAB_DATASET_PATH')\n",
        "    print(\"MF Running in Colab environment\")\n",
        "except ModuleNotFoundError:\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
        "    print(\"MF Running in local environment\\n\")\n",
        "\n",
        "# Global logger\n",
        "frogger = logging.getLogger(__name__)\n",
        "\n",
        "def configure_logging(log_level=logging.DEBUG):\n",
        "    \"\"\"\n",
        "    Configures the logging level for the application.\n",
        "\n",
        "    Args:\n",
        "        log_level: The desired logging level (e.g., logging.DEBUG, logging.INFO, logging.ERROR).\n",
        "    \"\"\"\n",
        "    # Clear existing logging configuration\n",
        "    frogger.handlers = []\n",
        "\n",
        "    # Configure the new logging level\n",
        "    logging.basicConfig(\n",
        "        level=log_level,\n",
        "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "        handlers=[logging.StreamHandler()]\n",
        "    )\n",
        "    frogger.setLevel(log_level)\n",
        "    frogger.info(f\"Logging level set to: {logging.getLevelName(log_level)}\")\n",
        "\n",
        "# Set the logging level\n",
        "configure_logging(logging.DEBUG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wJnDWbu0xS0"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- This code block imports necessary libraries (`pandas`, `numpy`, `matplotlib`, and `seaborn`) and reads the three CSV files into pandas DataFrames. It then displays the first few rows of each dataset to give an initial view of the data.\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- Importing and examining the datasets is crucial as it allows us to understand the structure and content of our data. This step helps identify any immediate issues with data formatting or missing values and provides a foundation for all subsequent analyses.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDS5q-yo0xS0"
      },
      "source": [
        "#### 1.4.1.2. <a id='toc1_4_1_2_'></a>[**[OPTIONAL] Convert Grayscale2RGB or RGB2Grayscale**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z5ymF_720xS0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'DATASET_PATH' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 76\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[38;5;66;03m# Convert the image based on the specified mode\u001b[39;00m\n\u001b[1;32m     74\u001b[0m                 convert_image(file_path, mode)\n\u001b[0;32m---> 76\u001b[0m root_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATASET_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/att_faces_png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     77\u001b[0m frogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot_directory: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# process_images_in_directory(root_directory, mode='gray_to_rgb') #  gray_to_rgb or rgb_to_gray\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DATASET_PATH' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from dotenv import load_dotenv\n",
        "import logging\n",
        "\n",
        "def convert_image(image_path, mode):\n",
        "    \"\"\"\n",
        "    Converts an image from RGB to Grayscale or Grayscale to RGB and saves it.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the image file to convert.\n",
        "        mode: 'rgb_to_gray' to convert RGB to Grayscale or 'gray_to_rgb' to convert Grayscale to RGB.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Read the image using Pillow\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Convert Pillow image to NumPy array to check the original shape\n",
        "    img_np = np.array(img)\n",
        "    frogger.info(f\"Original Image shape: {img_np.shape}\")\n",
        "\n",
        "    if mode == 'rgb_to_gray':\n",
        "        # Check if the image is already grayscale\n",
        "        if len(img_np.shape) == 2:  # Grayscale images have only 2 dimensions\n",
        "            frogger.info(f\"{image_path} is already a grayscale image. No conversion needed.\")\n",
        "        else:\n",
        "            # Convert RGB to Grayscale using OpenCV\n",
        "            gray_img = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "            # Save the grayscale image using OpenCV\n",
        "            cv2.imwrite(image_path, gray_img)\n",
        "            # Reload the image after conversion to grayscale\n",
        "            img_new = np.array(Image.open(image_path))\n",
        "            frogger.info(f\"New Image shape after conversion to Grayscale: {img_new.shape}\")\n",
        "\n",
        "    elif mode == 'gray_to_rgb':\n",
        "        # If the image is grayscale, convert it to RGB using OpenCV\n",
        "        if len(img_np.shape) == 2:  # Grayscale images have only 2 dimensions\n",
        "            rgb_img = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
        "            # Save the RGB image using OpenCV\n",
        "            cv2.imwrite(image_path, rgb_img)\n",
        "\n",
        "            # Reload the image after conversion to RGB\n",
        "            img_new = np.array(Image.open(image_path))\n",
        "            frogger.info(f\"New Image shape after conversion to RGB: {img_new.shape}\")\n",
        "        else:\n",
        "            frogger.info(f\"{image_path} is already in RGB format.\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid mode. Use 'rgb_to_gray' or 'gray_to_rgb'.\")\n",
        "\n",
        "def process_images_in_directory(root_dir, mode='rgb_to_gray'):\n",
        "    \"\"\"\n",
        "    Recursively processes all images in the given directory and subdirectories,\n",
        "    converting them based on the provided mode (RGB to Grayscale or Grayscale to RGB).\n",
        "\n",
        "    Args:\n",
        "        root_dir: The root directory containing subdirectories with images.\n",
        "        mode: 'rgb_to_gray' or 'gray_to_rgb' to define the conversion type.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    for subdir, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            # Check if the file is an image (e.g., with jpg, png extension)\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                file_path = os.path.join(subdir, file)\n",
        "\n",
        "                # Convert the image based on the specified mode\n",
        "                convert_image(file_path, mode)\n",
        "\n",
        "root_directory = f'{DATASET_PATH}/att_faces_png'\n",
        "frogger.info(f'root_directory: {root_directory}')\n",
        "# process_images_in_directory(root_directory, mode='gray_to_rgb') #  gray_to_rgb or rgb_to_gray\n",
        "process_images_in_directory(root_directory, mode='rgb_to_gray') #  gray_to_rgb or rgb_to_gray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI66HQEZ0xS0"
      },
      "source": [
        "#### 1.4.1.2. <a id='toc1_4_1_2_'></a>[**[OPTIONAL] Analyze Example File Shape**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVkHCIxT0xS0",
        "outputId": "a0a59fec-91e7-4718-b8fb-15120585b310"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:09:22,157 - INFO - Image mode: L\n",
            "2024-10-25 19:09:22,157 - INFO - Width: 92, Height: 112\n",
            "2024-10-25 19:09:22,163 - INFO - Image array shape: (112, 92)\n",
            "2024-10-25 19:09:22,163 - INFO - The image has 1 channel (Grayscale).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "\n",
        "# Open an image file\n",
        "image_path = 'att_faces/s1/1.pgm'\n",
        "image = Image.open(f'{DATASET_PATH}/{image_path}')\n",
        "\n",
        "# Get dimensions\n",
        "width, height = image.size\n",
        "\n",
        "# Check the image mode\n",
        "mode = image.mode\n",
        "\n",
        "frogger.info(f\"Image mode: {mode}\")\n",
        "frogger.info(f\"Width: {width}, Height: {height}\")\n",
        "\n",
        "img_np = np.array(image)\n",
        "\n",
        "# Determine if the image is color or black and white\n",
        "if len(img_np.shape) == 2:\n",
        "    frogger.info(f\"Image array shape: {img_np.shape}\")\n",
        "    frogger.info(\"The image has 1 channel (Grayscale).\")\n",
        "elif len(img_np.shape) == 3:\n",
        "    channels = img_np.shape[2]\n",
        "    frogger.info(f\"Image array shape: {img_np.shape}\")\n",
        "    if channels == 3:\n",
        "        frogger.info(\"The image has 3 channels (RGB).\")\n",
        "    elif channels == 4:\n",
        "        frogger.info(\"The image has 4 channels (RGBA).\")\n",
        "    else:\n",
        "        frogger.info(f\"Unexpected number of channels: {channels}\")\n",
        "\n",
        "    # Check if all color channels are the same\n",
        "    if channels in [3, 4] and np.array_equal(img_np[:, :, 0], img_np[:, :, 1]) and np.array_equal(img_np[:, :, 1], img_np[:, :, 2]):\n",
        "        frogger.info(\"The color channels are all the same. The image is Grayscale.\")\n",
        "    else:\n",
        "        frogger.info(\"The image is Color.\")\n",
        "else:\n",
        "    frogger.info(\"Unexpected shape for the image.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0-lS2pA0xS0"
      },
      "source": [
        "#### 1.4.1.2. <a id='toc1_4_1_2_'></a>[**[OPTIONAL] Look for corrupt files**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdcqDzD90xS0"
      },
      "outputs": [],
      "source": [
        "def verify_images(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif', '.pgm', '.pnm', '.webp')):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    img = Image.open(file_path)\n",
        "                    img.verify()\n",
        "                except (IOError, SyntaxError) as e:\n",
        "                    print(f'Bad file: {file_path}')\n",
        "                    os.remove(file_path)\n",
        "                    print(f'Deleted bad file: {file_path}')\n",
        "\n",
        "# verify_images(f'{DATASET_PATH}/dataset_test')\n",
        "# verify_images(f'{DATASET_PATH}/structure_dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQspPGwW0xS0"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- This code examines the shape, structure, and quality of each dataset. It checks the number of rows and columns, data types of each column, presence of missing values, and existence of duplicate entries.\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- Understanding the dataset's structure and quality is crucial for data preprocessing and analysis. It helps identify potential issues like missing data or duplicates that need to be addressed before proceeding with the analysis.\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcM8jQui0xS0"
      },
      "source": [
        "#### 1.4.1.3. <a id='toc1_4_1_3_'></a>[**[OPTIONAL] Rename Files**](#toc0_)  [&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57_VZBuV0xS0"
      },
      "outputs": [],
      "source": [
        "def random_string(length):\n",
        "    \"\"\"Generate a random string of fixed length\"\"\"\n",
        "    letters = string.ascii_lowercase + string.digits\n",
        "    return ''.join(random.choice(letters) for i in range(length))\n",
        "\n",
        "def rename_files(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            # Generate a unique name\n",
        "            new_name = str(uuid.uuid4())\n",
        "\n",
        "            # Get the file extension\n",
        "            file_extension = os.path.splitext(filename)[1]\n",
        "\n",
        "            # Create the new filename\n",
        "            new_filename = f\"{new_name}.{file_extension}\"\n",
        "\n",
        "            # Full paths\n",
        "            old_file = os.path.join(root, filename)\n",
        "            new_file = os.path.join(root, new_filename)\n",
        "\n",
        "            # Rename the file\n",
        "            os.rename(old_file, new_file)\n",
        "            print(f\"Renamed: {filename} -> {new_filename}\")\n",
        "\n",
        "# Uncomment if you want to rename all of the files in the dataset\n",
        "# directories = [f'{DATASET_PATH}/structures_dataset', f'{DATASET_PATH}/dataset_test']\n",
        "# for start_directory in directories:\n",
        "#     rename_files(start_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi52fhlz0xS0"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VAT1mjE0xS0"
      },
      "source": [
        "#### 1.4.1.4. <a id='toc1_4_1_4_'></a>[**[OPTIONAL] Convert File Type**](#toc0_)  [&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Xrq_Z5y0xS1"
      },
      "outputs": [],
      "source": [
        "def convert_pgm_to_png(input_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for root, dirs, files in os.walk(input_dir):\n",
        "        # Create corresponding subdirectories in output_dir\n",
        "        rel_path = os.path.relpath(root, input_dir)\n",
        "        output_subdir = os.path.join(output_dir, rel_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith('.pgm'):\n",
        "                filepath = os.path.join(root, filename)\n",
        "                try:\n",
        "                    with Image.open(filepath) as img:\n",
        "                        img = img.convert('RGB')  # Convert to RGB\n",
        "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
        "                        output_path = os.path.join(output_subdir, new_filename)\n",
        "                        img.save(output_path, 'PNG')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error converting {filepath}: {e}\")\n",
        "                    print(traceback.format_exc())\n",
        "\n",
        "# Usage\n",
        "input_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/adlcv/projects/1697032566/att_faces/'  # Your current dataset path with PGM files\n",
        "output_dir = '/content/drive/MyDrive/Colab Notebooks/datasets/adlcv/projects/1697032566/att_faces_png'  # New dataset path for PNG files\n",
        "convert_pgm_to_png(input_dir, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkYOfann0xS1"
      },
      "source": [
        "#### 1.4.1.5. <a id='toc1_4_1_5_'></a>[**Plot Sample Images**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSARwxb50xS1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "import re\n",
        "\n",
        "def natural_sort_key(s):\n",
        "    \"\"\"Helper function to extract the numerical part from a class name for natural sorting.\"\"\"\n",
        "    return int(re.search(r'\\d+', s).group())\n",
        "\n",
        "def plot_sample_images_in_grid(dataset_path, grid_rows=8, grid_cols=5):\n",
        "    # Collect all classes sorted by natural order (numerical order based on 's1', 's2', ..., 's40')\n",
        "    classes = sorted([d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))], key=natural_sort_key)\n",
        "\n",
        "    # Prepare the figure with an 8x5 grid\n",
        "    fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(15, 10))\n",
        "\n",
        "    # Plot one image per class\n",
        "    for idx, class_name in enumerate(classes[:grid_rows * grid_cols]):\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        image_name = sorted([f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))])[0]  # Take the first image\n",
        "        image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        row, col = divmod(idx, grid_cols)  # Calculate row and column position\n",
        "        axes[row, col].imshow(img)\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "        # Set the class name (folder name) as the title for each image\n",
        "        axes[row, col].set_title(class_name, fontsize=10)\n",
        "\n",
        "    # Hide any unused subplots (if any)\n",
        "    for i in range(len(classes), grid_rows * grid_cols):\n",
        "        row, col = divmod(i, grid_cols)\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Mount Google Drive if using Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('COLAB_DATASET_PATH', default='/default/dataset/path')\n",
        "except ImportError:\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
        "\n",
        "plot_sample_images_in_grid(f'{DATASET_PATH}/att_faces/', grid_rows=8, grid_cols=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-Qx7LhY0xS1"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0novPZoy0xS1"
      },
      "source": [
        "#### 1.4.1.6. <a id='toc1_4_1_6_'></a>[**Create a validation framework and split the data into train, test, and validation datasets**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIZkZ0ev0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUT8XS3T0xS1"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebBb_dsK0xS1"
      },
      "source": [
        "#### 1.4.1.7. <a id='toc1_4_1_7_'></a>[**Perform necessary transformations to prepare the data for input to the CNN model**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haNHWZfO0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWseQuMy0xS1"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UlJ_oz80xS1"
      },
      "source": [
        "#### 1.4.1.8. <a id='toc1_4_1_8_'></a>[**Thing G**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tf45Vl8-0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAMAZifz0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNGw_RyQ0xS1"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCFDwlfU0xS1"
      },
      "source": [
        "#### 1.4.1.9. <a id='toc1_4_1_9_'></a>[**Thing H**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ff0JcTLz0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7ITWVux0xS1"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5J5F6B70xS1"
      },
      "source": [
        "#### 1.4.1.10. <a id='toc1_4_1_10_'></a>[**Thing I**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu2jeUmd0xS1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwEGsQmW0xS5"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IrrjtXu0xS5"
      },
      "source": [
        "### 1.4.2. <a id='toc1_4_2_'></a>[**Train Model with Augmentation**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRM6wiLz0xS5",
        "outputId": "a3ae68e6-f289-4c07-a964-689bad2ba268"
      },
      "outputs": [],
      "source": [
        "# !pip install python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gWR0cqqU0xS5"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import glob\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import traceback\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "from dotenv import load_dotenv\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.applications import (\n",
        "    EfficientNetB0,\n",
        "    InceptionV3,\n",
        "    MobileNetV2,\n",
        "    ResNet50V2,\n",
        "    VGG16\n",
        ")\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.callbacks import (\n",
        "    Callback,\n",
        "    EarlyStopping,\n",
        "    LambdaCallback,\n",
        "    LearningRateScheduler,\n",
        "    ModelCheckpoint,\n",
        "    ReduceLROnPlateau\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    BatchNormalization,\n",
        "    Conv2D,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    Flatten,\n",
        "    GlobalAveragePooling2D,\n",
        "    Input,\n",
        "    MaxPooling2D,\n",
        "    RandomRotation,\n",
        "    RandomFlip,\n",
        "    RandomZoom,\n",
        "    RandomContrast,\n",
        "    RandomTranslation,\n",
        "    Rescaling\n",
        ")\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC, Metric\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input as vggface_preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Import Keras Tuner modules\n",
        "from keras_tuner import (\n",
        "    Hyperband,\n",
        "    HyperModel,\n",
        "    HyperParameters,\n",
        "    BayesianOptimization,\n",
        "    RandomSearch\n",
        ")\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'  # Default setting\n",
        "\n",
        "class F1Score(Metric):\n",
        "    def __init__(self, name='f1_score', **kwargs):\n",
        "        super(F1Score, self).__init__(name=name, **kwargs)\n",
        "        self.precision = Precision(name='precision')\n",
        "        self.recall = Recall(name='recall')\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Update the precision and recall variables\n",
        "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
        "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "    @tf.function\n",
        "    def result(self):\n",
        "        # Compute the F1 score\n",
        "        precision = self.precision.result()\n",
        "        recall = self.recall.result()\n",
        "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "    @tf.function\n",
        "    def reset_states(self):\n",
        "        # Reset the state of the metrics\n",
        "        self.precision.reset_states()\n",
        "        self.recall.reset_states()\n",
        "\n",
        "# Define mappings for architectures and preprocessing functions\n",
        "ARCHITECTURES = {\n",
        "    'ResNet50V2': ResNet50V2,\n",
        "    'VGG16': VGG16,\n",
        "    'InceptionV3': InceptionV3,\n",
        "    'MobileNetV2': MobileNetV2,\n",
        "    'EfficientNetB0': EfficientNetB0,\n",
        "    'VGGFace': VGGFace\n",
        "}\n",
        "\n",
        "PREPROCESSING_FUNCTIONS = {\n",
        "    'resnet_preprocess': resnet_preprocess,\n",
        "    'vgg_preprocess': vgg_preprocess,\n",
        "    'inception_preprocess': inception_preprocess,\n",
        "    'mobilenet_preprocess': mobilenet_preprocess,\n",
        "    'efficientnet_preprocess': efficientnet_preprocess\n",
        "}\n",
        "\n",
        "# Define metrics mapping\n",
        "METRICS = {\n",
        "    'Precision': Precision(name='precision'),\n",
        "    'Recall': Recall(name='recall'),\n",
        "    'AUC': AUC(name='auc'),\n",
        "    'F1Score': F1Score(name='f1_score')\n",
        "}\n",
        "\n",
        "class AccuracyCallback(Callback):\n",
        "    def __init__(self, target_accuracy):\n",
        "        super().__init__()\n",
        "        self.target_accuracy = target_accuracy\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_accuracy') >= self.target_accuracy:\n",
        "            logger.info(f\"Reached {self.target_accuracy*100}% validation accuracy. Stopping training.\\n\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "class CustomValidationCallback(Callback):\n",
        "    def __init__(self, validation_data, validation_steps):\n",
        "        super().__init__()\n",
        "        self.validation_data = validation_data\n",
        "        self.validation_steps = validation_steps\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = 0\n",
        "        val_accuracy = 0\n",
        "        for x, y in self.validation_data.take(self.validation_steps):\n",
        "            val_metrics = self.model.test_on_batch(x, y)\n",
        "            val_loss += val_metrics[0]\n",
        "            val_accuracy += val_metrics[1]\n",
        "\n",
        "        val_loss /= self.validation_steps\n",
        "        val_accuracy /= self.validation_steps\n",
        "\n",
        "        logs['val_loss'] = val_loss\n",
        "        logs['val_accuracy'] = val_accuracy\n",
        "        logger.debug(f\"Epoch {epoch + 1} - Custom validation:\")\n",
        "        logger.debug(f\"Loss: {val_loss:.4f}\")\n",
        "        logger.debug(f\"Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "class DatasetLogger(Callback):\n",
        "    def __init__(self, train_dataset, val_dataset):\n",
        "        super().__init__()\n",
        "        self.train_dataset = train_dataset\n",
        "        self.val_dataset = val_dataset\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        logger.debug(f\"Epoch {epoch + 1} - Train samples: {tf.data.experimental.cardinality(self.train_dataset)}\")\n",
        "        logger.debug(f\"Epoch {epoch + 1} - Val samples: {tf.data.experimental.cardinality(self.val_dataset)}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs is not None:\n",
        "            logger.debug(f\"Epoch {epoch + 1} - Train accuracy: {logs.get('accuracy', 'N/A'):.4f}\")\n",
        "            logger.debug(f\"Epoch {epoch + 1} - Val accuracy: {logs.get('val_accuracy', 'N/A'):.4f}\")\n",
        "\n",
        "class DebugCallback(Callback):\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        logger.debug(f\"Starting epoch {epoch + 1}\\n\")\n",
        "\n",
        "    def on_batch_begin(self, batch, logs=None):\n",
        "        if batch % 100 == 0:\n",
        "            # logger.debug(f\"Starting batch {batch}\\n\")\n",
        "            pass\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logger.debug(f\"End of epoch {epoch + 1}\\n\")\n",
        "        if logs:\n",
        "            for key, value in logs.items():\n",
        "                logger.debug(f\"{key}: {value}\")\n",
        "        logger.debug(\"--------------------\\n\")\n",
        "\n",
        "class DataGenerator:\n",
        "    def __init__(self, config):\n",
        "        logger.debug(f\"DataGenerator initialization starting.\")\n",
        "        self.config = config\n",
        "        self.batch_size = config['data']['batch_size']\n",
        "        self.input_shape = tuple(config['data']['input_shape'])\n",
        "        self.target_size = tuple(config['data']['target_size'])\n",
        "        self.color_mode = config['data'].get('color_mode', 'rgb')\n",
        "        self.preprocessing_function_name = config['model']['preprocessing_function']\n",
        "\n",
        "        # Determine preprocessing function\n",
        "        use_pretrained_weights = config['model'].get('use_pretrained_weights', True)\n",
        "        if use_pretrained_weights:\n",
        "            if config['model']['name'].lower() in ['vggface']:\n",
        "                # Use VGGFace preprocessing for VGGFace models\n",
        "                self.preprocessing_function = lambda x: vggface_preprocess_input(x, version=2)  # Choose version based on model type\n",
        "            else:\n",
        "                self.preprocessing_function = PREPROCESSING_FUNCTIONS[config['model']['preprocessing_function']]\n",
        "        else:\n",
        "            # When training from scratch, set preprocessing function to None\n",
        "            self.preprocessing_function = None\n",
        "            self.rescale_layer = Rescaling(1./255)  # Move Rescaling here\n",
        "\n",
        "        self.augmentation_params = config['augmentation']\n",
        "        self.pre_split = config['data'].get('pre_split', True)\n",
        "\n",
        "        logger.debug(f'DG batch_size = {self.batch_size}')\n",
        "        logger.debug(f'DG target_zie = {self.target_size}')\n",
        "        logger.debug(f'DG preprocessing_function = {self.preprocessing_function_name}')\n",
        "        logger.debug(f'DG augmentation_params = {self.augmentation_params}')\n",
        "        logger.debug(f'DG pre_split = {self.pre_split}')\n",
        "\n",
        "        # Create data augmentation and rescaling layers\n",
        "        self.data_augmentation = self.create_data_augmentation()\n",
        "        self.rescale_layer = self.create_rescale_layer()\n",
        "\n",
        "        if self.pre_split:\n",
        "            logger.debug(\"DG Calling load_pre_split_data function.\")\n",
        "            self.load_pre_split_data()\n",
        "        else:\n",
        "            self.load_and_split_data()\n",
        "\n",
        "    def load_pre_split_data(self):\n",
        "        # Paths for pre-split data\n",
        "        logger.debug(\"DG LPSD Starting load_pre_split_data function.\")\n",
        "        self.train_path = self.config['data']['train_path']\n",
        "        logger.debug(f\"DG LPSD Train path: {self.train_path}\")\n",
        "        self.test_path = self.config['data']['test_path']\n",
        "        logger.debug(f\"DG LPSD Test path: {self.test_path}\")\n",
        "\n",
        "        # Validate paths\n",
        "        if not os.path.exists(self.train_path):\n",
        "            raise FileNotFoundError(f\"DG LPSD Training path not found: {self.train_path}\")\n",
        "        if not os.path.exists(self.test_path):\n",
        "            raise FileNotFoundError(f\"DG LPSD Testing path not found: {self.test_path}\")\n",
        "\n",
        "        # Load datasets\n",
        "        logger.debug(\"DG LPSD Loading train_dataset datasets\")\n",
        "        self.train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "            self.train_path,\n",
        "            label_mode='categorical',\n",
        "            batch_size=None,  # Load as individual samples\n",
        "            image_size=self.target_size,\n",
        "            color_mode=self.color_mode,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        logger.debug(\"DG LPSD Loading test_dataset datasets\")\n",
        "        self.test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "            self.test_path,\n",
        "            label_mode='categorical',\n",
        "            batch_size=None,\n",
        "            image_size=self.target_size,\n",
        "            color_mode=self.color_mode,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        train_dataset_unbatched = self.train_dataset\n",
        "        test_dataset_unbatched = self.test_dataset\n",
        "\n",
        "        self.class_names = self.train_dataset.class_names\n",
        "\n",
        "        logger.debug(f\"DG LPSD Class names: {self.class_names}\")\n",
        "\n",
        "        # Prepare datasets\n",
        "        logger.debug(\"DG LPSD Preparing datasets\")\n",
        "        self.train_dataset = self.prepare_dataset(self.train_dataset, augment=True)\n",
        "        logger.debug(\"DG LPSD Train dataset prepared.\")\n",
        "        self.val_dataset = self.prepare_dataset(self.test_dataset, augment=False)\n",
        "        logger.debug(\"DG LPSD Val dataset prepared.\")\n",
        "        self.test_dataset = self.val_dataset  # Use the validation dataset for testing if appropriate\n",
        "        logger.debug(\"DG LPSD Test dataset prepared.\")\n",
        "\n",
        "        # Compute sample counts\n",
        "        self.train_sample_count = tf.data.experimental.cardinality(train_dataset_unbatched).numpy()\n",
        "        self.val_sample_count = tf.data.experimental.cardinality(test_dataset_unbatched).numpy()\n",
        "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
        "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
        "\n",
        "        # Compute class counts directly from the dataset's file paths\n",
        "        self.class_counts = self.count_samples_from_directories(self.train_path, self.class_names)\n",
        "\n",
        "        # Compute class weights\n",
        "        self.class_weight_dict = compute_class_weights_from_counts(self.class_counts, self.class_names)\n",
        "\n",
        "        logger.info(f'\\nDG LPSD Train path: {self.train_path}')\n",
        "        logger.info(f'DG LPSD Test path: {self.test_path}')\n",
        "        logger.info(f'DG LPSD Batch size: {self.batch_size}')\n",
        "        logger.info(f'DG LPSD Input shape: {self.input_shape}')\n",
        "        logger.info(f'DG LPSD color_mode: {self.color_mode}')\n",
        "        logger.info(f'DG LPSD Target size: {self.target_size}')\n",
        "        logger.info(f'DG LPSD steps_per_epoch: {self.steps_per_epoch}')\n",
        "        logger.info(f'DG LPSD validation_steps: {self.validation_steps}')\n",
        "        logger.info(f'DG LPSD Preprocessing function: {self.preprocessing_function_name}')\n",
        "        logger.info(f'DG LPSD Augmentation params: {self.augmentation_params}')\n",
        "        logger.info(f'DG LPSD Class names: {self.class_names}')\n",
        "        logger.info(f'DG LPSD Class counts: {self.class_counts}')\n",
        "        logger.info(f'DG LPSD Class weights: {self.class_weight_dict}')\n",
        "        logger.info(f'DG LPSD Training set size: {self.train_sample_count}')\n",
        "        logger.info(f'DG LPSD Validation set size: {self.val_sample_count}')\n",
        "        logger.info(f'DG LPSD Testing set size: {self.val_sample_count}\\n')\n",
        "\n",
        "    def count_samples_from_directories(self, dataset_path, class_names):\n",
        "        import os\n",
        "        counts = {}\n",
        "        for class_name in class_names:\n",
        "            class_dir = os.path.join(dataset_path, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                counts[class_name] = len([\n",
        "                    fname for fname in os.listdir(class_dir)\n",
        "                    if os.path.isfile(os.path.join(class_dir, fname))\n",
        "                ])\n",
        "            else:\n",
        "                counts[class_name] = 0\n",
        "        return counts\n",
        "\n",
        "    def load_and_split_data(self):\n",
        "        logger.debug(\"DG LASD Getting Class Names.\")\n",
        "        self.class_names = [\n",
        "            d for d in sorted(os.listdir(self.config['data']['dataset_path']))\n",
        "            if os.path.isdir(os.path.join(self.config['data']['dataset_path'], d))\n",
        "        ]\n",
        "        logger.debug(f\"DG LASD Class Names: {self.class_names}\")\n",
        "        class_indices = {name: index for index, name in enumerate(self.class_names)}\n",
        "        logger.debug(f\"DG LASD Class Indices: {class_indices}\")\n",
        "    \n",
        "        # Collect file paths and labels\n",
        "        file_paths = []\n",
        "        labels = []\n",
        "        for class_name in self.class_names:\n",
        "            class_dir = os.path.join(self.config['data']['dataset_path'], class_name)\n",
        "            class_files = glob.glob(os.path.join(class_dir, '*'))\n",
        "            file_paths.extend(class_files)\n",
        "            labels.extend([class_indices[class_name]] * len(class_files))\n",
        "    \n",
        "        file_paths = np.array(file_paths)\n",
        "        labels = np.array(labels)\n",
        "    \n",
        "        # First split: train and temp (val + test)\n",
        "        logger.debug(\"DG LASD Splitting data into train and temp sets.\")\n",
        "        train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "            file_paths, labels,\n",
        "            # test_size=0.4,\n",
        "            test_size=float(self.config['data']['test_val_size']),\n",
        "            stratify=labels,\n",
        "            random_state=42\n",
        "        )\n",
        "    \n",
        "        # Second split: validation and test\n",
        "        logger.debug(\"DG LASD Splitting temp data into val and test sets.\")\n",
        "        val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "            temp_paths, temp_labels,\n",
        "            # test_size=0.5,\n",
        "            test_size=float(self.config['data']['test_val_split']),\n",
        "            stratify=temp_labels,\n",
        "            random_state=42\n",
        "        )\n",
        "    \n",
        "        # Mapping indices back to class names for readability\n",
        "        index_to_class = {index: name for name, index in class_indices.items()}\n",
        "    \n",
        "        # Training set class distribution\n",
        "        train_class_counts = Counter(train_labels)\n",
        "        train_class_counts_named = {index_to_class[k]: v for k, v in train_class_counts.items()}\n",
        "        logger.debug(f\"DG LASD Training class distribution: {train_class_counts_named}\")\n",
        "    \n",
        "        # Validation set class distribution\n",
        "        val_class_counts = Counter(val_labels)\n",
        "        val_class_counts_named = {index_to_class[k]: v for k, v in val_class_counts.items()}\n",
        "        logger.debug(f\"DG LASD Validation class distribution: {val_class_counts_named}\")\n",
        "    \n",
        "        # Test set class distribution\n",
        "        test_class_counts = Counter(test_labels)\n",
        "        test_class_counts_named = {index_to_class[k]: v for k, v in test_class_counts.items()}\n",
        "        logger.debug(f\"DG LASD Test class distribution: {test_class_counts_named}\")\n",
        "    \n",
        "        # Store the training class counts as an attribute\n",
        "        self.class_counts = train_class_counts_named\n",
        "    \n",
        "        # Create datasets from file paths and labels\n",
        "        logger.debug(\"DG LASD Creating datasets from file paths and labels.\")\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "        test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
        "    \n",
        "        # Get color_mode from config (default to 'rgb')\n",
        "        color_mode = self.config['data'].get('color_mode', 'rgb').lower()\n",
        "    \n",
        "        # Set the number of channels based on color mode\n",
        "        channels = 3 if color_mode == 'rgb' else 1\n",
        "    \n",
        "        # Define the load_image function inside the method\n",
        "        @tf.function\n",
        "        def load_image(file_path, label):\n",
        "            # Read the image from file\n",
        "            image = tf.io.read_file(file_path)\n",
        "            # Decode the image data (supports JPEG, PNG, BMP, and GIF)\n",
        "            image = tf.image.decode_image(image, channels=channels)\n",
        "    \n",
        "            # Log the original size of the image\n",
        "            original_size = image.shape\n",
        "            logger.debug(f\"File path: {file_path}, Original size: {original_size}\")\n",
        "    \n",
        "            # Set static shape if possible\n",
        "            if channels == 3:\n",
        "                image.set_shape([None, None, 3])\n",
        "            else:\n",
        "                image.set_shape([None, None, 1])\n",
        "            # Convert image to float32 and resize\n",
        "            image = tf.cast(image, tf.float32)\n",
        "            # Resize image to target size\n",
        "            image = tf.image.resize(image, self.target_size)\n",
        "    \n",
        "            # Log the new size of the image\n",
        "            new_size = image.shape\n",
        "            logger.debug(f\"File path: {file_path}, New size: {new_size}\")\n",
        "    \n",
        "            # Apply preprocessing function if specified\n",
        "            if self.preprocessing_function:\n",
        "                image = self.preprocessing_function(image)\n",
        "    \n",
        "            # One-hot encode the label\n",
        "            label = tf.one_hot(label, depth=len(self.class_names))\n",
        "            return image, label\n",
        "    \n",
        "        # Map function to load images from file paths\n",
        "        logger.debug(\"DG LASD Mapping load_image function to datasets.\")\n",
        "        train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        val_dataset = val_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "        test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    \n",
        "        # Prepare datasets\n",
        "        logger.debug(\"DG LASD Preparing datasets.\")\n",
        "        self.train_dataset = self.prepare_dataset(train_dataset, augment=True)\n",
        "        self.val_dataset = self.prepare_dataset(val_dataset, augment=False)\n",
        "        self.test_dataset = self.prepare_dataset(test_dataset, augment=False)\n",
        "    \n",
        "        # Compute sample counts\n",
        "        logger.debug(\"DG LASD Computing sample counts.\")\n",
        "        self.train_sample_count = len(train_paths)\n",
        "        self.val_sample_count = len(val_paths)\n",
        "        self.test_sample_count = len(test_paths)\n",
        "    \n",
        "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
        "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
        "        self.test_steps = math.ceil(self.test_sample_count / self.batch_size)\n",
        "    \n",
        "        # Compute class counts directly from the dataset's file paths\n",
        "        self.class_counts = self.count_samples_from_directories(self.config['data']['dataset_path'], self.class_names)\n",
        "    \n",
        "        logger.info(f'\\nDG LASD Batch size: {self.batch_size}')\n",
        "        logger.info(f'DG LASD Input shape: {self.input_shape}')\n",
        "        logger.info(f'DG LASD color_mode: {self.color_mode}')\n",
        "        logger.info(f'DG LASD Target size: {self.target_size}')\n",
        "        logger.info(f'DG LASD Steps per epoch: {self.steps_per_epoch}')\n",
        "        logger.info(f'DG LASD Validation steps: {self.validation_steps}')\n",
        "        logger.info(f'DG LASD Test steps: {self.test_steps}')\n",
        "        logger.info(f'DG LASD Augmentation params: {self.augmentation_params}')\n",
        "        logger.info(f'DG LASD Class names: {self.class_names}')\n",
        "        logger.info(f'DG LASD Class counts: {self.class_counts}')\n",
        "        logger.info(f'DG LASD Training sample size: {self.train_sample_count}')\n",
        "        logger.info(f'DG LASD Training class distribution: {train_class_counts_named}')\n",
        "        logger.info(f'DG LASD Validation sample size: {self.val_sample_count}')\n",
        "        logger.info(f'DG LASD Validation class distribution: {val_class_counts_named}')\n",
        "        logger.info(f'DG LASD Test sample size: {self.test_sample_count}')\n",
        "        logger.info(f'DG LASD Test class distribution: {test_class_counts_named}')\n",
        "\n",
        "\n",
        "    # def load_and_split_data(self):\n",
        "    #     logger.debug(\"DG LASD Getting Class Names.\")\n",
        "    #     self.class_names = [\n",
        "    #         d for d in sorted(os.listdir(self.config['data']['dataset_path']))\n",
        "    #         if os.path.isdir(os.path.join(self.config['data']['dataset_path'], d))\n",
        "    #     ]\n",
        "    #     logger.debug(f\"DG LASD Class Names: {self.class_names}\")\n",
        "    #     class_indices = {name: index for index, name in enumerate(self.class_names)}\n",
        "    #     logger.debug(f\"DG LASD Class Indices: {class_indices}\")\n",
        "    # \n",
        "    #     # Load images and labels\n",
        "    #     images = []\n",
        "    #     labels = []\n",
        "    # \n",
        "    #     for class_name in self.class_names:\n",
        "    #         class_dir = os.path.join(self.config['data']['dataset_path'], class_name)\n",
        "    #         class_files = glob.glob(os.path.join(class_dir, '*'))\n",
        "    #         for path in class_files:\n",
        "    #             img = Image.open(path)\n",
        "    #             img = img.convert(self.color_mode.upper())  # 'RGB' or 'L'\n",
        "    #             img = img.resize(self.target_size)\n",
        "    #             img = np.array(img)\n",
        "    #             images.append(img)\n",
        "    #             labels.append(class_indices[class_name])\n",
        "    # \n",
        "    #     images = np.array(images)\n",
        "    #     labels = np.array(labels)\n",
        "    # \n",
        "    #     # Normalize images\n",
        "    #     images = images.astype('float32') / 255.0\n",
        "    # \n",
        "    #     # Now, split images and labels\n",
        "    #     x_train, x_temp, y_train, y_temp = train_test_split(\n",
        "    #         images, labels,\n",
        "    #         test_size=float(self.config['data']['test_val_size']),\n",
        "    #         stratify=labels,\n",
        "    #         random_state=42\n",
        "    #     )\n",
        "    # \n",
        "    #     x_val, x_test, y_val, y_test = train_test_split(\n",
        "    #         x_temp, y_temp,\n",
        "    #         test_size=float(self.config['data']['test_val_split']),\n",
        "    #         stratify=y_temp,\n",
        "    #         random_state=42\n",
        "    #     )\n",
        "    # \n",
        "    #     # One-hot encode labels\n",
        "    #     y_train = tf.keras.utils.to_categorical(y_train, num_classes=len(self.class_names))\n",
        "    #     y_val = tf.keras.utils.to_categorical(y_val, num_classes=len(self.class_names))\n",
        "    #     y_test = tf.keras.utils.to_categorical(y_test, num_classes=len(self.class_names))\n",
        "    # \n",
        "    #     # Store the training class counts as an attribute\n",
        "    #     train_class_counts = Counter(np.argmax(y_train, axis=1))\n",
        "    #     index_to_class = {index: name for name, index in class_indices.items()}\n",
        "    #     train_class_counts_named = {index_to_class[k]: v for k, v in train_class_counts.items()}\n",
        "    #     self.class_counts = train_class_counts_named\n",
        "    # \n",
        "    #     # Prepare datasets\n",
        "    #     self.train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "    #     self.val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "    #     self.test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    # \n",
        "    #     # Prepare datasets\n",
        "    #     logger.debug(\"DG LASD Preparing datasets.\")\n",
        "    #     self.train_dataset = self.prepare_dataset(self.train_dataset, augment=True)\n",
        "    #     self.val_dataset = self.prepare_dataset(self.val_dataset, augment=False)\n",
        "    #     self.test_dataset = self.prepare_dataset(self.test_dataset, augment=False)\n",
        "    # \n",
        "    #     # Compute sample counts\n",
        "    #     self.train_sample_count = len(x_train)\n",
        "    #     self.val_sample_count = len(x_val)\n",
        "    #     self.test_sample_count = len(x_test)\n",
        "    # \n",
        "    #     self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
        "    #     self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
        "    #     self.test_steps = math.ceil(self.test_sample_count / self.batch_size)\n",
        "    # \n",
        "    #     logger.info(f'DG LASD Batch size: {self.batch_size}')\n",
        "    #     logger.info(f'DG LASD Input shape: {self.input_shape}')\n",
        "    #     logger.info(f'DG LASD color_mode: {self.color_mode}')\n",
        "    #     logger.info(f'DG LASD Target size: {self.target_size}')\n",
        "    #     logger.info(f'DG LASD Steps per epoch: {self.steps_per_epoch}')\n",
        "    #     logger.info(f'DG LASD Validation steps: {self.validation_steps}')\n",
        "    #     logger.info(f'DG LASD Test steps: {self.test_steps}')\n",
        "    #     logger.info(f'DG LASD Augmentation params: {self.augmentation_params}')\n",
        "    #     logger.info(f'DG LASD Class names: {self.class_names}')\n",
        "    #     logger.info(f'DG LASD Class counts: {self.class_counts}')\n",
        "    #     logger.info(f'DG LASD Training sample size: {self.train_sample_count}')\n",
        "    #     logger.info(f'DG LASD Validation sample size: {self.val_sample_count}')\n",
        "    #     logger.info(f'DG LASD Test sample size: {self.test_sample_count}')\n",
        "\n",
        "    @tf.function\n",
        "    def prepare_dataset(self, dataset, augment):\n",
        "        if augment:\n",
        "            try:\n",
        "                dataset = dataset.map(self.augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "                dataset = dataset.shuffle(1000).repeat()\n",
        "            except Exception as e:\n",
        "                logger.error(f\"DG SD An error occurred trying to prepare dataset with augment true: {e}\")\n",
        "                logger.debug(traceback.format_exc())\n",
        "        else:\n",
        "            dataset = dataset.map(self.normalize_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            dataset = dataset.cache()\n",
        "        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "        return dataset\n",
        "\n",
        "    def get_dataset_size(self, dataset):\n",
        "        return tf.data.experimental.cardinality(dataset).numpy() * self.batch_size\n",
        "\n",
        "    def create_data_augmentation(self):\n",
        "        layers = []\n",
        "        augmentation_params = self.augmentation_params\n",
        "\n",
        "        # Apply augmentations based on parameters\n",
        "        if augmentation_params.get('rotation_range'):\n",
        "            rotation_range = augmentation_params['rotation_range']\n",
        "            factor = rotation_range / 360.0  # Convert degrees to fraction of full circle\n",
        "            # Ensure factor is within [-1.0, 1.0]\n",
        "            factor = max(min(factor, 1.0), -1.0)\n",
        "            layers.append(RandomRotation(factor=(-factor, factor)))\n",
        "\n",
        "        if augmentation_params.get('horizontal_flip'):\n",
        "            layers.append(RandomFlip(mode='horizontal'))\n",
        "\n",
        "        if augmentation_params.get('vertical_flip'):\n",
        "            layers.append(RandomFlip(mode='vertical'))\n",
        "\n",
        "        if augmentation_params.get('zoom_range'):\n",
        "            zoom = augmentation_params['zoom_range']\n",
        "            # RandomZoom expects height_factor and width_factor in [-1.0, 1.0]\n",
        "            # Ensure zoom is within [0.0, 1.0] to avoid invalid factors\n",
        "            zoom = max(min(zoom, 1.0), 0.0)\n",
        "            layers.append(RandomZoom(height_factor=(-zoom, zoom), width_factor=(-zoom, zoom)))\n",
        "\n",
        "        if augmentation_params.get('width_shift_range') or augmentation_params.get('height_shift_range'):\n",
        "            width_shift = augmentation_params.get('width_shift_range', 0.0)\n",
        "            height_shift = augmentation_params.get('height_shift_range', 0.0)\n",
        "            # RandomTranslation expects height_factor and width_factor in [-1.0, 1.0]\n",
        "            width_shift = max(min(width_shift, 1.0), -1.0)\n",
        "            height_shift = max(min(height_shift, 1.0), -1.0)\n",
        "            layers.append(RandomTranslation(height_factor=height_shift, width_factor=width_shift))\n",
        "\n",
        "        if augmentation_params.get('brightness_range'):\n",
        "            brightness = augmentation_params['brightness_range']\n",
        "            # RandomBrightness expects factor in [0.0, inf), but to avoid extreme brightness, cap it\n",
        "            # brightness = max(brightness, 0.0)\n",
        "            # layers.append(RandomBrightness(factor=brightness))\n",
        "\n",
        "            # Replace RandomBrightness with a Lambda layer using tf.image.random_brightness\n",
        "            layers.append(tf.keras.layers.Lambda(lambda x: tf.image.random_brightness(x, max_delta=brightness)))\n",
        "\n",
        "        if augmentation_params.get('contrast_range'):\n",
        "            contrast = augmentation_params['contrast_range']\n",
        "            # RandomContrast expects factor in [0.0, inf), but to avoid extreme contrast, cap it\n",
        "            contrast = max(contrast, 0.0)\n",
        "            layers.append(RandomContrast(factor=contrast))\n",
        "\n",
        "        if not layers:\n",
        "            layers.append(tf.keras.layers.Lambda(lambda x: x))\n",
        "\n",
        "        data_augmentation = tf.keras.Sequential(layers)\n",
        "        return data_augmentation\n",
        "\n",
        "    def create_rescale_layer(self):\n",
        "        # Define which preprocessing functions expect which input ranges\n",
        "        preprocess_0_255 = [resnet_preprocess, vgg_preprocess]\n",
        "        preprocess_0_1 = [efficientnet_preprocess]\n",
        "        preprocess_minus1_1 = [mobilenet_preprocess, inception_preprocess]\n",
        "\n",
        "        # Skip rescaling for VGGFace models\n",
        "        if self.config['model']['name'].lower() in ['vggface']:\n",
        "            return None  # No rescaling needed; VGGFace preprocesses it\n",
        "        else:\n",
        "            if self.preprocessing_function in preprocess_0_255:\n",
        "                # No rescaling needed; images are already in [0, 255]\n",
        "                return None\n",
        "            elif self.preprocessing_function is None:\n",
        "                # For custom models without a preprocessing function, rescale to [0, 1]\n",
        "                return Rescaling(1./255)\n",
        "            elif self.preprocessing_function in preprocess_0_1:\n",
        "                # Rescaling needed to bring images to [0, 1]\n",
        "                return Rescaling(1./255)\n",
        "            elif self.preprocessing_function in preprocess_minus1_1:\n",
        "                # Rescaling needed to bring images to [0, 1]; preprocessing function will scale to [-1, 1]\n",
        "                return Rescaling(1./255)\n",
        "\n",
        "    @tf.function\n",
        "    def augment(self, images, labels):\n",
        "        # Different preprocessing functions expect different ranges of images after augmentation\n",
        "        # ResNet50V2 and VGG16: Expect images in the range [0, 255] with mean subtraction.\n",
        "        # InceptionV3 and MobileNetV2: Expect images scaled to [-1, 1].\n",
        "        # EfficientNetB0: Expects images scaled to [0, 1].\n",
        "\n",
        "        images = tf.cast(images, tf.float32)\n",
        "\n",
        "        # Apply rescaling if necessary\n",
        "        if self.rescale_layer:\n",
        "            images = self.rescale_layer(images)\n",
        "            \n",
        "        # Only apply preprocessing if it's set (won't be set for custom models)\n",
        "        if self.preprocessing_function is not None:\n",
        "            images = self.preprocessing_function(images)\n",
        "\n",
        "        # Apply data augmentation\n",
        "        images = self.data_augmentation(images)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    @tf.function\n",
        "    def normalize_and_preprocess(self, images, labels):\n",
        "        images = tf.cast(images, tf.float32)\n",
        "\n",
        "        # Apply rescaling if necessary\n",
        "        if self.rescale_layer:\n",
        "            images = self.rescale_layer(images)\n",
        "\n",
        "        # Apply preprocessing function if it exists\n",
        "        if self.preprocessing_function is not None:\n",
        "            images = self.preprocessing_function(images)\n",
        "\n",
        "        return images, labels\n",
        "\n",
        "    def create_datasets(self):\n",
        "        return None\n",
        "\n",
        "class MyHyperModel(HyperModel):\n",
        "    def __init__(self, config, num_classes, best_hyperparameters=None):\n",
        "        \"\"\"\n",
        "        Initializes the HyperModel.\n",
        "\n",
        "        Args:\n",
        "            config (dict): Configuration dictionary.\n",
        "            num_classes (int): Number of output classes.\n",
        "            best_hyperparameters (HyperParameters, optional): Best hyperparameters from tuning.\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.num_classes = num_classes\n",
        "        self.best_hyperparameters = best_hyperparameters\n",
        "\n",
        "    def build(self, hp):\n",
        "        \"\"\"\n",
        "        Builds the model based on whether to use pre-trained weights or not.\n",
        "\n",
        "        Args:\n",
        "            hp (HyperParameters): Hyperparameters for tuning.\n",
        "\n",
        "        Returns:\n",
        "            keras.Model: Compiled Keras model.\n",
        "        \"\"\"\n",
        "        # Determine if we're using a pre-trained model\n",
        "        model_config = self.config['model']\n",
        "        use_pretrained_weights = model_config.get('use_pretrained_weights', True)\n",
        "\n",
        "        # If hp is None, use best_hyperparameters or default fixed hyperparameters\n",
        "        if hp is None:\n",
        "            if self.best_hyperparameters is not None:\n",
        "                hp = self.best_hyperparameters\n",
        "            else:\n",
        "                # Create a default HyperParameters object with fixed values from config\n",
        "                hp = HyperParameters()\n",
        "\n",
        "                logger.info(f\"MHM-b no best hyperparameters found setting values to defaults from config file\")\n",
        "\n",
        "                if use_pretrained_weights:\n",
        "                    # Pre-trained model hyperparameters\n",
        "                    hp.Fixed('num_dense_layers', self.config['hyperparameters']['pretrained_model']['num_dense_layers']['default'])\n",
        "                    hp.Fixed('dense_units', self.config['hyperparameters']['pretrained_model']['dense_units']['default'])\n",
        "                    hp.Fixed('dropout_rate', self.config['hyperparameters']['pretrained_model']['dropout_rate']['default'])\n",
        "                    hp.Fixed('use_batch_norm', self.config['hyperparameters']['pretrained_model']['use_batch_norm']['default'])\n",
        "                    hp.Fixed('optimizer', self.config['hyperparameters']['pretrained_model']['optimizer']['default'])\n",
        "                    hp.Fixed('learning_rate', float(self.config['hyperparameters']['pretrained_model']['learning_rate']['default']))\n",
        "                    logger.info(f\"MHM-b setting num_dense_layers to default value: {hp.get('num_dense_layers')}\")\n",
        "                    logger.info(f\"MHM-b setting dense_units to default value: {hp.get('dense_units')}\")\n",
        "                    logger.info(f\"MHM-b setting dropout_rate to default value: {hp.get('dropout_rate')}\")\n",
        "                    logger.info(f\"MHM-b setting use_batch_norm to default value: {hp.get('use_batch_norm')}\")\n",
        "                    logger.info(f\"MHM-b setting optimizer to default value: {hp.get('optimizer')}\")\n",
        "                    logger.info(f\"MHM-b setting learning_rate to default value: {hp.get('learning_rate')}\")\n",
        "                else:\n",
        "                    # Scratch model hyperparameters\n",
        "                    hp.Fixed('num_conv_layers', self.config['hyperparameters']['scratch_model']['num_conv_layers']['default'])\n",
        "                    hp.Fixed('conv_filters_scratch', self.config['hyperparameters']['scratch_model']['conv_filters_scratch']['default'])\n",
        "                    hp.Fixed('conv_kernel_size_scratch', self.config['hyperparameters']['scratch_model']['conv_kernel_size_scratch']['default'])\n",
        "                    hp.Fixed('use_conv_batch_norm_scratch', self.config['hyperparameters']['scratch_model']['use_conv_batch_norm_scratch']['default'])\n",
        "                    hp.Fixed('conv_dropout_rate_scratch', self.config['hyperparameters']['scratch_model']['conv_dropout_rate_scratch']['default'])\n",
        "                    hp.Fixed('num_dense_layers_scratch', self.config['hyperparameters']['scratch_model']['num_dense_layers_scratch']['default'])\n",
        "                    hp.Fixed('dense_units_scratch', self.config['hyperparameters']['scratch_model']['dense_units_scratch']['default'])\n",
        "                    hp.Fixed('use_dense_batch_norm_scratch', self.config['hyperparameters']['scratch_model']['use_dense_batch_norm_scratch']['default'])\n",
        "                    hp.Fixed('dropout_rate_scratch', self.config['hyperparameters']['scratch_model']['dropout_rate_scratch']['default'])\n",
        "                    hp.Fixed('optimizer_scratch', self.config['hyperparameters']['scratch_model']['optimizer_scratch']['default'])\n",
        "                    hp.Fixed('learning_rate_scratch', float(self.config['hyperparameters']['scratch_model']['learning_rate_scratch']['default']))\n",
        "                    logger.info(f\"MHM-b setting num_conv_layers to default value: {hp.get('num_conv_layers')}\")\n",
        "                    logger.info(f\"MHM-b setting conv_filters_scratch to default value: {hp.get('conv_filters_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting conv_kernel_size_scratch to default value: {hp.get('conv_kernel_size_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting use_conv_batch_norm_scratch to default value: {hp.get('use_conv_batch_norm_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting conv_dropout_rate_scratch to default value: {hp.get('conv_dropout_rate_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting num_dense_layers_scratch to default value: {hp.get('num_dense_layers_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting dense_units_scratch to default value: {hp.get('dense_units_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting use_dense_batch_norm_scratch to default value: {hp.get('use_dense_batch_norm_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting dropout_rate_scratch to default value: {hp.get('dropout_rate_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting optimizer_scratch to default value: {hp.get('optimizer_scratch')}\")\n",
        "                    logger.info(f\"MHM-b setting learning_rate_scratch to default value: {hp.get('learning_rate_scratch')}\")\n",
        "\n",
        "        if use_pretrained_weights:\n",
        "            # **Using Pre-trained Architecture**\n",
        "            architecture_name = model_config['name']\n",
        "            architecture = ARCHITECTURES[architecture_name]\n",
        "            input_shape = tuple(model_config['input_shape'])\n",
        "            if use_pretrained_weights:\n",
        "                if architecture_name == 'VGGFace':\n",
        "                    base_model_weights = 'vggface'\n",
        "                else:\n",
        "                    base_model_weights = 'imagenet'\n",
        "            else:\n",
        "                None\n",
        "\n",
        "            logger.info(f\"MHM-b Building model with pre-trained model {architecture_name} with input shape {input_shape} and using the {base_model_weights} base model weights\")\n",
        "\n",
        "            # Load the base model with or without pre-trained weights\n",
        "            if architecture_name == 'VGGFace':\n",
        "                base_model = architecture(\n",
        "                    weights=base_model_weights,\n",
        "                    include_top=False,\n",
        "                    input_shape=input_shape,\n",
        "                    pooling='avg',  # Use global average pooling to reduce the need for Flatten\n",
        "                )\n",
        "            else:\n",
        "                    base_model = architecture(\n",
        "                    weights=base_model_weights,\n",
        "                    include_top=False,\n",
        "                    input_shape=input_shape,\n",
        "                    pooling='avg',  # Use global average pooling to reduce the need for Flatten\n",
        "                    name='base_model'  # Assign a name for easy access\n",
        "                )\n",
        "\n",
        "            # Freeze the base model initially\n",
        "            base_model.trainable = False\n",
        "\n",
        "            # Input layer\n",
        "            inputs = Input(shape=input_shape)\n",
        "            x = base_model(inputs, training=False)\n",
        "\n",
        "            # Hyperparameter for the number of dense layers\n",
        "            num_dense_layers = hp.Int(\n",
        "                'num_dense_layers',\n",
        "                min_value=self.config['hyperparameters']['pretrained_model']['num_dense_layers']['min'],\n",
        "                max_value=self.config['hyperparameters']['pretrained_model']['num_dense_layers']['max'],\n",
        "                default=self.config['hyperparameters']['pretrained_model']['num_dense_layers']['default']\n",
        "            )\n",
        "\n",
        "            # Integrate hyperparameters for dense units and dropout rate\n",
        "            dense_units = hp.Int(\n",
        "                'dense_units',\n",
        "                min_value=self.config['hyperparameters']['pretrained_model']['dense_units']['min'],\n",
        "                max_value=self.config['hyperparameters']['pretrained_model']['dense_units']['max'],\n",
        "                step=self.config['hyperparameters']['pretrained_model']['dense_units']['step'],\n",
        "                default=self.config['hyperparameters']['pretrained_model']['dense_units']['default']\n",
        "            )\n",
        "            dropout_rate = hp.Float(\n",
        "                'dropout_rate',\n",
        "                min_value=self.config['hyperparameters']['pretrained_model']['dropout_rate']['min'],\n",
        "                max_value=self.config['hyperparameters']['pretrained_model']['dropout_rate']['max'],\n",
        "                step=self.config['hyperparameters']['pretrained_model']['dropout_rate']['step'],\n",
        "                default=self.config['hyperparameters']['pretrained_model']['dropout_rate']['default']\n",
        "            )\n",
        "            use_batch_norm = hp.Boolean(\n",
        "                'use_batch_norm',\n",
        "                default=self.config['hyperparameters']['pretrained_model']['use_batch_norm']['default']\n",
        "            )\n",
        "\n",
        "            # Build the classification head using global hyperparameters\n",
        "            for _ in range(num_dense_layers):\n",
        "                x = Dense(dense_units, activation='relu')(x)\n",
        "                if use_batch_norm:\n",
        "                    x = BatchNormalization()(x)\n",
        "                if dropout_rate > 0.0:\n",
        "                    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "            # Output layer\n",
        "            output = Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "            # Create the model\n",
        "            model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "            # Compile the model with hyperparameter-defined optimizer\n",
        "            learning_rate = hp.Float(\n",
        "                'learning_rate',\n",
        "                min_value=float(self.config['hyperparameters']['pretrained_model']['learning_rate']['min']),\n",
        "                max_value=float(self.config['hyperparameters']['pretrained_model']['learning_rate']['max']),\n",
        "                sampling='log',\n",
        "                default=float(self.config['hyperparameters']['pretrained_model']['learning_rate']['default'])\n",
        "            )\n",
        "            optimizer_choice = hp.Choice(\n",
        "                'optimizer',\n",
        "                values=self.config['hyperparameters']['pretrained_model']['optimizer']['choices'],\n",
        "                default=self.config['hyperparameters']['pretrained_model']['optimizer']['default']\n",
        "            )\n",
        "\n",
        "            if optimizer_choice == 'adam':\n",
        "                optimizer = Adam(learning_rate=learning_rate)\n",
        "            elif optimizer_choice == 'sgd':\n",
        "                optimizer = SGD(learning_rate=learning_rate)\n",
        "            else:\n",
        "                optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
        "\n",
        "            metrics = ['accuracy'] + [METRICS[metric] for metric in self.config['model']['additional_metrics']]\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            # Print the model summary\n",
        "            logger.info(\"Model Summary:\")\n",
        "            model.summary()\n",
        "\n",
        "            return model\n",
        "\n",
        "        else:\n",
        "            # **Building Custom Model from Scratch**\n",
        "            logger.info(f'\\nMhM-b Building model from scratch.\\n')\n",
        "\n",
        "            # Input layer\n",
        "            inputs = Input(shape=tuple(self.config['data']['input_shape']))\n",
        "            x = inputs\n",
        "\n",
        "            # Hyperparameter for the number of convolutional layers\n",
        "            num_conv_layers = hp.Int(\n",
        "                'num_conv_layers',\n",
        "                min_value=self.config['hyperparameters']['scratch_model']['num_conv_layers']['min'],\n",
        "                max_value=self.config['hyperparameters']['scratch_model']['num_conv_layers']['max'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['num_conv_layers']['default']\n",
        "            )\n",
        "\n",
        "            # Global hyperparameters for convolutional layers\n",
        "            # Hyperparameters for number of convolutional filters\n",
        "            filters = hp.Int(\n",
        "                'conv_filters_scratch',\n",
        "                min_value=self.config['hyperparameters']['scratch_model']['conv_filters_scratch']['min'],\n",
        "                max_value=self.config['hyperparameters']['scratch_model']['conv_filters_scratch']['max'],\n",
        "                step=self.config['hyperparameters']['scratch_model']['conv_filters_scratch']['step'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['conv_filters_scratch']['default']\n",
        "            )\n",
        "            # Hyperparameters for kernel size\n",
        "            kernel_size = hp.Choice(\n",
        "                'conv_kernel_size_scratch',\n",
        "                values=self.config['hyperparameters']['scratch_model']['conv_kernel_size_scratch']['choices'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['conv_kernel_size_scratch']['default']\n",
        "            )\n",
        "            # Hyperparameters for convolutional batch normalization\n",
        "            use_conv_batch_norm = hp.Boolean(\n",
        "                'use_conv_batch_norm_scratch',\n",
        "                default=self.config['hyperparameters']['scratch_model']['use_conv_batch_norm_scratch']['default']\n",
        "            )\n",
        "            # Hyperparameters for convolutional dropout rate\n",
        "            conv_dropout_rate = hp.Float(\n",
        "                'conv_dropout_rate_scratch',\n",
        "                min_value=float(self.config['hyperparameters']['scratch_model']['conv_dropout_rate_scratch']['min']),\n",
        "                max_value=float(self.config['hyperparameters']['scratch_model']['conv_dropout_rate_scratch']['max']),\n",
        "                step=float(self.config['hyperparameters']['scratch_model']['conv_dropout_rate_scratch']['step']),\n",
        "                default=float(self.config['hyperparameters']['scratch_model']['conv_dropout_rate_scratch']['default'])\n",
        "            )\n",
        "\n",
        "            # Build convolutional layers\n",
        "            for i in range(num_conv_layers):\n",
        "                x = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), activation='relu', padding='same')(x)\n",
        "                if use_conv_batch_norm:\n",
        "                    x = BatchNormalization()(x)\n",
        "                x = MaxPooling2D((2, 2))(x)\n",
        "                if conv_dropout_rate > 0.0:\n",
        "                    x = Dropout(conv_dropout_rate)(x)\n",
        "\n",
        "            x = Flatten()(x)\n",
        "\n",
        "            # Hyperparameter for the number of dense layers\n",
        "            num_dense_layers = hp.Int(\n",
        "                'num_dense_layers_scratch',\n",
        "                min_value=self.config['hyperparameters']['scratch_model']['num_dense_layers_scratch']['min'],\n",
        "                max_value=self.config['hyperparameters']['scratch_model']['num_dense_layers_scratch']['max'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['num_dense_layers_scratch']['default']\n",
        "            )\n",
        "\n",
        "            # Global hyperparameters for dense layers\n",
        "            dense_units = hp.Int(\n",
        "                'dense_units_scratch',\n",
        "                min_value=self.config['hyperparameters']['scratch_model']['dense_units_scratch']['min'],\n",
        "                max_value=self.config['hyperparameters']['scratch_model']['dense_units_scratch']['max'],\n",
        "                step=self.config['hyperparameters']['scratch_model']['dense_units_scratch']['step'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['dense_units_scratch']['default']\n",
        "            )\n",
        "            dropout_rate = hp.Float(\n",
        "                'dropout_rate_scratch',\n",
        "                min_value=self.config['hyperparameters']['scratch_model']['dropout_rate_scratch']['min'],\n",
        "                max_value=self.config['hyperparameters']['scratch_model']['dropout_rate_scratch']['max'],\n",
        "                step=self.config['hyperparameters']['scratch_model']['dropout_rate_scratch']['step'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['dropout_rate_scratch']['default']\n",
        "            )\n",
        "            use_dense_batch_norm = hp.Boolean(\n",
        "                'use_dense_batch_norm_scratch',\n",
        "                default=False\n",
        "            )\n",
        "\n",
        "            # Build dense layers\n",
        "            for i in range(num_dense_layers):\n",
        "                x = Dense(dense_units, activation='relu')(x)\n",
        "                if use_dense_batch_norm:\n",
        "                    x = BatchNormalization()(x)\n",
        "                if dropout_rate > 0.0:\n",
        "                    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "            # Output layer\n",
        "            output = Dense(self.num_classes, activation='softmax')(x)\n",
        "\n",
        "            # Create the model\n",
        "            model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "            # Compile the model with hyperparameter-defined optimizer\n",
        "            learning_rate = hp.Float(\n",
        "                'learning_rate_scratch',\n",
        "                min_value=float(self.config['hyperparameters']['scratch_model']['learning_rate_scratch']['min']),\n",
        "                max_value=float(self.config['hyperparameters']['scratch_model']['learning_rate_scratch']['max']),\n",
        "                sampling='log',\n",
        "                default=float(self.config['hyperparameters']['scratch_model']['learning_rate_scratch']['default'])\n",
        "            )\n",
        "            optimizer_choice = hp.Choice(\n",
        "                'optimizer_scratch',\n",
        "                values=self.config['hyperparameters']['scratch_model']['optimizer_scratch']['choices'],\n",
        "                default=self.config['hyperparameters']['scratch_model']['optimizer_scratch']['default']\n",
        "            )\n",
        "\n",
        "            if optimizer_choice == 'adam':\n",
        "                optimizer = Adam(learning_rate=learning_rate)\n",
        "            elif optimizer_choice == 'sgd':\n",
        "                optimizer = SGD(learning_rate=learning_rate)\n",
        "            else:\n",
        "                optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
        "\n",
        "            metrics = ['accuracy'] + [METRICS[metric] for metric in self.config['model']['additional_metrics']]\n",
        "\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=metrics\n",
        "            )\n",
        "\n",
        "            # Print the model summary\n",
        "            logger.info(\"Model Summary:\")\n",
        "            model.summary()\n",
        "\n",
        "            return model\n",
        "\n",
        "def configure_logging(log_level='DEBUG', log_dir='logs', log_file='training.log'):\n",
        "    \"\"\"\n",
        "    Configures the logging level for the application.\n",
        "\n",
        "    Args:\n",
        "        log_level: The desired logging level (e.g., 'DEBUG', 'INFO', 'ERROR').\n",
        "    \"\"\"\n",
        "    # Map string levels to logging constants\n",
        "    log_level_map = {\n",
        "        'DEBUG': logging.DEBUG,\n",
        "        'INFO': logging.INFO,\n",
        "        'WARNING': logging.WARNING,\n",
        "        'ERROR': logging.ERROR,\n",
        "        'CRITICAL': logging.CRITICAL\n",
        "    }\n",
        "\n",
        "    # Clear any existing TensorFlow session\n",
        "    tf.keras.backend.clear_session()\n",
        "    # To ignore warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # Convert the string log level from config to the actual logging level\n",
        "    log_level_value = log_level_map.get(log_level.upper(), logging.INFO)\n",
        "\n",
        "    # Clear existing logging configuration\n",
        "    logger.handlers = []\n",
        "\n",
        "    # Create console handler\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(log_level)\n",
        "    console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "\n",
        "    # Create file handler with timestamp prefix\n",
        "    timestamp = datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "    log_file_with_timestamp = f\"{timestamp}_{log_file}\"\n",
        "    log_file_path = f'{log_dir}/{log_file_with_timestamp}'\n",
        "    file_handler = logging.FileHandler(log_file_path)\n",
        "    file_handler.setLevel(log_level)\n",
        "    file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
        "\n",
        "    # Add handlers to the logger\n",
        "    logger.addHandler(console_handler)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    # Set the logging level for the logger\n",
        "    logger.setLevel(log_level)\n",
        "    logger.info(f\"Logging level set to: {logging.getLevelName(log_level)}\")\n",
        "    logger.info(f\"Logging to file: {log_file_with_timestamp}\")\n",
        "\n",
        "def setup_random_seed(seed=42):\n",
        "    \"\"\"Configures random seed for reproducibility.\"\"\"\n",
        "    random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    # tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "def print_system_info():\n",
        "    \"\"\"Prints version info of the system and key libraries.\"\"\"\n",
        "    logger.info(f\"Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
        "    logger.info(f\"TensorFlow: {tf.__version__}\")\n",
        "    logger.info(f\"Keras: {tf.keras.__version__}\")\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    logger.info(f'GPUs: {gpus if gpus else \"None\"}\\n')\n",
        "\n",
        "def setup_gpu(gpu_config):\n",
        "    # gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Log the number of GPUs available\n",
        "            logger.debug(f\"SG GPU setup complete. Found {len(gpus)} GPU(s).\")\n",
        "\n",
        "            # Optionally, you can log more details about each GPU\n",
        "            for i, gpu in enumerate(gpus):\n",
        "                logger.debug(f\"GPU {i}: {gpu}\")\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            logger.error(f\"GPU setup failed: {e}\")\n",
        "    else:\n",
        "        logger.warning(\"No GPUs found. The model will run on CPU.\")\n",
        "\n",
        "def load_config(config_path):\n",
        "    with open(config_path, 'r') as file:\n",
        "        return yaml.safe_load(file)\n",
        "\n",
        "def setup_datasets(config):\n",
        "    try:\n",
        "        data_generator = DataGenerator(config)\n",
        "        logger.debug(\"SD DataGenerator initialized successfully.\")\n",
        "        train_dataset, test_dataset, steps_per_epoch, validation_steps = data_generator.get_data_generators()\n",
        "        class_names = data_generator.class_names  # Use class names from data generator\n",
        "        logger.debug(f\"SD Class names: {class_names}\")\n",
        "\n",
        "        return train_dataset, test_dataset, steps_per_epoch, validation_steps, class_names\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Dataset setup failed: {e}\")\n",
        "        logger.debug(traceback.format_exc())\n",
        "        raise\n",
        "\n",
        "def get_callbacks(config, train_dataset, test_dataset, validation_steps, for_tuning=False):\n",
        "    \"\"\"\n",
        "    Returns a list of callbacks based on the configuration.\n",
        "\n",
        "    Args:\n",
        "        config (dict): Configuration dictionary.\n",
        "        train_dataset (tf.data.Dataset): Training dataset.\n",
        "        test_dataset (tf.data.Dataset): Testing dataset.\n",
        "        validation_steps (int): Number of validation steps.\n",
        "        for_tuning (bool): Flag indicating if it's for hyperparameter tuning.\n",
        "\n",
        "    Returns:\n",
        "        list: List of Keras callbacks.\n",
        "    \"\"\"\n",
        "    callbacks = []\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=config['training']['patience'],\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    logger.debug(f\"EarlyStopping configured with monitor={early_stopping.monitor}, patience={early_stopping.patience}, restore_best_weights={early_stopping.restore_best_weights}\")\n",
        "    callbacks.append(early_stopping)\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        filepath=config['training']['model_checkpoint_path'],\n",
        "        save_best_only=True,\n",
        "        monitor='val_loss',\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "    logger.debug(f\"ModelCheckpoint configured with filepath={model_checkpoint.filepath}, save_best_only={model_checkpoint.save_best_only}, monitor={model_checkpoint.monitor}, save_weights_only={model_checkpoint.save_weights_only}, verbose={model_checkpoint.verbose}\")\n",
        "    callbacks.append(model_checkpoint)\n",
        "\n",
        "    # Incorporate ReduceLROnPlateau if specified in config\n",
        "    reduce_lr_config = config.get('reduce_lr_on_plateau', None)\n",
        "    if reduce_lr_config:\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor=reduce_lr_config.get('monitor', 'val_loss'),\n",
        "            factor=float(reduce_lr_config.get('factor', 0.5)),\n",
        "            patience=reduce_lr_config.get('patience', 5),\n",
        "            min_lr=float(reduce_lr_config.get('min_lr', 1e-6)),\n",
        "            verbose=reduce_lr_config.get('verbose', 1)\n",
        "        )\n",
        "        logger.debug(f\"ReduceLROnPlateau configured with monitor={reduce_lr.monitor}, factor={reduce_lr.factor}, patience={reduce_lr.patience}, min_lr={reduce_lr.min_lr}, verbose={reduce_lr.verbose}\")\n",
        "        callbacks.append(reduce_lr)\n",
        "\n",
        "    if not for_tuning:\n",
        "        # Include custom callbacks only when not tuning\n",
        "        callbacks.extend([\n",
        "            AccuracyCallback(target_accuracy=config['training']['target_accuracy']),\n",
        "            CustomValidationCallback(test_dataset, validation_steps),\n",
        "            DebugCallback(),\n",
        "            DatasetLogger(train_dataset, test_dataset)\n",
        "        ])\n",
        "\n",
        "    return callbacks\n",
        "\n",
        "def compute_class_weights_from_counts(class_counts, class_names):\n",
        "    total_samples = sum(class_counts.values())\n",
        "    class_weight_dict = {}\n",
        "    for idx, class_name in enumerate(class_names):\n",
        "        count = class_counts.get(class_name, 0)\n",
        "        if count > 0:\n",
        "            class_weight_dict[idx] = total_samples / (len(class_counts) * count)\n",
        "        else:\n",
        "            class_weight_dict[idx] = 0.0  # Handle classes with zero samples\n",
        "    return class_weight_dict\n",
        "\n",
        "def save_best_hyperparameters(best_hps, filepath='best_hyperparameters.json'):\n",
        "    # Assuming best_hps is an instance of HyperParameters\n",
        "    # Extracting hyperparameters values as a dictionary\n",
        "    hyperparameters_dict = {key: best_hps.get(key) for key in best_hps.values.keys()}\n",
        "\n",
        "    # Save the hyperparameters to a JSON file\n",
        "    with open(filepath, 'w') as f:\n",
        "        json.dump(hyperparameters_dict, f, indent=4)\n",
        "\n",
        "    logger.info(f\"SBHP Saved Best Hyperparameters to {filepath}.\")\n",
        "\n",
        "    # Log or print the loaded hyperparameters\n",
        "    logger.info(\"SBHP List of Best hyperparameters:\")\n",
        "    for key, value in hyperparameters_dict.items():\n",
        "        logger.info(f\"  {key}: {value}\")\n",
        "\n",
        "def load_best_hyperparameters(filepath='best_hyperparameters.json'):\n",
        "    \"\"\"\n",
        "    Loads the best hyperparameters from a JSON file and logs them.\n",
        "\n",
        "    Args:\n",
        "        filepath (str): Path to the JSON file containing the best hyperparameters.\n",
        "\n",
        "    Returns:\n",
        "        HyperParameters: A Keras Tuner HyperParameters object with the loaded values.\n",
        "    \"\"\"\n",
        "    # Load the hyperparameters from the JSON file\n",
        "    with open(filepath, 'r') as f:\n",
        "        hps_dict = json.load(f)\n",
        "\n",
        "    # Log or print the loaded hyperparameters\n",
        "    logger.info(f\"Loaded hyperparameters from {filepath}:\")\n",
        "    for key, value in hps_dict.items():\n",
        "        logger.info(f\"  {key}: {value}\")\n",
        "\n",
        "    # Create a HyperParameters object\n",
        "    hp = HyperParameters()\n",
        "\n",
        "    # Set the hyperparameters from the loaded JSON\n",
        "    for key, value in hps_dict.items():\n",
        "        hp.Fixed(key, value)\n",
        "\n",
        "    return hp\n",
        "\n",
        "def convert_pgm_to_png(input_dir, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for root, dirs, files in os.walk(input_dir):\n",
        "        # Create corresponding subdirectories in output_dir\n",
        "        rel_path = os.path.relpath(root, input_dir)\n",
        "        output_subdir = os.path.join(output_dir, rel_path)\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "        for filename in files:\n",
        "            if filename.lower().endswith('.pgm'):\n",
        "                filepath = os.path.join(root, filename)\n",
        "                try:\n",
        "                    with Image.open(filepath) as img:\n",
        "                        img = img.convert('L')  # Convert to RGB, use L for grayscale\n",
        "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
        "                        output_path = os.path.join(output_subdir, new_filename)\n",
        "                        img.save(output_path, 'PNG')\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error converting {filepath}: {e}\")\n",
        "                    logger.debug(traceback.format_exc())\n",
        "\n",
        "def create_custom_model(config, num_classes, input_shape):\n",
        "\n",
        "    logger.info(f\"Creating custom model.\\n\")\n",
        "\n",
        "    model_config = config['model']\n",
        "    use_pretrained_weights = model_config.get('use_pretrained_weights', True)\n",
        "\n",
        "    if use_pretrained_weights:\n",
        "        optimizer_choice = config['hyperparameters']['pretrained_model']['optimizer']['default']\n",
        "        learning_rate = config['hyperparameters']['pretrained_model']['learning_rate']['default']\n",
        "    else:\n",
        "        optimizer_choice = config['hyperparameters']['scratch_model']['optimizer_scratch']['default']\n",
        "        learning_rate = config['hyperparameters']['scratch_model']['learning_rate_scratch']['default']\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (5, 5), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    \n",
        "    # Remove padding='same' and adjust the Conv2D layer\n",
        "    x = Conv2D(64, (5, 5), padding='same', activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    # Adjust the pool_size to (3, 2)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    \n",
        "    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    if optimizer_choice == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_choice == 'sgd':\n",
        "        optimizer = SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
        "\n",
        "    metrics = ['accuracy'] + [METRICS[metric] for metric in config['model']['additional_metrics']]\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=metrics\n",
        "    )\n",
        "\n",
        "    # Print the model summary\n",
        "    logger.info(\"Model Summary:\")\n",
        "    model.summary()\n",
        "    \n",
        "    for layer in model.layers:\n",
        "        print(f\"{layer.name}: {layer.output_shape}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def create_custom_vggface_model(config, num_classes, input_shape):\n",
        "    \"\"\"\n",
        "    Create a custom model based on VGGFace pretrained model.\n",
        "    based on blog article: https://sefiks.com/2019/02/13/apparent-age-and-gender-prediction-in-keras/\n",
        "    \"\"\"\n",
        "    logger.debug(f\"Input shape: {input_shape}\")\n",
        "    logger.debug(f\"Input shape types: {[type(dim) for dim in input_shape]}\\n\")\n",
        "\n",
        "    model_config = config['model']\n",
        "    base_model_type = config['model']['base_name'].lower()\n",
        "    hidden_dim = config['model']['hidden_dims']\n",
        "\n",
        "    logger.debug(f\"Creating custom model based on VGGFace {base_model_type}.\\n\")\n",
        "\n",
        "    use_pretrained_weights = model_config.get('use_pretrained_weights', True)\n",
        "\n",
        "    if use_pretrained_weights:\n",
        "        optimizer_type = config['hyperparameters']['pretrained_model']['optimizer']['default']\n",
        "        learning_rate = float(config['hyperparameters']['pretrained_model']['learning_rate']['default'])\n",
        "    else:\n",
        "        optimizer_type = config['hyperparameters']['scratch_model']['optimizer_scratch']['default']\n",
        "        learning_rate = float(config['hyperparameters']['scratch_model']['learning_rate_scratch']['default'])\n",
        "\n",
        "    # Load the VGGFace model with the selected base model architecture\n",
        "    if base_model_type == 'vgg16':\n",
        "        base_model = VGGFace(include_top=False, model='vgg16', input_shape=input_shape)\n",
        "        last_layer = base_model.get_layer('pool5').output\n",
        "    elif base_model_type == 'resnet50':\n",
        "        base_model = VGGFace(include_top=False, model='resnet50', input_shape=input_shape)\n",
        "        last_layer = base_model.get_layer('avg_pool').output\n",
        "    elif base_model_type == 'senet50':\n",
        "        base_model = VGGFace(include_top=False, model='senet50', input_shape=input_shape)\n",
        "        last_layer = base_model.get_layer('avg_pool').output\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid base_model_type: {base_model_type}. Choose 'vgg16', 'resnet50', or 'senet50'.\")\n",
        "\n",
        "    # Load the pre-trained weights for VGGFace model\n",
        "    base_model.load_weights('models/vgg_face_weights.h5', by_name=True)\n",
        "    logger.debug(f\"Loaded pre-trained weights from 'vgg_face_weights.h5'\")\n",
        "\n",
        "    # Freeze all layers except the last three convolutional layers\n",
        "    for layer in base_model.layers[:-7]:\n",
        "        layer.trainable = False\n",
        "    logger.debug(f\"Froze all layers except the last 3 convolutional layers.\")\n",
        "\n",
        "    # Custom top layers\n",
        "    x = base_model.output\n",
        "\n",
        "    # Add a custom convolutional layer with 40 units\n",
        "    x = Conv2D(40, (1, 1), activation='relu', name='custom_conv')(x)\n",
        "    x = Flatten(name='flatten')(x)\n",
        "    x = Dense(hidden_dim, activation='relu', name='fc6')(x)\n",
        "    x = Dense(hidden_dim, activation='relu', name='fc7')(x)\n",
        "    output = Dense(num_classes, activation='softmax', name='classifier')(x)\n",
        "\n",
        "    # Create the new model using the base model's input and the custom output\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Choose optimizer\n",
        "    if optimizer_type == 'adam':\n",
        "        optimizer = Adam(learning_rate=learning_rate)\n",
        "    elif optimizer_type == 'sgd':\n",
        "        optimizer = SGD(learning_rate=learning_rate)\n",
        "    else:\n",
        "        optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
        "\n",
        "    # Add additional metrics\n",
        "    metrics = ['accuracy'] + [METRICS[metric] for metric in config['model']['additional_metrics']]\n",
        "\n",
        "    # Compile the model with the selected optimizer and categorical crossentropy loss\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=metrics)\n",
        "\n",
        "    # Print the model summary\n",
        "    logger.debug(\"\\nModel Summary:\")\n",
        "    model.summary()\n",
        "\n",
        "    # Run a forward pass with a dummy input\n",
        "    try:\n",
        "        # Ensure input_shape is a tuple of integers\n",
        "        input_shape = tuple(int(dim) for dim in input_shape)\n",
        "        dummy_input = tf.random.uniform((1,) + input_shape)\n",
        "        dummy_output = model(dummy_input)\n",
        "        print(f\"\\nForward pass output shape: {dummy_output.shape}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"\\nError during forward pass: {e}\")\n",
        "        logger.debug(traceback.format_exc())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def main(config_path):\n",
        "    \"\"\"\n",
        "    The main function to orchestrate data loading, model building, training, and evaluation.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to the configuration YAML file.\n",
        "    \"\"\"\n",
        "    global logger  # Use the global logger\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    # Load config.yaml\n",
        "    config = load_config('config.yaml')\n",
        "\n",
        "    # Set logging level based on the config file\n",
        "    logging_level = config['logging']['log_level']\n",
        "    log_dir = config['logging']['log_dir']\n",
        "    log_file = config['logging']['log_file']\n",
        "    configure_logging(logging_level, log_dir, log_file)\n",
        "\n",
        "    setup_random_seed()\n",
        "    # print_system_info()\n",
        "\n",
        "    # Load the configuration\n",
        "    config = load_config(config_path)\n",
        "    logger.debug(f\"MF Loaded configuration: {config}\")\n",
        "    performance_tuning = config.get('tuning', {}).get('perform_tuning', True)\n",
        "    logger.debug(f\"MF Perform tuning: {performance_tuning}\")\n",
        "    override = config.get('training', {}).get('override', False)\n",
        "\n",
        "    # Set up GPU if available\n",
        "    setup_gpu(config.get('gpu', {}))\n",
        "    logger.debug(\"MF Completed GPU setup.\")\n",
        "\n",
        "    # Load environment variables\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        # drive.mount('/content/drive')\n",
        "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "        DATASET_PATH = os.getenv('COLAB_DATASET_PATH')\n",
        "        logger.debug(\"MF Running in Colab environment\")\n",
        "    except ImportError:\n",
        "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "        DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
        "        logger.debug(\"MF Running in local environment\")\n",
        "\n",
        "    # Update the dataset paths based on whether the data is pre-split or not\n",
        "    pre_split = config['data'].get('pre_split', True)\n",
        "    if pre_split:\n",
        "        # For pre-split data\n",
        "        train_path = os.path.join(DATASET_PATH, config['data']['train_dir'])\n",
        "        test_path = os.path.join(DATASET_PATH, config['data']['test_dir'])\n",
        "        config['data']['train_path'] = train_path\n",
        "        config['data']['test_path'] = test_path\n",
        "        logger.debug(f\"MF Train path: {train_path}\")\n",
        "        logger.debug(f\"MF Test path: {test_path}\")\n",
        "    else:\n",
        "        # For single directory data\n",
        "        dataset_path = os.path.join(DATASET_PATH, config['data']['dataset_dir'])\n",
        "        config['data']['dataset_path'] = dataset_path\n",
        "        logger.debug(f\"MF Dataset path: {dataset_path}\")\n",
        "\n",
        "    try:\n",
        "        # Initialize DataGenerator\n",
        "        data_generator = DataGenerator(config)\n",
        "        logger.debug(\"DataGenerator initialized successfully.\")\n",
        "        train_dataset = data_generator.train_dataset\n",
        "        val_dataset = data_generator.val_dataset\n",
        "        test_dataset = data_generator.test_dataset\n",
        "        class_names = data_generator.class_names\n",
        "        logger.debug(f\"MF Class names: {class_names}\")\n",
        "        steps_per_epoch = data_generator.steps_per_epoch\n",
        "        validation_steps = data_generator.validation_steps\n",
        "\n",
        "        num_classes = len(class_names)\n",
        "\n",
        "        # Compute class weights using training data\n",
        "        logger.debug(\"MF Counting Classes and Computing Weights\")\n",
        "        class_counts = data_generator.class_counts\n",
        "        logger.debug(f\"MF Class counts: {class_counts}\")\n",
        "        class_weight_dict = compute_class_weights_from_counts(class_counts, class_names)\n",
        "        logger.debug(f\"MF Computed class weights: {class_weight_dict}\")\n",
        "\n",
        "        # Retrieve training parameters\n",
        "        initial_epochs = config['training'].get('initial_epochs', 10)\n",
        "        fine_tune_epochs = config['training'].get('fine_tune_epochs', 0)\n",
        "        total_epochs = initial_epochs + fine_tune_epochs\n",
        "\n",
        "        # Check if using pre-trained weights\n",
        "        use_pretrained_weights = config['model'].get('use_pretrained_weights', True)\n",
        "\n",
        "        if performance_tuning:\n",
        "            # Instantiate the hypermodel\n",
        "            hypermodel = MyHyperModel(config, num_classes)\n",
        "            logger.debug(\"MF HyperModel instantiated successfully.\")\n",
        "\n",
        "            # Get callbacks for tuning (only deepcopyable ones)\n",
        "            tuning_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=True)\n",
        "\n",
        "            # Set up the tuner\n",
        "            tuner = RandomSearch(\n",
        "                hypermodel,\n",
        "                objective='val_accuracy',\n",
        "                max_trials=config['tuning']['max_trials'],\n",
        "                executions_per_trial=config['tuning']['executions_per_trial'],\n",
        "                directory='hyperparameter_tuning',\n",
        "                project_name='keras_tuner_project'\n",
        "            )\n",
        "            logger.debug(\"Keras Tuner initialized successfully.\")\n",
        "\n",
        "            # Run the hyperparameter search\n",
        "            tuner.search(\n",
        "                train_dataset,\n",
        "                epochs=initial_epochs,\n",
        "                validation_data=val_dataset,\n",
        "                callbacks=tuning_callbacks,\n",
        "                class_weight=class_weight_dict,\n",
        "                steps_per_epoch=steps_per_epoch\n",
        "            )\n",
        "\n",
        "            # Get the optimal hyperparameters\n",
        "            best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "            save_best_hyperparameters(best_hps)\n",
        "            logger.debug(\"MF Best hyperparameters saved to file.\")\n",
        "\n",
        "            # Build the best model\n",
        "            model = tuner.hypermodel.build(best_hps)\n",
        "            logger.debug(\"MF Best model built with optimal hyperparameters.\")\n",
        "\n",
        "        else:\n",
        "            # Check if best_hyperparameters.json exists\n",
        "            best_hype_file_path = 'best_hyperparameters.json'\n",
        "            if os.path.exists(best_hype_file_path):\n",
        "                logger.debug(f'MF Loading best hyperparameters from file {best_hype_file_path}.')\n",
        "                best_hps = load_best_hyperparameters(best_hype_file_path)\n",
        "\n",
        "                # Instantiate the hypermodel with best hyperparameters\n",
        "                logger.info(f'MF Model building with loaded hyperparameters: {best_hps}\\n')\n",
        "                hypermodel = MyHyperModel(config, num_classes, best_hyperparameters=best_hps)\n",
        "                model = hypermodel.build(hp=None)  # hp is None, so it uses best_hyperparameters\n",
        "            else:\n",
        "                if override:\n",
        "                    input_shape = tuple(config['data']['input_shape'])\n",
        "                    model = create_custom_model(config, num_classes, input_shape)\n",
        "                    # model = create_custom_vggface_model(config, num_classes, input_shape)\n",
        "                else:\n",
        "                    logger.debug(f\"MF Best hyperparameters file not found. Building model with default hyperparameters from config.\")\n",
        "                    best_hps = None # No best hyperparameters available and uses default/fixed hyperparameters\n",
        "                    hypermodel = MyHyperModel(config, num_classes, best_hyperparameters=best_hps)\n",
        "                    model = hypermodel.build(hp=None) # hp is None, so it uses default hyperparameters\n",
        "\n",
        "        # Get all callbacks including custom ones for final training\n",
        "        final_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=False)\n",
        "\n",
        "        logger.info(f\"MF Starting Initial Training and Evaluation.\\n\")\n",
        "        # **Initial Training Phase**\n",
        "        history = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=initial_epochs,\n",
        "            validation_data=val_dataset,\n",
        "            callbacks=final_callbacks,\n",
        "            class_weight=class_weight_dict,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            # verbose=3\n",
        "        )\n",
        "\n",
        "        logger.info(f\"MF Initial training completed.\")\n",
        "\n",
        "        # **Fine-Tuning Phase**\n",
        "        if use_pretrained_weights and fine_tune_epochs > 0:\n",
        "            logger.debug(\"MFFT Starting fine-tuning phase.\")\n",
        "\n",
        "            # Unfreeze the base model\n",
        "            # Ensure that the base model was named 'base_model' in MyHyperModel\n",
        "            try:\n",
        "                base_model = model.get_layer('base_model')\n",
        "            except ValueError:\n",
        "                # If not found, iterate through layers to find the base model\n",
        "                base_model = None\n",
        "                for layer in model.layers:\n",
        "                    if isinstance(layer, Model):\n",
        "                        base_model = layer\n",
        "                        break\n",
        "                if base_model is None:\n",
        "                    raise ValueError(\"MFFT Base model layer not found for fine-tuning.\")\n",
        "\n",
        "            base_model.trainable = True\n",
        "\n",
        "            # Recompile the model with a lower learning rate\n",
        "            if use_pretrained_weights:\n",
        "                if performance_tuning:\n",
        "                    optimizer_choice = best_hps.get('optimizer', 'adam')\n",
        "                    fine_tune_learning_rate = float(config['model'].get('fine_tune_learning_rate', 1e-5))\n",
        "                else:\n",
        "                    optimizer_choice = config['hyperparameters']['pretrained_model']['optimizer']['default']\n",
        "                    fine_tune_learning_rate = float(config['model'].get('fine_tune_learning_rate', 1e-5))\n",
        "            else:\n",
        "                if performance_tuning:\n",
        "                    optimizer_choice = best_hps.get('optimizer', 'adam')\n",
        "                    fine_tune_learning_rate = float(config['model'].get('fine_tune_learning_rate_scratch', 1e-5))\n",
        "                else:\n",
        "                    optimizer_choice = config['hyperparameters']['scratch_model']['optimizer_scratch']['default']\n",
        "                    fine_tune_learning_rate = float(config['model'].get('fine_tune_learning_rate_scratch', 1e-5))\n",
        "\n",
        "            if optimizer_choice == 'adam':\n",
        "                optimizer = Adam(learning_rate=fine_tune_learning_rate)\n",
        "            elif optimizer_choice == 'sgd':\n",
        "                optimizer = SGD(learning_rate=fine_tune_learning_rate)\n",
        "            else:\n",
        "                optimizer = Adam(learning_rate=fine_tune_learning_rate)  # Default to Adam\n",
        "\n",
        "            # Recompile the model\n",
        "            model.compile(\n",
        "                optimizer=optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'] + [METRICS[metric] for metric in config['model']['additional_metrics']]\n",
        "            )\n",
        "\n",
        "            logger.debug(\"MFFT Model recompiled for fine-tuning.\")\n",
        "\n",
        "            # Continue training\n",
        "            history_fine = model.fit(\n",
        "                train_dataset,\n",
        "                epochs=total_epochs,\n",
        "                initial_epoch=initial_epochs,\n",
        "                validation_data=val_dataset,\n",
        "                callbacks=final_callbacks,\n",
        "                class_weight=class_weight_dict,\n",
        "                steps_per_epoch=steps_per_epoch\n",
        "            )\n",
        "\n",
        "            logger.debug(\"MFFT Fine-tuning completed.\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        logger.info(f\"MF Final evaluation:\")\n",
        "        final_evaluation = model.evaluate(test_dataset)\n",
        "        logger.info(f\"MF Final evaluation metrics: {final_evaluation}\")\n",
        "        # Build the list of metric names\n",
        "        metric_names = ['loss', 'accuracy']\n",
        "        additional_metric_names = [METRICS[metric].name for metric in config['model']['additional_metrics']]\n",
        "        metric_names.extend(additional_metric_names)\n",
        "\n",
        "        # Print the metrics\n",
        "        logger.info(\"MF Final evaluation metrics:\")\n",
        "        for name, value in zip(metric_names, final_evaluation):\n",
        "            logger.info(f\"  {name}: {value}\")\n",
        "\n",
        "        # Save the trained model\n",
        "        model.save('models/final_model.keras')\n",
        "        logger.info(f\"MF Model saved successfully to models/final_model.keras\\n\")\n",
        "\n",
        "        return history, model, class_names, config['data']['target_size'], config['model']['preprocessing_function'], config['model']['name']\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"MF An error occurred: {e}\")\n",
        "        logger.debug(traceback.format_exc())\n",
        "\n",
        "        return None, None, None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O4PM8kLt0xS6",
        "outputId": "45f40ef6-c924-403a-a949-7a08096a2f7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:12:04,753 - INFO - Logging level set to: 10\n",
            "2024-10-25 19:12:04,753 - INFO - Logging level set to: 10\n",
            "2024-10-25 19:12:04,755 - INFO - Logging to file: 20241025191204_1697032566-training.log\n",
            "2024-10-25 19:12:04,755 - INFO - Logging to file: 20241025191204_1697032566-training.log\n",
            "2024-10-25 19:12:04,772 - DEBUG - MF Loaded configuration: {'logging': {'log_dir': 'logs', 'log_file': '1697032566-training.log', 'log_level': 'DEBUG'}, 'model': {'name': 'ResNet50V2', 'preprocessing_function': 'resnet_preprocess', 'use_pretrained_weights': False, 'input_shape': [128, 128, 3], 'dense_units': 128, 'dropout_rate': 0.3, 'initial_learning_rate': 0.0003, 'decay_steps': 100, 'decay_rate': 0.96, 'fine_tune_learning_rate': '1e-5', 'additional_metrics': ['Precision', 'Recall', 'AUC', 'F1Score']}, 'augmentation': {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}, 'data': {'pre_split': False, 'test_val_size': 0.4, 'test_val_split': 0.5, 'dataset_dir': 'att_faces_png', 'train_dir': 'train_dataset', 'test_dir': 'test_dataset', 'validation_dir': 'val_dataset', 'color_mode': 'grayscale', 'batch_size': 64, 'input_shape': [26, 22, 1], 'target_size': [26, 22]}, 'tuning': {'perform_tuning': False, 'max_trials': 2, 'executions_per_trial': 1}, 'training': {'override': True, 'initial_epochs': 20, 'fine_tune_epochs': 0, 'patience': 10, 'target_accuracy': 0.99, 'find_lr': False, 'model_checkpoint_path': 'checkpoint.h5.keras'}, 'hyperparameters': {'pretrained_model': {'num_dense_layers': {'min': 1, 'max': 3, 'default': 2}, 'dense_units': {'min': 128, 'max': 1024, 'step': 128, 'default': 512}, 'dropout_rate': {'min': 0.0, 'max': 0.7, 'step': 0.1, 'default': 0.5}, 'use_batch_norm': {'default': False}, 'optimizer': {'choices': ['adam', 'sgd'], 'default': 'adam'}, 'learning_rate': {'min': '1e-5', 'max': '1e-3', 'default': 0.0003}}, 'scratch_model': {'num_conv_layers': {'min': 1, 'max': 5, 'default': 3}, 'conv_filters_scratch': {'min': 32, 'max': 256, 'step': 32, 'default': 32}, 'conv_kernel_size_scratch': {'choices': [3, 5], 'default': 3}, 'use_conv_batch_norm_scratch': {'default': False}, 'conv_dropout_rate_scratch': {'min': 0.0, 'max': 0.5, 'step': 0.1, 'default': 0.0}, 'num_dense_layers_scratch': {'min': 1, 'max': 4, 'default': 2}, 'dense_units_scratch': {'min': 64, 'max': 512, 'step': 64, 'default': 128}, 'use_dense_batch_norm_scratch': {'default': False}, 'dropout_rate_scratch': {'min': 0.0, 'max': 0.5, 'step': 0.1, 'default': 0.3}, 'optimizer_scratch': {'choices': ['adam', 'sgd'], 'default': 'adam'}, 'learning_rate_scratch': {'min': '1e-5', 'max': '1e-2', 'default': 0.0003}}}, 'reduce_lr_on_plateau': {'monitor': 'val_loss', 'factor': 0.2, 'patience': 20, 'min_lr': '1e-6', 'verbose': 1}, 'visualization': {'figure_size': [12, 4], 'history_plot_path': 'history_plot.png'}, 'gpu': {'memory_growth': True, 'allow_growth': True}}\n",
            "2024-10-25 19:12:04,772 - DEBUG - MF Loaded configuration: {'logging': {'log_dir': 'logs', 'log_file': '1697032566-training.log', 'log_level': 'DEBUG'}, 'model': {'name': 'ResNet50V2', 'preprocessing_function': 'resnet_preprocess', 'use_pretrained_weights': False, 'input_shape': [128, 128, 3], 'dense_units': 128, 'dropout_rate': 0.3, 'initial_learning_rate': 0.0003, 'decay_steps': 100, 'decay_rate': 0.96, 'fine_tune_learning_rate': '1e-5', 'additional_metrics': ['Precision', 'Recall', 'AUC', 'F1Score']}, 'augmentation': {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}, 'data': {'pre_split': False, 'test_val_size': 0.4, 'test_val_split': 0.5, 'dataset_dir': 'att_faces_png', 'train_dir': 'train_dataset', 'test_dir': 'test_dataset', 'validation_dir': 'val_dataset', 'color_mode': 'grayscale', 'batch_size': 64, 'input_shape': [26, 22, 1], 'target_size': [26, 22]}, 'tuning': {'perform_tuning': False, 'max_trials': 2, 'executions_per_trial': 1}, 'training': {'override': True, 'initial_epochs': 20, 'fine_tune_epochs': 0, 'patience': 10, 'target_accuracy': 0.99, 'find_lr': False, 'model_checkpoint_path': 'checkpoint.h5.keras'}, 'hyperparameters': {'pretrained_model': {'num_dense_layers': {'min': 1, 'max': 3, 'default': 2}, 'dense_units': {'min': 128, 'max': 1024, 'step': 128, 'default': 512}, 'dropout_rate': {'min': 0.0, 'max': 0.7, 'step': 0.1, 'default': 0.5}, 'use_batch_norm': {'default': False}, 'optimizer': {'choices': ['adam', 'sgd'], 'default': 'adam'}, 'learning_rate': {'min': '1e-5', 'max': '1e-3', 'default': 0.0003}}, 'scratch_model': {'num_conv_layers': {'min': 1, 'max': 5, 'default': 3}, 'conv_filters_scratch': {'min': 32, 'max': 256, 'step': 32, 'default': 32}, 'conv_kernel_size_scratch': {'choices': [3, 5], 'default': 3}, 'use_conv_batch_norm_scratch': {'default': False}, 'conv_dropout_rate_scratch': {'min': 0.0, 'max': 0.5, 'step': 0.1, 'default': 0.0}, 'num_dense_layers_scratch': {'min': 1, 'max': 4, 'default': 2}, 'dense_units_scratch': {'min': 64, 'max': 512, 'step': 64, 'default': 128}, 'use_dense_batch_norm_scratch': {'default': False}, 'dropout_rate_scratch': {'min': 0.0, 'max': 0.5, 'step': 0.1, 'default': 0.3}, 'optimizer_scratch': {'choices': ['adam', 'sgd'], 'default': 'adam'}, 'learning_rate_scratch': {'min': '1e-5', 'max': '1e-2', 'default': 0.0003}}}, 'reduce_lr_on_plateau': {'monitor': 'val_loss', 'factor': 0.2, 'patience': 20, 'min_lr': '1e-6', 'verbose': 1}, 'visualization': {'figure_size': [12, 4], 'history_plot_path': 'history_plot.png'}, 'gpu': {'memory_growth': True, 'allow_growth': True}}\n",
            "2024-10-25 19:12:04,773 - DEBUG - MF Perform tuning: False\n",
            "2024-10-25 19:12:04,773 - DEBUG - MF Perform tuning: False\n",
            "2024-10-25 19:12:04,773 - WARNING - No GPUs found. The model will run on CPU.\n",
            "2024-10-25 19:12:04,773 - WARNING - No GPUs found. The model will run on CPU.\n",
            "2024-10-25 19:12:04,774 - DEBUG - MF Completed GPU setup.\n",
            "2024-10-25 19:12:04,774 - DEBUG - MF Completed GPU setup.\n",
            "2024-10-25 19:12:04,776 - DEBUG - MF Running in local environment\n",
            "2024-10-25 19:12:04,776 - DEBUG - MF Running in local environment\n",
            "2024-10-25 19:12:04,776 - DEBUG - MF Dataset path: /Users/toddwalters/Development/data/advDLandCV/projects/1697032566/att_faces_png\n",
            "2024-10-25 19:12:04,776 - DEBUG - MF Dataset path: /Users/toddwalters/Development/data/advDLandCV/projects/1697032566/att_faces_png\n",
            "2024-10-25 19:12:04,777 - DEBUG - DataGenerator initialization starting.\n",
            "2024-10-25 19:12:04,777 - DEBUG - DataGenerator initialization starting.\n",
            "2024-10-25 19:12:04,777 - DEBUG - DG batch_size = 64\n",
            "2024-10-25 19:12:04,777 - DEBUG - DG batch_size = 64\n",
            "2024-10-25 19:12:04,778 - DEBUG - DG target_zie = (26, 22)\n",
            "2024-10-25 19:12:04,778 - DEBUG - DG target_zie = (26, 22)\n",
            "2024-10-25 19:12:04,778 - DEBUG - DG preprocessing_function = resnet_preprocess\n",
            "2024-10-25 19:12:04,778 - DEBUG - DG preprocessing_function = resnet_preprocess\n",
            "2024-10-25 19:12:04,779 - DEBUG - DG augmentation_params = {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
            "2024-10-25 19:12:04,779 - DEBUG - DG augmentation_params = {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
            "2024-10-25 19:12:04,779 - DEBUG - DG pre_split = False\n",
            "2024-10-25 19:12:04,779 - DEBUG - DG pre_split = False\n",
            "2024-10-25 19:12:04,787 - DEBUG - DG LASD Getting Class Names.\n",
            "2024-10-25 19:12:04,787 - DEBUG - DG LASD Getting Class Names.\n",
            "2024-10-25 19:12:04,790 - DEBUG - DG LASD Class Names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:04,790 - DEBUG - DG LASD Class Names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:04,793 - DEBUG - DG LASD Class Indices: {'s1': 0, 's10': 1, 's11': 2, 's12': 3, 's13': 4, 's14': 5, 's15': 6, 's16': 7, 's17': 8, 's18': 9, 's19': 10, 's2': 11, 's20': 12, 's21': 13, 's22': 14, 's23': 15, 's24': 16, 's25': 17, 's26': 18, 's27': 19, 's28': 20, 's29': 21, 's3': 22, 's30': 23, 's31': 24, 's32': 25, 's33': 26, 's34': 27, 's35': 28, 's36': 29, 's37': 30, 's38': 31, 's39': 32, 's4': 33, 's40': 34, 's5': 35, 's6': 36, 's7': 37, 's8': 38, 's9': 39}\n",
            "2024-10-25 19:12:04,793 - DEBUG - DG LASD Class Indices: {'s1': 0, 's10': 1, 's11': 2, 's12': 3, 's13': 4, 's14': 5, 's15': 6, 's16': 7, 's17': 8, 's18': 9, 's19': 10, 's2': 11, 's20': 12, 's21': 13, 's22': 14, 's23': 15, 's24': 16, 's25': 17, 's26': 18, 's27': 19, 's28': 20, 's29': 21, 's3': 22, 's30': 23, 's31': 24, 's32': 25, 's33': 26, 's34': 27, 's35': 28, 's36': 29, 's37': 30, 's38': 31, 's39': 32, 's4': 33, 's40': 34, 's5': 35, 's6': 36, 's7': 37, 's8': 38, 's9': 39}\n",
            "2024-10-25 19:12:04,802 - DEBUG - DG LASD Splitting data into train and temp sets.\n",
            "2024-10-25 19:12:04,802 - DEBUG - DG LASD Splitting data into train and temp sets.\n",
            "2024-10-25 19:12:04,804 - DEBUG - DG LASD Splitting temp data into val and test sets.\n",
            "2024-10-25 19:12:04,804 - DEBUG - DG LASD Splitting temp data into val and test sets.\n",
            "2024-10-25 19:12:04,812 - DEBUG - DG LASD Training class distribution: {'s13': 6, 's11': 6, 's31': 6, 's25': 6, 's36': 6, 's21': 6, 's39': 6, 's4': 6, 's9': 6, 's30': 6, 's16': 6, 's2': 6, 's22': 6, 's15': 6, 's18': 6, 's28': 6, 's20': 6, 's7': 6, 's5': 6, 's32': 6, 's10': 6, 's6': 6, 's12': 6, 's24': 6, 's33': 6, 's37': 6, 's14': 6, 's3': 6, 's35': 6, 's1': 6, 's34': 6, 's8': 6, 's38': 6, 's26': 6, 's40': 6, 's27': 6, 's29': 6, 's23': 6, 's19': 6, 's17': 6}\n",
            "2024-10-25 19:12:04,812 - DEBUG - DG LASD Training class distribution: {'s13': 6, 's11': 6, 's31': 6, 's25': 6, 's36': 6, 's21': 6, 's39': 6, 's4': 6, 's9': 6, 's30': 6, 's16': 6, 's2': 6, 's22': 6, 's15': 6, 's18': 6, 's28': 6, 's20': 6, 's7': 6, 's5': 6, 's32': 6, 's10': 6, 's6': 6, 's12': 6, 's24': 6, 's33': 6, 's37': 6, 's14': 6, 's3': 6, 's35': 6, 's1': 6, 's34': 6, 's8': 6, 's38': 6, 's26': 6, 's40': 6, 's27': 6, 's29': 6, 's23': 6, 's19': 6, 's17': 6}\n",
            "2024-10-25 19:12:04,816 - DEBUG - DG LASD Validation class distribution: {'s40': 2, 's32': 2, 's19': 2, 's38': 2, 's7': 2, 's16': 2, 's31': 2, 's17': 2, 's23': 2, 's37': 2, 's18': 2, 's28': 2, 's35': 2, 's26': 2, 's4': 2, 's11': 2, 's20': 2, 's13': 2, 's1': 2, 's34': 2, 's39': 2, 's22': 2, 's29': 2, 's3': 2, 's10': 2, 's25': 2, 's15': 2, 's9': 2, 's8': 2, 's27': 2, 's5': 2, 's33': 2, 's30': 2, 's36': 2, 's21': 2, 's6': 2, 's2': 2, 's24': 2, 's14': 2, 's12': 2}\n",
            "2024-10-25 19:12:04,816 - DEBUG - DG LASD Validation class distribution: {'s40': 2, 's32': 2, 's19': 2, 's38': 2, 's7': 2, 's16': 2, 's31': 2, 's17': 2, 's23': 2, 's37': 2, 's18': 2, 's28': 2, 's35': 2, 's26': 2, 's4': 2, 's11': 2, 's20': 2, 's13': 2, 's1': 2, 's34': 2, 's39': 2, 's22': 2, 's29': 2, 's3': 2, 's10': 2, 's25': 2, 's15': 2, 's9': 2, 's8': 2, 's27': 2, 's5': 2, 's33': 2, 's30': 2, 's36': 2, 's21': 2, 's6': 2, 's2': 2, 's24': 2, 's14': 2, 's12': 2}\n",
            "2024-10-25 19:12:04,818 - DEBUG - DG LASD Test class distribution: {'s23': 2, 's25': 2, 's27': 2, 's31': 2, 's38': 2, 's29': 2, 's15': 2, 's13': 2, 's33': 2, 's20': 2, 's16': 2, 's5': 2, 's17': 2, 's12': 2, 's9': 2, 's7': 2, 's19': 2, 's3': 2, 's37': 2, 's18': 2, 's40': 2, 's22': 2, 's30': 2, 's26': 2, 's28': 2, 's24': 2, 's11': 2, 's8': 2, 's34': 2, 's14': 2, 's10': 2, 's1': 2, 's4': 2, 's35': 2, 's2': 2, 's21': 2, 's36': 2, 's39': 2, 's6': 2, 's32': 2}\n",
            "2024-10-25 19:12:04,818 - DEBUG - DG LASD Test class distribution: {'s23': 2, 's25': 2, 's27': 2, 's31': 2, 's38': 2, 's29': 2, 's15': 2, 's13': 2, 's33': 2, 's20': 2, 's16': 2, 's5': 2, 's17': 2, 's12': 2, 's9': 2, 's7': 2, 's19': 2, 's3': 2, 's37': 2, 's18': 2, 's40': 2, 's22': 2, 's30': 2, 's26': 2, 's28': 2, 's24': 2, 's11': 2, 's8': 2, 's34': 2, 's14': 2, 's10': 2, 's1': 2, 's4': 2, 's35': 2, 's2': 2, 's21': 2, 's36': 2, 's39': 2, 's6': 2, 's32': 2}\n",
            "2024-10-25 19:12:04,893 - DEBUG - DG LASD Creating datasets from file paths and labels.\n",
            "2024-10-25 19:12:04,893 - DEBUG - DG LASD Creating datasets from file paths and labels.\n",
            "2024-10-25 19:12:04,898 - DEBUG - DG LASD Mapping load_image function to datasets.\n",
            "2024-10-25 19:12:04,898 - DEBUG - DG LASD Mapping load_image function to datasets.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /opt/homebrew/anaconda3/envs/facetime/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:12:05,290 - WARNING - From /opt/homebrew/anaconda3/envs/facetime/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x10820b9a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:12:05,339 - DEBUG - File path: Tensor(\"file_path:0\", shape=(), dtype=string), Original size: <unknown>\n",
            "2024-10-25 19:12:05,793 - WARNING - AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x10820b9a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x10820b9a0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:12:05,339 - DEBUG - File path: Tensor(\"file_path:0\", shape=(), dtype=string), Original size: <unknown>\n",
            "2024-10-25 19:12:06,081 - DEBUG - File path: Tensor(\"file_path:0\", shape=(), dtype=string), New size: (26, 22, 1)\n",
            "2024-10-25 19:12:06,081 - DEBUG - File path: Tensor(\"file_path:0\", shape=(), dtype=string), New size: (26, 22, 1)\n",
            "2024-10-25 19:12:06,116 - DEBUG - DG LASD Preparing datasets.\n",
            "2024-10-25 19:12:06,116 - DEBUG - DG LASD Preparing datasets.\n",
            "2024-10-25 19:12:06.391640: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2024-10-25 19:12:06,461 - DEBUG - DG LASD Computing sample counts.\n",
            "2024-10-25 19:12:06,461 - DEBUG - DG LASD Computing sample counts.\n",
            "2024-10-25 19:12:06,464 - INFO - \n",
            "DG LASD Batch size: 64\n",
            "2024-10-25 19:12:06,464 - INFO - \n",
            "DG LASD Batch size: 64\n",
            "2024-10-25 19:12:06,465 - INFO - DG LASD Input shape: (26, 22, 1)\n",
            "2024-10-25 19:12:06,465 - INFO - DG LASD Input shape: (26, 22, 1)\n",
            "2024-10-25 19:12:06,465 - INFO - DG LASD color_mode: grayscale\n",
            "2024-10-25 19:12:06,465 - INFO - DG LASD color_mode: grayscale\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Target size: (26, 22)\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Target size: (26, 22)\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Steps per epoch: 4\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Steps per epoch: 4\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Validation steps: 2\n",
            "2024-10-25 19:12:06,466 - INFO - DG LASD Validation steps: 2\n",
            "2024-10-25 19:12:06,467 - INFO - DG LASD Test steps: 2\n",
            "2024-10-25 19:12:06,467 - INFO - DG LASD Test steps: 2\n",
            "2024-10-25 19:12:06,467 - INFO - DG LASD Augmentation params: {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
            "2024-10-25 19:12:06,467 - INFO - DG LASD Augmentation params: {'enabled': False, 'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
            "2024-10-25 19:12:06,468 - INFO - DG LASD Class names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:06,468 - INFO - DG LASD Class names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:06,468 - INFO - DG LASD Class counts: {'s1': 10, 's10': 10, 's11': 10, 's12': 10, 's13': 10, 's14': 10, 's15': 10, 's16': 10, 's17': 10, 's18': 10, 's19': 10, 's2': 10, 's20': 10, 's21': 10, 's22': 10, 's23': 10, 's24': 10, 's25': 10, 's26': 10, 's27': 10, 's28': 10, 's29': 10, 's3': 10, 's30': 10, 's31': 10, 's32': 10, 's33': 10, 's34': 10, 's35': 10, 's36': 10, 's37': 10, 's38': 10, 's39': 10, 's4': 10, 's40': 10, 's5': 10, 's6': 10, 's7': 10, 's8': 10, 's9': 10}\n",
            "2024-10-25 19:12:06,468 - INFO - DG LASD Class counts: {'s1': 10, 's10': 10, 's11': 10, 's12': 10, 's13': 10, 's14': 10, 's15': 10, 's16': 10, 's17': 10, 's18': 10, 's19': 10, 's2': 10, 's20': 10, 's21': 10, 's22': 10, 's23': 10, 's24': 10, 's25': 10, 's26': 10, 's27': 10, 's28': 10, 's29': 10, 's3': 10, 's30': 10, 's31': 10, 's32': 10, 's33': 10, 's34': 10, 's35': 10, 's36': 10, 's37': 10, 's38': 10, 's39': 10, 's4': 10, 's40': 10, 's5': 10, 's6': 10, 's7': 10, 's8': 10, 's9': 10}\n",
            "2024-10-25 19:12:06,469 - INFO - DG LASD Training sample size: 240\n",
            "2024-10-25 19:12:06,469 - INFO - DG LASD Training sample size: 240\n",
            "2024-10-25 19:12:06,469 - INFO - DG LASD Training class distribution: {'s13': 6, 's11': 6, 's31': 6, 's25': 6, 's36': 6, 's21': 6, 's39': 6, 's4': 6, 's9': 6, 's30': 6, 's16': 6, 's2': 6, 's22': 6, 's15': 6, 's18': 6, 's28': 6, 's20': 6, 's7': 6, 's5': 6, 's32': 6, 's10': 6, 's6': 6, 's12': 6, 's24': 6, 's33': 6, 's37': 6, 's14': 6, 's3': 6, 's35': 6, 's1': 6, 's34': 6, 's8': 6, 's38': 6, 's26': 6, 's40': 6, 's27': 6, 's29': 6, 's23': 6, 's19': 6, 's17': 6}\n",
            "2024-10-25 19:12:06,469 - INFO - DG LASD Training class distribution: {'s13': 6, 's11': 6, 's31': 6, 's25': 6, 's36': 6, 's21': 6, 's39': 6, 's4': 6, 's9': 6, 's30': 6, 's16': 6, 's2': 6, 's22': 6, 's15': 6, 's18': 6, 's28': 6, 's20': 6, 's7': 6, 's5': 6, 's32': 6, 's10': 6, 's6': 6, 's12': 6, 's24': 6, 's33': 6, 's37': 6, 's14': 6, 's3': 6, 's35': 6, 's1': 6, 's34': 6, 's8': 6, 's38': 6, 's26': 6, 's40': 6, 's27': 6, 's29': 6, 's23': 6, 's19': 6, 's17': 6}\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Validation sample size: 80\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Validation sample size: 80\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Validation class distribution: {'s40': 2, 's32': 2, 's19': 2, 's38': 2, 's7': 2, 's16': 2, 's31': 2, 's17': 2, 's23': 2, 's37': 2, 's18': 2, 's28': 2, 's35': 2, 's26': 2, 's4': 2, 's11': 2, 's20': 2, 's13': 2, 's1': 2, 's34': 2, 's39': 2, 's22': 2, 's29': 2, 's3': 2, 's10': 2, 's25': 2, 's15': 2, 's9': 2, 's8': 2, 's27': 2, 's5': 2, 's33': 2, 's30': 2, 's36': 2, 's21': 2, 's6': 2, 's2': 2, 's24': 2, 's14': 2, 's12': 2}\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Validation class distribution: {'s40': 2, 's32': 2, 's19': 2, 's38': 2, 's7': 2, 's16': 2, 's31': 2, 's17': 2, 's23': 2, 's37': 2, 's18': 2, 's28': 2, 's35': 2, 's26': 2, 's4': 2, 's11': 2, 's20': 2, 's13': 2, 's1': 2, 's34': 2, 's39': 2, 's22': 2, 's29': 2, 's3': 2, 's10': 2, 's25': 2, 's15': 2, 's9': 2, 's8': 2, 's27': 2, 's5': 2, 's33': 2, 's30': 2, 's36': 2, 's21': 2, 's6': 2, 's2': 2, 's24': 2, 's14': 2, 's12': 2}\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Test sample size: 80\n",
            "2024-10-25 19:12:06,470 - INFO - DG LASD Test sample size: 80\n",
            "2024-10-25 19:12:06,471 - INFO - DG LASD Test class distribution: {'s23': 2, 's25': 2, 's27': 2, 's31': 2, 's38': 2, 's29': 2, 's15': 2, 's13': 2, 's33': 2, 's20': 2, 's16': 2, 's5': 2, 's17': 2, 's12': 2, 's9': 2, 's7': 2, 's19': 2, 's3': 2, 's37': 2, 's18': 2, 's40': 2, 's22': 2, 's30': 2, 's26': 2, 's28': 2, 's24': 2, 's11': 2, 's8': 2, 's34': 2, 's14': 2, 's10': 2, 's1': 2, 's4': 2, 's35': 2, 's2': 2, 's21': 2, 's36': 2, 's39': 2, 's6': 2, 's32': 2}\n",
            "2024-10-25 19:12:06,471 - INFO - DG LASD Test class distribution: {'s23': 2, 's25': 2, 's27': 2, 's31': 2, 's38': 2, 's29': 2, 's15': 2, 's13': 2, 's33': 2, 's20': 2, 's16': 2, 's5': 2, 's17': 2, 's12': 2, 's9': 2, 's7': 2, 's19': 2, 's3': 2, 's37': 2, 's18': 2, 's40': 2, 's22': 2, 's30': 2, 's26': 2, 's28': 2, 's24': 2, 's11': 2, 's8': 2, 's34': 2, 's14': 2, 's10': 2, 's1': 2, 's4': 2, 's35': 2, 's2': 2, 's21': 2, 's36': 2, 's39': 2, 's6': 2, 's32': 2}\n",
            "2024-10-25 19:12:06,471 - DEBUG - DataGenerator initialized successfully.\n",
            "2024-10-25 19:12:06,471 - DEBUG - DataGenerator initialized successfully.\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Class names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Class names: ['s1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Counting Classes and Computing Weights\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Counting Classes and Computing Weights\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Class counts: {'s1': 10, 's10': 10, 's11': 10, 's12': 10, 's13': 10, 's14': 10, 's15': 10, 's16': 10, 's17': 10, 's18': 10, 's19': 10, 's2': 10, 's20': 10, 's21': 10, 's22': 10, 's23': 10, 's24': 10, 's25': 10, 's26': 10, 's27': 10, 's28': 10, 's29': 10, 's3': 10, 's30': 10, 's31': 10, 's32': 10, 's33': 10, 's34': 10, 's35': 10, 's36': 10, 's37': 10, 's38': 10, 's39': 10, 's4': 10, 's40': 10, 's5': 10, 's6': 10, 's7': 10, 's8': 10, 's9': 10}\n",
            "2024-10-25 19:12:06,472 - DEBUG - MF Class counts: {'s1': 10, 's10': 10, 's11': 10, 's12': 10, 's13': 10, 's14': 10, 's15': 10, 's16': 10, 's17': 10, 's18': 10, 's19': 10, 's2': 10, 's20': 10, 's21': 10, 's22': 10, 's23': 10, 's24': 10, 's25': 10, 's26': 10, 's27': 10, 's28': 10, 's29': 10, 's3': 10, 's30': 10, 's31': 10, 's32': 10, 's33': 10, 's34': 10, 's35': 10, 's36': 10, 's37': 10, 's38': 10, 's39': 10, 's4': 10, 's40': 10, 's5': 10, 's6': 10, 's7': 10, 's8': 10, 's9': 10}\n",
            "2024-10-25 19:12:06,473 - DEBUG - MF Computed class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0}\n",
            "2024-10-25 19:12:06,473 - DEBUG - MF Computed class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 1.0, 21: 1.0, 22: 1.0, 23: 1.0, 24: 1.0, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0}\n",
            "2024-10-25 19:12:06,474 - INFO - Creating custom model.\n",
            "\n",
            "2024-10-25 19:12:06,474 - INFO - Creating custom model.\n",
            "\n",
            "2024-10-25 19:12:06,504 - INFO - Model Summary:\n",
            "2024-10-25 19:12:06,504 - INFO - Model Summary:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 26, 22, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 22, 18, 32)        832       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 9, 32)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 9, 64)         51264     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               163968    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 40)                5160      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221,224\n",
            "Trainable params: 221,224\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-25 19:12:06,509 - DEBUG - EarlyStopping configured with monitor=val_loss, patience=10, restore_best_weights=True\n",
            "2024-10-25 19:12:06,509 - DEBUG - EarlyStopping configured with monitor=val_loss, patience=10, restore_best_weights=True\n",
            "2024-10-25 19:12:06,510 - DEBUG - ModelCheckpoint configured with filepath=checkpoint.h5.keras, save_best_only=True, monitor=val_loss, save_weights_only=False, verbose=1\n",
            "2024-10-25 19:12:06,510 - DEBUG - ModelCheckpoint configured with filepath=checkpoint.h5.keras, save_best_only=True, monitor=val_loss, save_weights_only=False, verbose=1\n",
            "2024-10-25 19:12:06,510 - DEBUG - ReduceLROnPlateau configured with monitor=val_loss, factor=0.2, patience=20, min_lr=1e-06, verbose=1\n",
            "2024-10-25 19:12:06,510 - DEBUG - ReduceLROnPlateau configured with monitor=val_loss, factor=0.2, patience=20, min_lr=1e-06, verbose=1\n",
            "2024-10-25 19:12:06,511 - INFO - MF Starting Initial Training and Evaluation.\n",
            "\n",
            "2024-10-25 19:12:06,511 - INFO - MF Starting Initial Training and Evaluation.\n",
            "\n",
            "2024-10-25 19:12:06,661 - DEBUG - Starting epoch 1\n",
            "\n",
            "2024-10-25 19:12:06,661 - DEBUG - Starting epoch 1\n",
            "\n",
            "2024-10-25 19:12:06,662 - DEBUG - Epoch 1 - Train samples: -1\n",
            "2024-10-25 19:12:06,662 - DEBUG - Epoch 1 - Train samples: -1\n",
            "2024-10-25 19:12:06,663 - DEBUG - Epoch 1 - Val samples: 2\n",
            "2024-10-25 19:12:06,663 - DEBUG - Epoch 1 - Val samples: 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_1: [(None, 26, 22, 1)]\n",
            "conv2d: (None, 22, 18, 32)\n",
            "max_pooling2d: (None, 11, 9, 32)\n",
            "conv2d_1: (None, 11, 9, 64)\n",
            "max_pooling2d_1: (None, 5, 4, 64)\n",
            "flatten: (None, 1280)\n",
            "dense: (None, 128)\n",
            "dense_1: (None, 40)\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "history, model, class_names, target_size, preprocessing_function, ptm_name = main('config.yaml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9A2XmUHHYrb",
        "outputId": "1df8bf54-5236-43cb-e17d-4a6def443f82"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZpqujbcOYbm",
        "outputId": "fb1a476d-563f-470f-ceef-52301a6c8c5b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Simple model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(20,)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Generate dummy data\n",
        "import numpy as np\n",
        "X = np.random.random((100, 20))\n",
        "y = np.random.randint(2, size=(100, 1))\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5pkx6cW0xS7"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhq-En0Z0xS7"
      },
      "source": [
        "#### 1.4.2.1. <a id='toc1_4_2_1_'></a>[**Visualize Training And Validation Accuracy**](#toc0_)[&#8593;](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kXTyo2sP0xS7",
        "outputId": "f163bce7-387d-48d4-d1c7-9416d00fa6ad"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def training_subplot(hist, metric: str, plotnum: int, lim=None, test_val=None):\n",
        "    sp = plt.subplot(3, 2, plotnum)\n",
        "    metric_nm = metric.replace('_', ' ').capitalize()\n",
        "    plt.plot(hist.history[metric], label='Training')\n",
        "    plt.plot(hist.history['val_' + metric], label='Validation')\n",
        "\n",
        "    if test_val is not None:\n",
        "        test_lbl = 'Test ' + (f'({test_val:.1%})' if lim == 1 else f'({test_val:.2f})')\n",
        "        plt.axhline(y=test_val, label=test_lbl, color='green', linestyle='-')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(metric_nm)\n",
        "    plt.ylim(0, lim)\n",
        "    plt.xlim(0, len(hist.history['loss']))\n",
        "\n",
        "    if lim == 1:\n",
        "        sp.yaxis.set_major_formatter(ticker.PercentFormatter(xmax=1.0))\n",
        "\n",
        "    plt.legend()\n",
        "    plt.grid(visible=True, which='both', axis='both', linestyle='--', linewidth=0.5, color='grey')\n",
        "    plt.title(metric_nm)\n",
        "\n",
        "def plot_training_history(hist, ptm_name, title='Training History'):\n",
        "    # Assuming that you might have test values (quality scores) elsewhere in your project\n",
        "    # We'll set `None` for now. If you have test values, replace `None` with those values.\n",
        "    quality = {\n",
        "        'loss': None,         # Replace with actual test loss if available\n",
        "        'accuracy': None,     # Replace with actual test accuracy if available\n",
        "        'precision': None,    # Replace with actual test precision if available\n",
        "        'recall': None,       # Replace with actual test recall if available\n",
        "        'f1_score': None      # Replace with actual test F1 score if available\n",
        "    }\n",
        "\n",
        "    # Create the main figure and subplots\n",
        "    plt.figure(figsize=(24, 36))\n",
        "    #plt.suptitle(f'{title} using {ptm_name} with Best Performing Hyperparameters', fontsize=16, fontweight='bold')\n",
        "    plt.title(f'{title} using {ptm_name} with Best Performing Hyperparameters', fontsize=16, fontweight='bold')#\n",
        "\n",
        "\n",
        " # Plot loss\n",
        "    training_subplot(hist, 'loss', 1, test_val=quality['loss'])\n",
        "\n",
        "    # Plot accuracy\n",
        "    training_subplot(hist, 'accuracy', 2, lim=1, test_val=quality['accuracy'])\n",
        "\n",
        "    # Plot precision (check if precision exists in history)\n",
        "    if 'precision' in hist.history:\n",
        "        training_subplot(hist, 'precision', 3, lim=1, test_val=quality['precision'])\n",
        "\n",
        "    # Plot recall (check if recall exists in history)\n",
        "    if 'recall' in hist.history:\n",
        "        training_subplot(hist, 'recall', 4, lim=1, test_val=quality['recall'])\n",
        "\n",
        "    # Plot F1 score (check if F1 score exists in history)\n",
        "    if 'f1_score' in hist.history:\n",
        "        training_subplot(hist, 'f1_score', 5, lim=1, test_val=quality['f1_score'])\n",
        "\n",
        "    # Adjust layout to prevent overlapping\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example call after training:\n",
        "plot_training_history(history, 'Custom Model', title='Training History')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRDzVjKL0xS7"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kckX94MV0xS7"
      },
      "source": [
        "##### 1.4.2.1.1. <a id='toc1_4_2_1_1_'></a>[**Plot Hyperparameter Search Results**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STJsSK2x0xS7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import logging\n",
        "\n",
        "# Set logging level to INFO\n",
        "logger.basicConfig(level=logger.CRITICAL)\n",
        "\n",
        "# Define the directory containing the trial folders\n",
        "base_dir = \"hyperparameter_tuning/keras_tuner_project\"\n",
        "\n",
        "# Metrics to extract and plot\n",
        "metrics_to_plot = [\n",
        "    \"accuracy\", \"loss\", \"auc\", \"precision\", \"recall\", \"f1_score\",\n",
        "    \"val_accuracy\", \"val_loss\", \"val_auc\", \"val_precision\", \"val_recall\", \"val_f1_score\"\n",
        "]\n",
        "\n",
        "# Initialize storage for metrics\n",
        "all_metrics = {metric: [] for metric in metrics_to_plot}\n",
        "trial_ids = []\n",
        "scores = []\n",
        "\n",
        "# Iterate through each trial folder and extract metrics\n",
        "for trial_folder in sorted(os.listdir(base_dir)):\n",
        "    trial_path = os.path.join(base_dir, trial_folder)\n",
        "    trial_json_path = os.path.join(trial_path, \"trial.json\")\n",
        "\n",
        "    if os.path.isdir(trial_path) and os.path.exists(trial_json_path):\n",
        "        with open(trial_json_path, \"r\") as f:\n",
        "            trial_data = json.load(f)\n",
        "            trial_id = trial_data.get(\"trial_id\")\n",
        "            metrics = trial_data.get(\"metrics\", {}).get(\"metrics\", {})\n",
        "\n",
        "            # Skip trials with missing score or metrics\n",
        "            if not trial_data.get(\"score\") or not metrics:\n",
        "                continue\n",
        "\n",
        "            trial_ids.append(trial_id)\n",
        "            scores.append(trial_data.get(\"score\", 0))\n",
        "\n",
        "            # Extract the last recorded value for each metric\n",
        "            for metric in metrics_to_plot:\n",
        "                if metric in metrics:\n",
        "                    observations = metrics[metric][\"observations\"]\n",
        "                    if observations:\n",
        "                        value = observations[-1][\"value\"][0]  # Get the last value\n",
        "                        all_metrics[metric].append(value if value is not None else 0)\n",
        "                    else:\n",
        "                        all_metrics[metric].append(0)\n",
        "                else:\n",
        "                    all_metrics[metric].append(0)\n",
        "\n",
        "# Plot separate subplots for each metric\n",
        "fig, axs = plt.subplots(len(metrics_to_plot), 1, figsize=(15, 5 * len(metrics_to_plot)))\n",
        "\n",
        "# Use a color palette from seaborn\n",
        "colors = sns.color_palette(\"husl\", len(trial_ids))\n",
        "\n",
        "for idx, metric in enumerate(metrics_to_plot):\n",
        "    bars = axs[idx].bar(trial_ids, all_metrics[metric], color=colors)\n",
        "    axs[idx].set_title(f'{metric} across Trials')\n",
        "    axs[idx].set_xlabel('Trial ID')\n",
        "    axs[idx].set_ylabel(metric)\n",
        "    axs[idx].grid(True)\n",
        "\n",
        "    # Add labels to each bar\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        axs[idx].text(bar.get_x() + bar.get_width() / 2, yval + 0.02, f'{yval:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot heatmap of metrics\n",
        "metrics_array = np.array([all_metrics[metric] for metric in metrics_to_plot]).T\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.heatmap(metrics_array, annot=True, cmap='viridis', xticklabels=metrics_to_plot, yticklabels=trial_ids)\n",
        "plt.title(\"Heatmap of Metrics across Trials\")\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Trial ID\")\n",
        "plt.show()\n",
        "\n",
        "# Scatter plots for hyperparameters vs. score (example)\n",
        "# Assuming hyperparameters like learning_rate, dropout_rate are available in trial data\n",
        "hyperparameters_to_plot = [\"learning_rate\", \"dropout_rate\"]\n",
        "hyperparameters = {param: [] for param in hyperparameters_to_plot}\n",
        "\n",
        "# Extract hyperparameters for scatter plot\n",
        "for trial_folder in sorted(os.listdir(base_dir)):\n",
        "    trial_path = os.path.join(base_dir, trial_folder)\n",
        "    trial_json_path = os.path.join(trial_path, \"trial.json\")\n",
        "\n",
        "    if os.path.isdir(trial_path) and os.path.exists(trial_json_path):\n",
        "        with open(trial_json_path, \"r\") as f:\n",
        "            trial_data = json.load(f)\n",
        "            hyper_params = trial_data.get(\"hyperparameters\", {}).get(\"values\", {})\n",
        "\n",
        "            for param in hyperparameters_to_plot:\n",
        "                if param in hyper_params:\n",
        "                    hyperparameters[param].append(hyper_params[param])\n",
        "                else:\n",
        "                    hyperparameters[param].append(None)\n",
        "\n",
        "# Filter out trials with missing hyperparameters\n",
        "valid_indices = [i for i, score in enumerate(scores) if all(hyperparameters[param][i] is not None for param in hyperparameters_to_plot)]\n",
        "\n",
        "filtered_scores = [scores[i] for i in valid_indices]\n",
        "filtered_hyperparameters = {param: [hyperparameters[param][i] for i in valid_indices] for param in hyperparameters_to_plot}\n",
        "\n",
        "# Plot scatter plots of hyperparameters vs. score\n",
        "for param in hyperparameters_to_plot:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.scatter(filtered_hyperparameters[param], filtered_scores, color='darkred')\n",
        "    plt.xlabel(param)\n",
        "    plt.ylabel('Score')\n",
        "    plt.title(f'{param} vs. Score')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Plot score values across trials with filled area below the line\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(trial_ids, scores, color='blue', marker='o', linestyle='-', linewidth=2, label='Score')\n",
        "plt.fill_between(trial_ids, scores, color='blue', alpha=0.2)\n",
        "for i, score in enumerate(scores):\n",
        "    plt.text(i, score + 0.02, f'{score:.3f}', ha='center', fontsize=10, fontweight='bold')\n",
        "plt.xlabel('Trial ID')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Score Values across Trials')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdwIPjO20xS7"
      },
      "source": [
        "##### 1.4.2.1.2. <a id='toc1_4_2_1_2_'></a>[**Test Trained Model**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvDZTB2_0xS7"
      },
      "outputs": [],
      "source": [
        "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
        "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
        "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
        "from keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
        "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "\n",
        "# Create a dictionary mapping string names to preprocessing functions\n",
        "preprocessing_functions = {\n",
        "    'efficientnet_preprocess': efficientnet_preprocess,\n",
        "    'inception_preprocess': inception_preprocess,\n",
        "    'mobilenet_preprocess': mobilenet_preprocess,\n",
        "    'resnet_preprocess': resnet_preprocess,\n",
        "    'vgg_preprocess': vgg_preprocess\n",
        "}\n",
        "\n",
        "def predict_image_class(model, img_path, class_names, target_size, preprocessing_function_name):\n",
        "    target_size = target_size  # Get the target size for the chosen architecture\n",
        "    # Retrieve the actual preprocessing function from the dictionary\n",
        "    preprocessing_function = preprocessing_functions.get(preprocessing_function_name)\n",
        "\n",
        "    if preprocessing_function is None:\n",
        "        raise ValueError(f\"Unknown preprocessing function: {preprocessing_function_name}\")\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocessing_function(img_array)\n",
        "\n",
        "    # Make prediction\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions[0])\n",
        "    predicted_class = class_names[predicted_class_index]\n",
        "    confidence = predictions[0][predicted_class_index]\n",
        "\n",
        "    return predicted_class, confidence\n",
        "\n",
        "def visualize_prediction(img_path, target_size, predicted_class, confidence):\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {predicted_class}\\nConfidence: {confidence:.2f}\")\n",
        "    plt.show()\n",
        "\n",
        "# Mount Google Drive if using Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('COLAB_DATASET_PATH')\n",
        "    logger.debug(\"MF Running in Colab environment\")\n",
        "except ImportError:\n",
        "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
        "    DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
        "    logger.debug(\"MF Running in local environment\")\n",
        "\n",
        "print()\n",
        "print(\"Testing model on new images:\")\n",
        "print()\n",
        "\n",
        "# Get the list of all files in the model_test_images directory\n",
        "test_image_path = f'{DATASET_PATH}/validation_dataset'\n",
        "image_files = os.listdir(f'{test_image_path}/')\n",
        "\n",
        "# Optionally, filter the list to include only image files\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
        "image_files = [file for file in image_files if file.lower().endswith(image_extensions)]\n",
        "\n",
        "# Print the list of image files\n",
        "print(image_files)\n",
        "\n",
        "print(f'The preprocessing function is: {preprocessing_function}')\n",
        "print(f'The compiled model is: {model}')\n",
        "print(f'The class names are: {class_names}')\n",
        "\n",
        "# for img_path in test_image_paths:\n",
        "for image_file in image_files:\n",
        "    img_path = f'{test_image_path}/{image_file}'\n",
        "    predicted_class, confidence = predict_image_class(model, img_path, class_names, target_size, preprocessing_function)\n",
        "    print()\n",
        "    print(f\"Image: {img_path}\")\n",
        "    print(f\"Predicted class: {predicted_class}\")\n",
        "    print(f\"Confidence: {confidence:.2f}\")\n",
        "    print()\n",
        "\n",
        "    # Visualize prediction\n",
        "    visualize_prediction(img_path, target_size, predicted_class, confidence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiC93ea10xS7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKMAvFe00xS7"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYUnfg0n0xS7"
      },
      "source": [
        "##### 1.4.2.1.3. <a id='toc1_4_2_1_3_'></a>[**Thing A.B**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQNSq-H30xS7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNF9MyLU0xS7"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhy9UPre0xS8"
      },
      "source": [
        "##### 1.4.2.1.4. <a id='toc1_4_2_1_4_'></a>[**Thing A.C**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inaaFiO80xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYi1jfyB0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUAoncxp0xS8"
      },
      "source": [
        "##### 1.4.2.1.5. <a id='toc1_4_2_1_5_'></a>[**Thing A.D**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2hwg52x0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fdpMfhM0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ56o_l10xS8"
      },
      "source": [
        "### 1.4.3. <a id='toc1_4_3_'></a>[**Part 3**](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC12GqRr0xS8"
      },
      "source": [
        "#### 1.4.3.1. <a id='toc1_4_3_1_'></a>[**Thing A**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYlAkF_70xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdl_wEAv0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRztfgj50xS8"
      },
      "source": [
        "#### 1.4.3.2. <a id='toc1_4_3_2_'></a>[**Thing B**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ46ais-0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbGP1WE90xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF7PvT0L0xS8"
      },
      "source": [
        "##### 1.4.3.2.1. <a id='toc1_4_3_2_1_'></a>[**Thing B.A**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reDPgwGl0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWFqc6qp0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSsJgxza0xS8"
      },
      "source": [
        "##### 1.4.3.2.2. <a id='toc1_4_3_2_2_'></a>[**Thing B.A**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IHA47Oq0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFV2AiBL0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkQWrFHK0xS8"
      },
      "source": [
        "##### 1.4.3.2.3. <a id='toc1_4_3_2_3_'></a>[**Thing B.C**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmjuU3zY0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTDW4r10xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t813evvP0xS8"
      },
      "source": [
        "##### 1.4.3.2.4. <a id='toc1_4_3_2_4_'></a>[**Thing B.D**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEJ3YGdA0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqQbWqhf0xS8"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWq2_rN30xS8"
      },
      "source": [
        "#### 1.4.3.3. <a id='toc1_4_3_3_'></a>[**Thing C**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNQwY-fG0xS8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlpsZ6Ov0xS9"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua005KoW0xS9"
      },
      "source": [
        "#### 1.4.3.4. <a id='toc1_4_3_4_'></a>[**Thing D**](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6_LPIhc0xS9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h308HdAI0xS9"
      },
      "source": [
        "**Explanations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Why It Is Important:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "- [Placeholder for observations after running the code]\n",
        "\n",
        "**Conclusions:**\n",
        "\n",
        "- [Placeholder for conclusions based on initial data view]\n",
        "\n",
        "**Recommendations:**\n",
        "\n",
        "- [Placeholder for recommendations based on initial data examination]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "facetime",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
