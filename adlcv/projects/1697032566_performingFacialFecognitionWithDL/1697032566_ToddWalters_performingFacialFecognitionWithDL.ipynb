{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [**Performing Facial Recognition with Deep Learning**](#toc1_)    \n",
    "  - 1.1. [**Project Context**](#toc1_1_)    \n",
    "  - 1.2. [**Project Objectives**](#toc1_2_)    \n",
    "  - 1.3. [**Project Dataset Description**](#toc1_3_)    \n",
    "  - 1.4. [**Project Analysis Steps To Perform**](#toc1_4_)    \n",
    "    - 1.4.1. [**Preliminary analysis**](#toc1_4_1_)    \n",
    "      - 1.4.1.1. [**Import Modules and Set Default Environment Variables**](#toc1_4_1_1_)    \n",
    "      - 1.4.1.2. [**Look for corrupt files [Optional]**   ](#toc1_4_1_2_)    \n",
    "      - 1.4.1.3. [**Rename Files [Optional]**    ](#toc1_4_1_3_)    \n",
    "      - 1.4.1.4. [**Plot Sample Images**](#toc1_4_1_4_)    \n",
    "      - 1.4.1.5. [**Create a validation framework and split the data into train, test, and validation datasets**](#toc1_4_1_5_)    \n",
    "      - 1.4.1.6. [**Perform necessary transformations to prepare the data for input to the CNN model**](#toc1_4_1_6_)    \n",
    "      - 1.4.1.7. [**Thing G**](#toc1_4_1_7_)    \n",
    "      - 1.4.1.8. [**Thing H**](#toc1_4_1_8_)    \n",
    "      - 1.4.1.9. [**Thing I**](#toc1_4_1_9_)    \n",
    "      - 1.4.1.10. [**Thing J**](#toc1_4_1_10_)    \n",
    "      - 1.4.1.11. [**Thing K**](#toc1_4_1_11_)    \n",
    "      - 1.4.1.12. [**Thing L**](#toc1_4_1_12_)    \n",
    "    - 1.4.2. [**Part 2**](#toc1_4_2_)    \n",
    "      - 1.4.2.1. [**Thing A**](#toc1_4_2_1_)    \n",
    "        - 1.4.2.1.1. [**Thing A.A**](#toc1_4_2_1_1_)    \n",
    "        - 1.4.2.1.2. [**A.B**](#toc1_4_2_1_2_)    \n",
    "        - 1.4.2.1.3. [**Thing A.C**](#toc1_4_2_1_3_)    \n",
    "        - 1.4.2.1.4. [**Thing A.D**](#toc1_4_2_1_4_)    \n",
    "    - 1.4.3. [**Part 3**](#toc1_4_3_)    \n",
    "      - 1.4.3.1. [**Thing A**](#toc1_4_3_1_)    \n",
    "      - 1.4.3.2. [**Thing B**](#toc1_4_3_2_)    \n",
    "        - 1.4.3.2.1. [**Thing B.A**](#toc1_4_3_2_1_)    \n",
    "        - 1.4.3.2.2. [**Thing B.A**](#toc1_4_3_2_2_)    \n",
    "        - 1.4.3.2.3. [**Thing B.C**](#toc1_4_3_2_3_)    \n",
    "        - 1.4.3.2.4. [**Thing B.D**](#toc1_4_3_2_4_)    \n",
    "      - 1.4.3.3. [**Thing C**](#toc1_4_3_3_)    \n",
    "      - 1.4.3.4. [**Thing D**](#toc1_4_3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# 1. <a id='toc1_'></a>[**Performing Facial Recognition with Deep Learning**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## 1.1. <a id='toc1_1_'></a>[**Project Context**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "You are working for Face2Gene, an American AI company that has developed a \n",
    "healthcare app for doctors. The app utilizes deep learning algorithms to aid in diagnosing \n",
    "patients for genetic disorders and their variants. It converts patient photos into de-identified \n",
    "mathematical facial descriptors, which are then compared to syndrome-specific computational-\n",
    "based classifiers to determine similarity. The app provides a prioritized list of syndromes with \n",
    "similar morphology and suggests phenotypic traits and genes for feature annotation and \n",
    "syndrome prioritization. \n",
    "  \n",
    "Management has given priority to empowering and entrusting the in-house AI team. As a new \n",
    "member of the team, your task is to build a baseline model for facial recognition. The goal is to \n",
    "further enhance the app's existing features and add more value to the business based on this \n",
    "baseline model.\n",
    "\n",
    "-----------------------------\n",
    "## 1.2. <a id='toc1_2_'></a>[**Project Objectives**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Create a facial recognition tool using a relevant deep learning algorithm, leveraging \n",
    "the provided resources.\n",
    "\n",
    "-----------------------------\n",
    "## 1.3. <a id='toc1_3_'></a>[**Project Dataset Description**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "The ORL Database of Faces consists of 400 images from 40 different subjects. \n",
    "The images were captured at different times, under varying lighting conditions, with different \n",
    "facial expressions (open, closed eyes, smiling, not smiling), and with or without glasses. All the \n",
    "images have a dark homogeneous background, and the subjects are positioned upright and \n",
    "frontal with some tolerance for side movement. Each image has a size of 92x112 pixels and 256 \n",
    "grey levels per pixel. \n",
    "  \n",
    "Data can be downloaded from the following link: \n",
    "https://www.kaggle.com/datasets/kasikrit/att-database-of-faces\n",
    "\n",
    "-----------------------------------\n",
    "## 1.4. <a id='toc1_4_'></a>[**Project Analysis Steps To Perform**](#toc0_)\n",
    "-----------------------------------\n",
    "\n",
    "The following steps will guide you in building the model. \n",
    "  \n",
    "1. Import the relevant packages and collect all the necessary dependencies. \n",
    "  \n",
    "2. Upload and import the data. \n",
    "  \n",
    "3. View a few images to get a sense of the data. \n",
    "  \n",
    "4. Create a validation framework and split the data into train, test, and validation datasets. \n",
    "  \n",
    "5. Perform necessary transformations to prepare the data for input to the CNN model. \n",
    "  \n",
    "6. Build a CNN model with three main layers: a convolutional layer, a pooling layer, and a fully \n",
    "connected layer. You can also consider utilizing state-of-the-art architectures using transfer \n",
    "learning. \n",
    "  \n",
    "7. Train the model using the prepared data. \n",
    "  \n",
    "8. Plot the results to evaluate the model's performance. \n",
    "  \n",
    "9. Iterate on the model, making adjustments and improvements, until you achieve an accuracy \n",
    "above 90%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. <a id='toc1_4_1_'></a>[**Preliminary analysis**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.1. <a id='toc1_4_1_1_'></a>[**Import Modules and Set Default Environment Variables**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import backend as K\n",
    "from keras.applications import (EfficientNetB0, InceptionV3, MobileNetV2, ResNet50V2, VGG16)\n",
    "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from keras.callbacks import (Callback, EarlyStopping, LambdaCallback, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau)\n",
    "from keras.layers import (BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Input)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- This code block imports necessary libraries (`pandas`, `numpy`, `matplotlib`, and `seaborn`) and reads the three CSV files into pandas DataFrames. It then displays the first few rows of each dataset to give an initial view of the data.\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- Importing and examining the datasets is crucial as it allows us to understand the structure and content of our data. This step helps identify any immediate issues with data formatting or missing values and provides a foundation for all subsequent analyses.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.2. <a id='toc1_4_1_2_'></a>[**Look for corrupt files [Optional]**](#toc0_)    [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_images(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif', '.pgm', '.pnm', '.webp')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img.verify()\n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    print(f'Bad file: {file_path}')\n",
    "                    os.remove(file_path)\n",
    "                    print(f'Deleted bad file: {file_path}')\n",
    "\n",
    "# verify_images(f'{DATASET_PATH}/dataset_test')\n",
    "# verify_images(f'{DATASET_PATH}/structure_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- This code examines the shape, structure, and quality of each dataset. It checks the number of rows and columns, data types of each column, presence of missing values, and existence of duplicate entries.\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- Understanding the dataset's structure and quality is crucial for data preprocessing and analysis. It helps identify potential issues like missing data or duplicates that need to be addressed before proceeding with the analysis.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.3. <a id='toc1_4_1_3_'></a>[**Rename Files [Optional]**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_string(length):\n",
    "    \"\"\"Generate a random string of fixed length\"\"\"\n",
    "    letters = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def rename_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Generate a unique name\n",
    "            new_name = str(uuid.uuid4())\n",
    "\n",
    "            # Get the file extension\n",
    "            file_extension = os.path.splitext(filename)[1]\n",
    "\n",
    "            # Create the new filename\n",
    "            new_filename = f\"{new_name}.{file_extension}\"\n",
    "\n",
    "            # Full paths\n",
    "            old_file = os.path.join(root, filename)\n",
    "            new_file = os.path.join(root, new_filename)\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "\n",
    "# Uncomment if you want to rename all of the files in the dataset\n",
    "# directories = [f'{DATASET_PATH}/structures_dataset', f'{DATASET_PATH}/dataset_test']\n",
    "# for start_directory in directories:\n",
    "#     rename_files(start_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.4. <a id='toc1_4_1_4_'></a>[**Convert File Type [Optional]**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pgm_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Create corresponding subdirectories in output_dir\n",
    "        rel_path = os.path.relpath(root, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, rel_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.pgm'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    with Image.open(filepath) as img:\n",
    "                        img = img.convert('RGB')  # Convert to RGB\n",
    "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                        output_path = os.path.join(output_subdir, new_filename)\n",
    "                        img.save(output_path, 'PNG')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {filepath}: {e}\")\n",
    "\n",
    "# Usage\n",
    "# input_dir = 'att_faces_pgm'  # Your current dataset path with PGM files\n",
    "# output_dir = 'att_faces'  # New dataset path for PNG files\n",
    "convert_pgm_to_png(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.4. <a id='toc1_4_1_4_'></a>[**Plot Sample Images**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(dataset_path, num_samples=8):\n",
    "    classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    fig, axes = plt.subplots(len(classes), num_samples, figsize=(20, 4*len(classes)))\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))][:num_samples]\n",
    "\n",
    "        for j, image_name in enumerate(images):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "        # Set the class name as the title for the first image in the row\n",
    "        axes[i, 0].set_title(class_name, fontsize=16, pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mount Google Drive if using Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "    DATASET_PATH = os.getenv('COLAB_DATASET_PATH', default='/default/dataset/path')\n",
    "except ImportError:\n",
    "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "    DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
    "\n",
    "plot_sample_images(f'{DATASET_PATH}/structures_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.5. <a id='toc1_4_1_5_'></a>[**Create a validation framework and split the data into train, test, and validation datasets**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.6. <a id='toc1_4_1_6_'></a>[**Perform necessary transformations to prepare the data for input to the CNN model**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.7. <a id='toc1_4_1_7_'></a>[**Thing G**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.8. <a id='toc1_4_1_8_'></a>[**Thing H**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.9. <a id='toc1_4_1_9_'></a>[**Thing I**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. <a id='toc1_4_2_'></a>[**Train Model with Augmentation**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a debug message\n",
      "This is an info message\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import traceback\n",
    "import warnings\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import (\n",
    "    EfficientNetB0,\n",
    "    InceptionV3,\n",
    "    MobileNetV2,\n",
    "    ResNet50V2,\n",
    "    VGG16\n",
    ")\n",
    "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from keras.callbacks import (\n",
    "    Callback,\n",
    "    EarlyStopping,\n",
    "    LambdaCallback,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau\n",
    ")\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    GlobalAveragePooling2D,\n",
    "    Input,\n",
    "    RandomRotation,\n",
    "    RandomFlip,\n",
    "    RandomZoom,\n",
    "    RandomContrast,\n",
    "    RandomBrightness,\n",
    "    RandomTranslation,\n",
    "    Rescaling\n",
    ")\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.utils import Sequence\n",
    "from keras.metrics import Precision, Recall, AUC\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Import Keras Tuner modules\n",
    "from keras_tuner import (\n",
    "    Hyperband, \n",
    "    HyperModel, \n",
    "    HyperParameters, \n",
    "    BayesianOptimization, \n",
    "    RandomSearch\n",
    ")\n",
    "\n",
    "# Clear any existing TensorFlow session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Set up the logger and the handler\n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Set the level for the handler\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Set the overall logger level to DEBUG\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Test logging\n",
    "logger.debug(\"This is a debug message\")    # Should be displayed\n",
    "logger.info(\"This is an info message\")     # Should be displayed\n",
    "\n",
    "# To ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure Random Seed for Numpy and Tensorflow\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Define mappings for architectures and preprocessing functions\n",
    "ARCHITECTURES = {\n",
    "    'ResNet50V2': ResNet50V2,\n",
    "    'VGG16': VGG16,\n",
    "    'InceptionV3': InceptionV3,\n",
    "    'MobileNetV2': MobileNetV2,\n",
    "    'EfficientNetB0': EfficientNetB0\n",
    "}\n",
    "\n",
    "PREPROCESSING_FUNCTIONS = {\n",
    "    'resnet_preprocess': resnet_preprocess,\n",
    "    'vgg_preprocess': vgg_preprocess,\n",
    "    'inception_preprocess': inception_preprocess,\n",
    "    'mobilenet_preprocess': mobilenet_preprocess,\n",
    "    'efficientnet_preprocess': efficientnet_preprocess\n",
    "}\n",
    "\n",
    "# Define metrics mapping\n",
    "METRICS = {\n",
    "    'Precision': Precision(name='precision'),\n",
    "    'Recall': Recall(name='recall'),\n",
    "    'AUC': AUC(name='auc')\n",
    "}\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def __init__(self, target_accuracy):\n",
    "        super().__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_accuracy') >= self.target_accuracy:\n",
    "            print(f\"\\nReached {self.target_accuracy*100}% validation accuracy. Stopping training.\")\n",
    "            print()\n",
    "            print(\"--------------------\")\n",
    "            print()\n",
    "            self.model.stop_training = True\n",
    "\n",
    "class CustomValidationCallback(Callback):\n",
    "    def __init__(self, validation_data, validation_steps):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.validation_steps = validation_steps\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        for x, y in self.validation_data.take(self.validation_steps):\n",
    "            val_metrics = self.model.test_on_batch(x, y)\n",
    "            val_loss += val_metrics[0]\n",
    "            val_accuracy += val_metrics[1]\n",
    "\n",
    "        val_loss /= self.validation_steps\n",
    "        val_accuracy /= self.validation_steps\n",
    "\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logging.debug(f\"\\nEpoch {epoch + 1} - Custom validation:\")\n",
    "        logging.debug(f\"Loss: {val_loss:.4f}\")\n",
    "        logging.debug(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "class DatasetLogger(Callback):\n",
    "    def __init__(self, train_dataset, val_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nEpoch {epoch + 1} - Train samples: {tf.data.experimental.cardinality(self.train_dataset)}\")\n",
    "        logging.debug(f\"Epoch {epoch + 1} - Val samples: {tf.data.experimental.cardinality(self.val_dataset)}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            logging.debug(f\"\\nEpoch {epoch + 1} - Train accuracy: {logs.get('accuracy', 'N/A'):.4f}\")\n",
    "            logging.debug(f\"Epoch {epoch + 1} - Val accuracy: {logs.get('val_accuracy', 'N/A'):.4f}\")\n",
    "\n",
    "class DebugCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nStarting epoch {epoch + 1}\\n\")\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if batch % 100 == 0:\n",
    "            logging.debug(f\"\\nStarting batch {batch}\\n\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nEnd of epoch {epoch + 1}\\n\")\n",
    "        if logs:\n",
    "            for key, value in logs.items():\n",
    "                logging.debug(f\"{key}: {value}\")\n",
    "        logging.debug(\"\\n--------------------\\n\")\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, config):\n",
    "        logging.debug(\"DataGenerator initialization starting.\")\n",
    "        self.config = config\n",
    "        self.batch_size = config['data']['batch_size']\n",
    "        self.target_size = tuple(config['data']['target_size'])\n",
    "        self.preprocessing_function = PREPROCESSING_FUNCTIONS[config['data']['preprocessing_function']]\n",
    "        self.augmentation_params = config['augmentation']\n",
    "        self.pre_split = config['data'].get('pre_split', True)\n",
    "\n",
    "        logging.debug(f'DG batch_size = {self.batch_size}')\n",
    "        logging.debug(f'DG target_zie = {self.target_size}')\n",
    "        logging.debug(f'DG preprocessing_fuction = {self.preprocessing_function}')\n",
    "        logging.debug(f'DG augmentation_params = {self.augmentation_params}')\n",
    "        logging.debug(f'DG pre_split = {self.pre_split}')\n",
    "\n",
    "        # Create data augmentation and rescaling layers\n",
    "        self.data_augmentation = self.create_data_augmentation()\n",
    "        self.rescale_layer = self.create_rescale_layer()\n",
    "\n",
    "        if self.pre_split:\n",
    "            logging.debug(\"DG Calling load_pre_split_data function.\")\n",
    "            self.load_pre_split_data()\n",
    "        else:\n",
    "            self.load_and_split_data()\n",
    "\n",
    "    def load_pre_split_data(self):\n",
    "        # Paths for pre-split data\n",
    "        logging.debug(\"DG LPSD Starting load_pre_split_data function.\")\n",
    "        self.train_path = self.config['data']['train_path']\n",
    "        logging.debug(f\"DG LPSD Train path: {self.train_path}\")\n",
    "        self.test_path = self.config['data']['test_path']\n",
    "        logging.debug(f\"DG LPSD Test path: {self.test_path}\")\n",
    "\n",
    "        # Validate paths\n",
    "        if not os.path.exists(self.train_path):\n",
    "            raise FileNotFoundError(f\"DG LPSD Training path not found: {self.train_path}\")\n",
    "        if not os.path.exists(self.test_path):\n",
    "            raise FileNotFoundError(f\"DG LPSD Testing path not found: {self.test_path}\")\n",
    "\n",
    "        # Load datasets\n",
    "        logging.debug(\"DG LPSD Loading train_dataset datasets\")\n",
    "        self.train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.train_path,\n",
    "            label_mode='categorical',\n",
    "            batch_size=None,  # Load as individual samples\n",
    "            image_size=self.target_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        logging.debug(\"DG LPSD Loading test_dataset datasets\")  \n",
    "        self.test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.test_path,\n",
    "            label_mode='categorical',\n",
    "            batch_size=None,\n",
    "            image_size=self.target_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        train_dataset_unbatched = self.train_dataset\n",
    "        test_dataset_unbatched = self.test_dataset\n",
    "\n",
    "        self.class_names = self.train_dataset.class_names\n",
    "        logging.debug(f\"DG LPSD Class names: {self.class_names}\")\n",
    "\n",
    "        # Prepare datasets\n",
    "        logging.debug(\"DG LPSD Preparing datasets\")\n",
    "        self.train_dataset = self.prepare_dataset(self.train_dataset, augment=True)\n",
    "        logging.debug(\"DG LPSD Train dataset prepared.\")\n",
    "        self.val_dataset = self.prepare_dataset(self.test_dataset, augment=False)\n",
    "        logging.debug(\"DG LPSD Val dataset prepared.\")\n",
    "        self.test_dataset = self.val_dataset  # Use the validation dataset for testing if appropriate\n",
    "        logging.debug(\"DG LPSD Test dataset prepared.\")\n",
    "\n",
    "        # Compute sample counts\n",
    "        self.train_sample_count = tf.data.experimental.cardinality(train_dataset_unbatched).numpy()\n",
    "        self.val_sample_count = tf.data.experimental.cardinality(test_dataset_unbatched).numpy()\n",
    "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
    "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
    "        \n",
    "        # Compute class counts directly from the dataset's file paths\n",
    "        self.class_counts = self.count_samples_from_directories(self.train_path, self.class_names)\n",
    "        \n",
    "        logging.debug(f'DG LPSD Train path: {self.train_path}')\n",
    "        logging.debug(f'DG LPSD Test path: {self.test_path}')\n",
    "        logging.debug(f'DG LPSD Batch size: {self.batch_size}')\n",
    "        logging.debug(f'DG LPSD Target size: {self.target_size}')\n",
    "        logging.debug(f'DG LPSD steps_per_epoch: {self.steps_per_epoch}')\n",
    "        logging.debug(f'DG LPSD validation_steps: {self.validation_steps}')\n",
    "        logging.debug(f'DG LPSD Preprocessing function: {self.preprocessing_function}')\n",
    "        logging.debug(f'DG LPSD Augmentation params: {self.augmentation_params}')\n",
    "        logging.debug(f'DG LPSD Class counts: {self.class_counts}')\n",
    "\n",
    "    def count_samples_from_directories(self, dataset_path, class_names):\n",
    "        import os\n",
    "        counts = {}\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(dataset_path, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                counts[class_name] = len([\n",
    "                    fname for fname in os.listdir(class_dir)\n",
    "                    if os.path.isfile(os.path.join(class_dir, fname))\n",
    "                ])\n",
    "            else:\n",
    "                counts[class_name] = 0\n",
    "        return counts\n",
    "\n",
    "    def load_and_split_data(self):\n",
    "        # Get class names and indices\n",
    "        logging.debug(f'DG LASD Getting Class Names.')\n",
    "        self.class_names = sorted(os.listdir(self.config['data']['dataset_path']))\n",
    "        logging.debug(f'DG LASD Class Names: {self.class_names}')\n",
    "        class_indices = {name: index for index, name in enumerate(self.class_names)}\n",
    "        logging.debug(f'DG LASD Class Indices: {class_indices}')\n",
    "\n",
    "        # Collect file paths and labels\n",
    "        file_paths = []\n",
    "        labels = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(self.config['data']['dataset_path'], class_name)\n",
    "            class_files = glob.glob(os.path.join(class_dir, '*'))\n",
    "            file_paths.extend(class_files)\n",
    "            labels.extend([class_indices[class_name]] * len(class_files))\n",
    "\n",
    "        file_paths = np.array(file_paths)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # First split: train and temp (val + test)\n",
    "        logging.debug(f'DG LASD Splitting data into train and temp sets.')\n",
    "        train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "            file_paths, labels,\n",
    "            test_size=0.3,\n",
    "            stratify=labels,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Second split: validation and test\n",
    "        logging.debug(f'DG LASD Splitting temp data into val and test sets.')\n",
    "        val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "            temp_paths, temp_labels,\n",
    "            test_size=0.5,\n",
    "            stratify=temp_labels,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Place Counter statements here to check class distributions\n",
    "        # Mapping indices back to class names for readability\n",
    "        index_to_class = {index: name for name, index in class_indices.items()}\n",
    "\n",
    "        # Training set class distribution\n",
    "        train_class_counts = Counter(train_labels)\n",
    "        train_class_counts_named = {index_to_class[k]: v for k, v in train_class_counts.items()}\n",
    "        print(\"Training class distribution:\", train_class_counts_named)\n",
    "\n",
    "        # Validation set class distribution\n",
    "        val_class_counts = Counter(val_labels)\n",
    "        val_class_counts_named = {index_to_class[k]: v for k, v in val_class_counts.items()}\n",
    "        print(\"Validation class distribution:\", val_class_counts_named)\n",
    "\n",
    "        # Test set class distribution\n",
    "        test_class_counts = Counter(test_labels)\n",
    "        test_class_counts_named = {index_to_class[k]: v for k, v in test_class_counts.items()}\n",
    "        print(\"Test class distribution:\", test_class_counts_named)\n",
    "\n",
    "        # Create datasets from file paths and labels\n",
    "        logging.debug(f'DG LASD Creating datasets from file paths and labels.')\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "        # Map function to load images from file paths\n",
    "        def load_image(file_path, label):\n",
    "            # Read the image from file\n",
    "            image = tf.io.read_file(file_path)\n",
    "            # Decode the image data\n",
    "            image = tf.image.decode_png(image, channels=3)\n",
    "            # Convert image to float32 and resize\n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            image = tf.image.resize(image, self.target_size)\n",
    "            # One-hot encode the label\n",
    "            label = tf.one_hot(label, depth=len(self.class_names))\n",
    "            return image, label\n",
    "\n",
    "        # Apply the load_image function\n",
    "        logging.debug(f'DG LASD Mapping load_image function to datasets.')\n",
    "        train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        val_dataset = val_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        # Prepare datasets\n",
    "        logging.debug(f'DG LASD Preparing datasets.')\n",
    "        self.train_dataset = self.prepare_dataset(train_dataset, augment=True)\n",
    "        self.val_dataset = self.prepare_dataset(val_dataset, augment=False)\n",
    "        self.test_dataset = self.prepare_dataset(test_dataset, augment=False)\n",
    "\n",
    "        # Compute sample counts\n",
    "        logging.debug(f'DG LASD Computing sample counts.')\n",
    "        self.train_sample_count = len(train_paths)\n",
    "        self.val_sample_count = len(val_paths)\n",
    "        self.test_sample_count = len(test_paths)\n",
    "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
    "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
    "        self.test_steps = math.ceil(self.test_sample_count / self.batch_size)\n",
    "        logging.debug(f'DG LASD Train sample count: {self.train_sample_count}')\n",
    "        logging.debug(f'DG LASD Val sample count: {self.val_sample_count}')\n",
    "        logging.debug(f'DG LASD Test sample count: {self.test_sample_count}')\n",
    "        logging.debug(f'DG LASD Steps per epoch: {self.steps_per_epoch}')\n",
    "        logging.debug(f'DG LASD Validation steps: {self.validation_steps}')\n",
    "        logging.debug(f'DG LASD Test steps: {self.test_steps}')\n",
    "\n",
    "\n",
    "    def split_dataset(self):\n",
    "        # Calculate dataset size\n",
    "        dataset_size = tf.data.experimental.cardinality(self.dataset).numpy()\n",
    "\n",
    "        # Define split sizes\n",
    "        train_size = int(0.7 * dataset_size)\n",
    "        val_size = int(0.15 * dataset_size)\n",
    "        test_size = dataset_size - train_size - val_size\n",
    "\n",
    "        # Shuffle and split\n",
    "        self.dataset = self.dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "        train_dataset = self.dataset.take(train_size)\n",
    "        val_test_dataset = self.dataset.skip(train_size)\n",
    "        val_dataset = val_test_dataset.take(val_size)\n",
    "        test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "        logging.debug(f\"DG SD Dataset size: {dataset_size}\")\n",
    "        logging.debug(f\"DG SD Training size: {train_size}\")\n",
    "        logging.debug(f\"DG SD Validation size: {val_size}\")\n",
    "        logging.debug(f\"DG SD Test size: {test_size}\")\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    def prepare_dataset(self, dataset, augment):\n",
    "        if augment:\n",
    "            try:\n",
    "                dataset = dataset.map(self.augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                dataset = dataset.shuffle(1000).repeat()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"An error occurred trying to prepare dataset with augment true: {e}\")\n",
    "                logging.debug(traceback.format_exc())\n",
    "        else:\n",
    "            dataset = dataset.map(self.normalize_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            dataset = dataset.cache()\n",
    "        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_dataset_size(self, dataset):\n",
    "        return tf.data.experimental.cardinality(dataset).numpy() * self.batch_size\n",
    "\n",
    "    def create_data_augmentation(self):\n",
    "        layers = []\n",
    "        augmentation_params = self.augmentation_params\n",
    "\n",
    "        # Apply augmentations based on parameters\n",
    "        if augmentation_params.get('rotation_range'):\n",
    "            rotation_range = augmentation_params['rotation_range']\n",
    "            factor = rotation_range / 360.0  # Convert degrees to fraction of full circle\n",
    "            layers.append(RandomRotation(factor=(-factor, factor)))\n",
    "\n",
    "        if augmentation_params.get('horizontal_flip'):\n",
    "            layers.append(RandomFlip(mode='horizontal'))\n",
    "\n",
    "        if augmentation_params.get('vertical_flip'):\n",
    "            layers.append(RandomFlip(mode='vertical'))\n",
    "\n",
    "        if augmentation_params.get('zoom_range'):\n",
    "            zoom = augmentation_params['zoom_range']\n",
    "            layers.append(RandomZoom(height_factor=(-zoom, zoom), width_factor=(-zoom, zoom)))\n",
    "\n",
    "        if augmentation_params.get('width_shift_range') or augmentation_params.get('height_shift_range'):\n",
    "            width_shift = augmentation_params.get('width_shift_range', 0.0)\n",
    "            height_shift = augmentation_params.get('height_shift_range', 0.0)\n",
    "            layers.append(RandomTranslation(height_factor=height_shift, width_factor=width_shift))\n",
    "\n",
    "        if augmentation_params.get('brightness_range'):\n",
    "            brightness = augmentation_params['brightness_range']\n",
    "            layers.append(RandomBrightness(factor=brightness))\n",
    "\n",
    "        if augmentation_params.get('contrast_range'):\n",
    "            contrast = augmentation_params['contrast_range']\n",
    "            layers.append(RandomContrast(factor=contrast))\n",
    "            \n",
    "        if not layers:\n",
    "            layers.append(tf.keras.layers.Lambda(lambda x: x))\n",
    "\n",
    "        data_augmentation = tf.keras.Sequential(layers)\n",
    "        return data_augmentation\n",
    "\n",
    "    def create_rescale_layer(self):\n",
    "        # Define which preprocessing functions expect which input ranges\n",
    "        preprocess_0_255 = [resnet_preprocess, vgg_preprocess]\n",
    "        preprocess_0_1 = [efficientnet_preprocess]\n",
    "        preprocess_minus1_1 = [mobilenet_preprocess, inception_preprocess]\n",
    "\n",
    "        if self.preprocessing_function in preprocess_0_255:\n",
    "            # No rescaling needed; images are already in [0, 255]\n",
    "            return None\n",
    "        elif self.preprocessing_function in preprocess_0_1:\n",
    "            # Rescaling needed to bring images to [0, 1]\n",
    "            return Rescaling(1./255)\n",
    "        elif self.preprocessing_function in preprocess_minus1_1:\n",
    "            # Rescaling needed to bring images to [0, 1]; preprocessing function will scale to [-1, 1]\n",
    "            return Rescaling(1./255)\n",
    "        else:\n",
    "            # Default to rescaling to [0, 1]\n",
    "            return Rescaling(1./255)\n",
    "\n",
    "    def augment(self, images, labels):\n",
    "        # Different preprocessing functions expect different ranges of images after augmentation\n",
    "        # ResNet50V2 and VGG16: Expect images in the range [0, 255] with mean subtraction.\n",
    "        # InceptionV3 and MobileNetV2: Expect images scaled to [-1, 1].\n",
    "        # EfficientNetB0: Expects images scaled to [0, 1].\n",
    "        \n",
    "        images = tf.cast(images, tf.float32)\n",
    "\n",
    "        # Apply rescaling if necessary\n",
    "        if self.rescale_layer:\n",
    "            images = self.rescale_layer(images)\n",
    "\n",
    "        # Apply data augmentation\n",
    "        images = self.data_augmentation(images)\n",
    "\n",
    "        # Apply preprocessing function\n",
    "        images = self.preprocessing_function(images)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def normalize_and_preprocess(self, images, labels):\n",
    "        images = tf.cast(images, tf.float32)\n",
    "\n",
    "        # Apply rescaling if necessary\n",
    "        if self.rescale_layer:\n",
    "            images = self.rescale_layer(images)\n",
    "\n",
    "        # Apply preprocessing function\n",
    "        images = self.preprocessing_function(images)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def create_datasets(self):\n",
    "        return None\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, config, num_classes, best_hyperparameters=None):\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.best_hyperparameters = best_hyperparameters\n",
    "\n",
    "    def build(self, hp):\n",
    "        if self.best_hyperparameters:\n",
    "            hp = self.best_hyperparameters  # Use best hyperparameters if available\n",
    "        architecture = ARCHITECTURES[self.config['model']['architecture']]\n",
    "        input_shape = tuple(self.config['model']['input_shape'])\n",
    "\n",
    "        base_model = architecture(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "\n",
    "        # Optionally unfreeze layers based on config\n",
    "        for layer in base_model.layers[-10:]:\n",
    "            layer.trainable = True  # You can make this a hyperparameter if needed\n",
    "\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = base_model(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "        # Tunable hyperparameters with defaults from config.yaml\n",
    "        dense_units = hp.Int('dense_units',\n",
    "                             min_value=self.config['hyperparameters']['dense_units']['min'],\n",
    "                             max_value=self.config['hyperparameters']['dense_units']['max'],\n",
    "                             step=self.config['hyperparameters']['dense_units']['step'],\n",
    "                             default=self.config['hyperparameters']['dense_units']['default'])\n",
    "\n",
    "        dropout_rate = hp.Float('dropout_rate',\n",
    "                                min_value=float(self.config['hyperparameters']['dropout_rate']['min']),\n",
    "                                max_value=float(self.config['hyperparameters']['dropout_rate']['max']),\n",
    "                                step=0.1,\n",
    "                                default=float(self.config['hyperparameters']['dropout_rate']['default']))\n",
    "\n",
    "        x = Dense(dense_units)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(dense_units // 2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = tf.keras.layers.ReLU()(x)\n",
    "\n",
    "        output = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "        # Compile the model\n",
    "        learning_rate = hp.Float('learning_rate',\n",
    "                                 min_value=float(self.config['hyperparameters']['learning_rate']['min']),\n",
    "                                 max_value=float(self.config['hyperparameters']['learning_rate']['max']),\n",
    "                                 sampling='log',\n",
    "                                 default=float(self.config['hyperparameters']['learning_rate']['default']))\n",
    "\n",
    "        optimizer_choice = hp.Choice('optimizer',\n",
    "                                     values=self.config['hyperparameters']['optimizer']['choices'],\n",
    "                                     default=self.config['hyperparameters']['optimizer']['default'])\n",
    "\n",
    "        if optimizer_choice == 'adam':\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "        elif optimizer_choice == 'sgd':\n",
    "            optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "        metrics = ['accuracy'] + [METRICS[metric] for metric in self.config['model']['additional_metrics']]\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=metrics)\n",
    "        return model\n",
    "\n",
    "def setup_gpu(gpu_config):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Log the number of GPUs available\n",
    "            logging.debug(f\"GPU setup complete. Found {len(gpus)} GPU(s).\")\n",
    "\n",
    "            # Optionally, you can log more details about each GPU\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                logging.debug(f\"GPU {i}: {gpu}\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"GPU setup failed: {e}\")\n",
    "    else:\n",
    "        logging.warning(\"No GPUs found. The model will run on CPU.\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def setup_datasets(config):\n",
    "    try:\n",
    "        data_generator = DataGenerator(config)\n",
    "        logging.debug(\"DataGenerator initialized successfully.\")\n",
    "        train_dataset, test_dataset, steps_per_epoch, validation_steps = data_generator.get_data_generators()\n",
    "        class_names = data_generator.class_names  # Use class names from data generator\n",
    "        logging.debug(f\"Class names: {class_names}\")\n",
    "\n",
    "        return train_dataset, test_dataset, steps_per_epoch, validation_steps, class_names\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Dataset setup failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_callbacks(config, train_dataset, test_dataset, validation_steps, for_tuning=False):\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=config['training']['patience'], restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=config['training']['model_checkpoint_path'], save_best_only=True)\n",
    "    ]\n",
    "    if not for_tuning:\n",
    "        # Include custom callbacks only when not tuning\n",
    "        callbacks.extend([\n",
    "            AccuracyCallback(target_accuracy=config['training']['target_accuracy']),\n",
    "            CustomValidationCallback(test_dataset, validation_steps),\n",
    "            DebugCallback(),\n",
    "            DatasetLogger(train_dataset, test_dataset)\n",
    "        ])\n",
    "    return callbacks\n",
    "\n",
    "def compute_class_weights_from_counts(class_counts, class_names):\n",
    "    total_samples = sum(class_counts.values())\n",
    "    class_weight_dict = {}\n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        count = class_counts.get(class_name, 0)\n",
    "        if count > 0:\n",
    "            class_weight_dict[idx] = total_samples / (len(class_counts) * count)\n",
    "        else:\n",
    "            class_weight_dict[idx] = 0.0  # Handle classes with zero samples\n",
    "    return class_weight_dict\n",
    "\n",
    "def save_best_hyperparameters(best_hps, filepath='best_hyperparameters.json'):\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(best_hps.values, f)\n",
    "\n",
    "def load_best_hyperparameters(filepath='best_hyperparameters.json'):\n",
    "    with open(filepath, 'r') as f:\n",
    "        hps_dict = json.load(f)\n",
    "    hp = HyperParameters()\n",
    "    for key, value in hps_dict.items():\n",
    "        hp.Fixed(key, value)\n",
    "    return hp\n",
    "\n",
    "def convert_pgm_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Create corresponding subdirectories in output_dir\n",
    "        rel_path = os.path.relpath(root, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, rel_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.pgm'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    with Image.open(filepath) as img:\n",
    "                        img = img.convert('RGB')  # Convert to RGB\n",
    "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                        output_path = os.path.join(output_subdir, new_filename)\n",
    "                        img.save(output_path, 'PNG')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {filepath}: {e}\")\n",
    "\n",
    "# Usage\n",
    "input_dir = 'att_faces'  # Your current dataset path with PGM files\n",
    "output_dir = 'att_faces_png'  # New dataset path for PNG files\n",
    "convert_pgm_to_png(input_dir, output_dir)\n",
    "\n",
    "def main(config_path):\n",
    "    # Load the configuration\n",
    "    config = load_config(config_path)\n",
    "    logging.debug(f\"Loaded configuration: {config}\")\n",
    "    performance_tuning = config.get('tuning', {}).get('perform_tuning', True)\n",
    "    logging.debug(f\"Perform tuning: {performance_tuning}\")\n",
    "\n",
    "    # Set up GPU if available\n",
    "    setup_gpu(config.get('gpu', {}))\n",
    "    logging.debug(\"Completed GPU setup.\")\n",
    "\n",
    "    # Load environment variables\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        # drive.mount('/content/drive')\n",
    "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "        DATASET_PATH = os.getenv('COLAB_DATASET_PATH')\n",
    "        logging.debug(\"Running in Colab environment\")\n",
    "    except ImportError:\n",
    "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "        DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
    "        logging.debug(\"Running in local environment\")\n",
    "\n",
    "    # Update the dataset paths based on whether the data is pre-split or not\n",
    "    pre_split = config['data'].get('pre_split', True)\n",
    "    if pre_split:\n",
    "        # For pre-split data\n",
    "        train_path = os.path.join(DATASET_PATH, config['data']['train_dir'])\n",
    "        test_path = os.path.join(DATASET_PATH, config['data']['test_dir'])\n",
    "        config['data']['train_path'] = train_path\n",
    "        config['data']['test_path'] = test_path\n",
    "        logging.debug(f\"Train path: {train_path}\")\n",
    "        logging.debug(f\"Test path: {test_path}\")\n",
    "    else:\n",
    "        # For single directory data\n",
    "        dataset_path = os.path.join(DATASET_PATH, config['data']['dataset_dir'])\n",
    "        config['data']['dataset_path'] = dataset_path\n",
    "        logging.debug(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "    try:\n",
    "        # Initialize DataGenerator\n",
    "        data_generator = DataGenerator(config)\n",
    "        logging.debug(\"DataGenerator initialized successfully.\")\n",
    "        train_dataset = data_generator.train_dataset\n",
    "        val_dataset = data_generator.val_dataset\n",
    "        test_dataset = data_generator.test_dataset\n",
    "        steps_per_epoch = data_generator.steps_per_epoch\n",
    "        validation_steps = data_generator.validation_steps\n",
    "        class_names = data_generator.class_names\n",
    "        logging.debug(f\"Class names: {class_names}\")\n",
    "\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "        # Compute class weights using training data\n",
    "        logging.debug(\"Main Function Counting Classes and Computing Weights\")\n",
    "        class_counts = data_generator.class_counts\n",
    "        logging.debug(f\"Class counts: {class_counts}\")\n",
    "        class_weight_dict = compute_class_weights_from_counts(class_counts, class_names)\n",
    "        logging.debug(f\"Computed class weights: {class_weight_dict}\")\n",
    "\n",
    "        if performance_tuning:\n",
    "            # Instantiate the hypermodel\n",
    "            hypermodel = MyHyperModel(config, num_classes)\n",
    "            logging.debug(\"HyperModel instantiated successfully.\")\n",
    "\n",
    "            # Get callbacks for tuning (only deepcopyable ones)\n",
    "            tuning_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=True)\n",
    "\n",
    "            # Set up the tuner\n",
    "            tuner = RandomSearch(\n",
    "                hypermodel,\n",
    "                objective='val_accuracy',\n",
    "                max_trials=config['tuner']['max_trials'],\n",
    "                executions_per_trial=config['tuner']['executions_per_trial'],\n",
    "                directory='hyperparameter_tuning',\n",
    "                project_name='keras_tuner_project'\n",
    "            )\n",
    "            logging.debug(\"Keras Tuner initialized successfully.\")\n",
    "\n",
    "            # Run the hyperparameter search\n",
    "            tuner.search(\n",
    "                train_dataset,\n",
    "                epochs=config['training']['epochs'],\n",
    "                validation_data=val_dataset,\n",
    "                callbacks=tuning_callbacks,\n",
    "                class_weight=class_weight_dict,\n",
    "                steps_per_epoch=steps_per_epoch\n",
    "                # No need to specify validation_steps; Keras will handle it automatically\n",
    "            )\n",
    "\n",
    "            # Get the optimal hyperparameters\n",
    "            best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "            logging.debug(f\"\"\"\n",
    "            The hyperparameter search is complete.\n",
    "            Best learning rate: {best_hps.get('learning_rate')}\n",
    "            Best dense units: {best_hps.get('dense_units')}\n",
    "            Best dropout rate: {best_hps.get('dropout_rate')}\n",
    "            Best optimizer: {best_hps.get('optimizer')}\n",
    "            \"\"\")\n",
    "\n",
    "            save_best_hyperparameters(best_hps)\n",
    "            logging.debug(\"Best hyperparameters saved to file.\")\n",
    "\n",
    "            # Build the best model\n",
    "            model = tuner.hypermodel.build(best_hps)\n",
    "            logging.debug(\"Best model built with optimal hyperparameters.\")\n",
    "        else:\n",
    "            # Load the best hyperparameters from file\n",
    "            best_hps = load_best_hyperparameters()\n",
    "            logging.debug(\"Loaded best hyperparameters from file.\")\n",
    "\n",
    "            # Instantiate the hypermodel with best hyperparameters\n",
    "            hypermodel = MyHyperModel(config, num_classes, best_hyperparameters=best_hps)\n",
    "            model = hypermodel.build(hp=None)  # hp is None, so it uses best_hyperparameters\n",
    "            logging.debug(\"Model built with loaded hyperparameters.\")\n",
    "\n",
    "        # Get all callbacks including custom ones for final training\n",
    "        final_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=False)\n",
    "\n",
    "        # Retrain the model with the best hyperparameters\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=config['training']['epochs'],\n",
    "            validation_data=val_dataset,\n",
    "            callbacks=final_callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            steps_per_epoch=steps_per_epoch\n",
    "            # No need to specify validation_steps; Keras will handle it automatically\n",
    "        )\n",
    "\n",
    "        logging.debug(\"Model retrained with optimal hyperparameters.\")\n",
    "        logging.debug(\"Final evaluation:\")\n",
    "        final_evaluation = model.evaluate(test_dataset)\n",
    "        logging.debug(f\"Final evaluation metrics: {final_evaluation}\")\n",
    "\n",
    "        return history, model, class_names, config['data']['target_size'], config['data']['preprocessing_function'], config['model']['architecture']\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        logging.debug(traceback.format_exc())\n",
    "\n",
    "        return None, None, None, None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded configuration: {'data': {'pre_split': False, 'dataset_path': 'dataset', 'dataset_dir': 'att_faces', 'train_dir': 'train_dataset', 'test_dir': 'test_dataset', 'validation_dir': 'validation_dataset', 'batch_size': 32, 'target_size': [128, 128], 'preprocessing_function': 'resnet_preprocess'}, 'augmentation': {'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.1}, 'model': {'architecture': 'ResNet50V2', 'input_shape': [128, 128, 3], 'initial_learning_rate': 0.001, 'decay_steps': 100, 'decay_rate': 0.96, 'dense_units': 512, 'dropout_rate': 0.5, 'additional_metrics': ['Precision', 'Recall', 'AUC']}, 'training': {'epochs': 1, 'patience': 5, 'target_accuracy': 0.99, 'find_lr': False, 'pretrain_model_eval': True, 'model_checkpoint_path': 'checkpoint.h5.keras'}, 'hyperparameters': {'learning_rate': {'min': '1e-5', 'max': '1e-3', 'default': 1.0294583766002546e-05}, 'dense_units': {'min': 128, 'max': 1024, 'step': 128, 'default': 128}, 'dropout_rate': {'min': 0.0, 'max': 0.7, 'default': 0.1}, 'optimizer': {'choices': ['adam', 'sgd'], 'default': 'adam'}}, 'tuning': {'perform_tuning': False}, 'tuner': {'max_trials': 5, 'executions_per_trial': 1}, 'visualization': {'figure_size': [12, 4], 'history_plot_path': 'history_plot.png'}, 'gpu': {'memory_growth': True, 'allow_growth': True}}\n",
      "Perform tuning: False\n",
      "No GPUs found. The model will run on CPU.\n",
      "Completed GPU setup.\n",
      "Running in local environment\n",
      "Dataset path: /Users/toddwalters/Development/data/advDLandCV/projects/1697032566/att_faces\n",
      "DataGenerator initialization starting.\n",
      "DG batch_size = 32\n",
      "DG target_zie = (128, 128)\n",
      "DG preprocessing_fuction = <function preprocess_input at 0x14fa98b80>\n",
      "DG augmentation_params = {'rotation_range': 20, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.1}\n",
      "DG pre_split = False\n",
      "DG LASD Getting Class Names.\n",
      "DG LASD Class Names: ['.DS_Store', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
      "DG LASD Class Indices: {'.DS_Store': 0, 's1': 1, 's10': 2, 's11': 3, 's12': 4, 's13': 5, 's14': 6, 's15': 7, 's16': 8, 's17': 9, 's18': 10, 's19': 11, 's2': 12, 's20': 13, 's21': 14, 's22': 15, 's23': 16, 's24': 17, 's25': 18, 's26': 19, 's27': 20, 's28': 21, 's29': 22, 's3': 23, 's30': 24, 's31': 25, 's32': 26, 's33': 27, 's34': 28, 's35': 29, 's36': 30, 's37': 31, 's38': 32, 's39': 33, 's4': 34, 's40': 35, 's5': 36, 's6': 37, 's7': 38, 's8': 39, 's9': 40}\n",
      "DG LASD Splitting data into train and temp sets.\n",
      "DG LASD Splitting temp data into val and test sets.\n",
      "DG LASD Creating datasets from file paths and labels.\n",
      "DG LASD Mapping load_image function to datasets.\n",
      "DG LASD Preparing datasets.\n",
      "DG LASD Computing sample counts.\n",
      "DG LASD Train sample count: 280\n",
      "DG LASD Val sample count: 60\n",
      "DG LASD Test sample count: 60\n",
      "DG LASD Steps per epoch: 9\n",
      "DG LASD Validation steps: 2\n",
      "DG LASD Test steps: 2\n",
      "DataGenerator initialized successfully.\n",
      "Class names: ['.DS_Store', 's1', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's2', 's20', 's21', 's22', 's23', 's24', 's25', 's26', 's27', 's28', 's29', 's3', 's30', 's31', 's32', 's33', 's34', 's35', 's36', 's37', 's38', 's39', 's4', 's40', 's5', 's6', 's7', 's8', 's9']\n",
      "Main Function Counting Classes and Computing Weights\n",
      "An error occurred: 'DataGenerator' object has no attribute 'class_counts'\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/1c/h_10706j24qc8qjh7x3yy0g40000gn/T/ipykernel_86868/4113955012.py\", line 763, in main\n",
      "    class_counts = data_generator.class_counts\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'DataGenerator' object has no attribute 'class_counts'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class distribution: {'s23': 7, 's12': 7, 's19': 7, 's2': 7, 's33': 7, 's31': 7, 's10': 7, 's26': 7, 's27': 7, 's20': 7, 's14': 7, 's5': 7, 's37': 7, 's16': 7, 's13': 7, 's34': 7, 's1': 7, 's36': 7, 's7': 7, 's15': 7, 's17': 7, 's40': 7, 's3': 7, 's38': 7, 's8': 7, 's32': 7, 's35': 7, 's30': 7, 's28': 7, 's18': 7, 's11': 7, 's6': 7, 's9': 7, 's24': 7, 's4': 7, 's21': 7, 's22': 7, 's39': 7, 's25': 7, 's29': 7}\n",
      "Validation class distribution: {'s5': 1, 's4': 2, 's9': 2, 's7': 2, 's20': 2, 's27': 2, 's1': 2, 's40': 2, 's13': 2, 's31': 2, 's21': 2, 's34': 2, 's19': 1, 's16': 1, 's24': 2, 's28': 1, 's11': 1, 's2': 1, 's26': 1, 's17': 2, 's15': 2, 's18': 2, 's6': 1, 's32': 2, 's39': 1, 's12': 1, 's36': 1, 's10': 1, 's38': 2, 's37': 1, 's25': 2, 's22': 1, 's33': 2, 's35': 1, 's30': 1, 's23': 2, 's29': 1, 's3': 1, 's14': 1, 's8': 1}\n",
      "Test class distribution: {'s28': 2, 's36': 2, 's17': 1, 's11': 2, 's5': 2, 's3': 2, 's37': 2, 's22': 2, 's14': 2, 's38': 1, 's33': 1, 's31': 1, 's35': 2, 's4': 1, 's19': 2, 's2': 2, 's21': 1, 's40': 1, 's6': 2, 's10': 2, 's12': 2, 's16': 2, 's25': 1, 's27': 1, 's30': 2, 's29': 2, 's18': 1, 's23': 1, 's39': 2, 's13': 1, 's9': 1, 's34': 1, 's26': 2, 's1': 1, 's32': 1, 's24': 1, 's8': 2, 's15': 1, 's20': 1, 's7': 1}\n"
     ]
    }
   ],
   "source": [
    "history, compiled_model, class_names, target_size, preprocessing_function, ptm_name = main('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1. <a id='toc1_4_2_1_'></a>[**Thing A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.1. <a id='toc1_4_2_1_1_'></a>[**Thing A.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.2. <a id='toc1_4_2_1_2_'></a>[**Thing A.B**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.3. <a id='toc1_4_2_1_3_'></a>[**Thing A.C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.4. <a id='toc1_4_2_1_4_'></a>[**Thing A.D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. <a id='toc1_4_3_'></a>[**Part 3**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.1. <a id='toc1_4_3_1_'></a>[**Thing A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.2. <a id='toc1_4_3_2_'></a>[**Thing B**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.1. <a id='toc1_4_3_2_1_'></a>[**Thing B.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.2. <a id='toc1_4_3_2_2_'></a>[**Thing B.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.3. <a id='toc1_4_3_2_3_'></a>[**Thing B.C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.4. <a id='toc1_4_3_2_4_'></a>[**Thing B.D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.3. <a id='toc1_4_3_3_'></a>[**Thing C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.4. <a id='toc1_4_3_4_'></a>[**Thing D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
