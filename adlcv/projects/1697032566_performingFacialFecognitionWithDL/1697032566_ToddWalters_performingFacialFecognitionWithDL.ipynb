{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [**Performing Facial Recognition with Deep Learning**](#toc1_)    \n",
    "  - 1.1. [**Project Context**](#toc1_1_)    \n",
    "  - 1.2. [**Project Objectives**](#toc1_2_)    \n",
    "  - 1.3. [**Project Dataset Description**](#toc1_3_)    \n",
    "  - 1.4. [**Project Analysis Steps To Perform**](#toc1_4_)    \n",
    "    - 1.4.1. [**Preliminary analysis**](#toc1_4_1_)    \n",
    "      - 1.4.1.1. [**Import Modules and Set Default Environment Variables**](#toc1_4_1_1_)    \n",
    "      - 1.4.1.2. [**Look for corrupt files [Optional]**   ](#toc1_4_1_2_)    \n",
    "      - 1.4.1.3. [**Rename Files [Optional]**    ](#toc1_4_1_3_)    \n",
    "      - 1.4.1.4. [**Plot Sample Images**](#toc1_4_1_4_)    \n",
    "      - 1.4.1.5. [**Create a validation framework and split the data into train, test, and validation datasets**](#toc1_4_1_5_)    \n",
    "      - 1.4.1.6. [**Perform necessary transformations to prepare the data for input to the CNN model**](#toc1_4_1_6_)    \n",
    "      - 1.4.1.7. [**Thing G**](#toc1_4_1_7_)    \n",
    "      - 1.4.1.8. [**Thing H**](#toc1_4_1_8_)    \n",
    "      - 1.4.1.9. [**Thing I**](#toc1_4_1_9_)    \n",
    "      - 1.4.1.10. [**Thing J**](#toc1_4_1_10_)    \n",
    "      - 1.4.1.11. [**Thing K**](#toc1_4_1_11_)    \n",
    "      - 1.4.1.12. [**Thing L**](#toc1_4_1_12_)    \n",
    "    - 1.4.2. [**Part 2**](#toc1_4_2_)    \n",
    "      - 1.4.2.1. [**Thing A**](#toc1_4_2_1_)    \n",
    "        - 1.4.2.1.1. [**Thing A.A**](#toc1_4_2_1_1_)    \n",
    "        - 1.4.2.1.2. [**A.B**](#toc1_4_2_1_2_)    \n",
    "        - 1.4.2.1.3. [**Thing A.C**](#toc1_4_2_1_3_)    \n",
    "        - 1.4.2.1.4. [**Thing A.D**](#toc1_4_2_1_4_)    \n",
    "    - 1.4.3. [**Part 3**](#toc1_4_3_)    \n",
    "      - 1.4.3.1. [**Thing A**](#toc1_4_3_1_)    \n",
    "      - 1.4.3.2. [**Thing B**](#toc1_4_3_2_)    \n",
    "        - 1.4.3.2.1. [**Thing B.A**](#toc1_4_3_2_1_)    \n",
    "        - 1.4.3.2.2. [**Thing B.A**](#toc1_4_3_2_2_)    \n",
    "        - 1.4.3.2.3. [**Thing B.C**](#toc1_4_3_2_3_)    \n",
    "        - 1.4.3.2.4. [**Thing B.D**](#toc1_4_3_2_4_)    \n",
    "      - 1.4.3.3. [**Thing C**](#toc1_4_3_3_)    \n",
    "      - 1.4.3.4. [**Thing D**](#toc1_4_3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# 1. <a id='toc1_'></a>[**Performing Facial Recognition with Deep Learning**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## 1.1. <a id='toc1_1_'></a>[**Project Context**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "You are working for Face2Gene, an American AI company that has developed a \n",
    "healthcare app for doctors. The app utilizes deep learning algorithms to aid in diagnosing \n",
    "patients for genetic disorders and their variants. It converts patient photos into de-identified \n",
    "mathematical facial descriptors, which are then compared to syndrome-specific computational-\n",
    "based classifiers to determine similarity. The app provides a prioritized list of syndromes with \n",
    "similar morphology and suggests phenotypic traits and genes for feature annotation and \n",
    "syndrome prioritization. \n",
    "  \n",
    "Management has given priority to empowering and entrusting the in-house AI team. As a new \n",
    "member of the team, your task is to build a baseline model for facial recognition. The goal is to \n",
    "further enhance the app's existing features and add more value to the business based on this \n",
    "baseline model.\n",
    "\n",
    "-----------------------------\n",
    "## 1.2. <a id='toc1_2_'></a>[**Project Objectives**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Create a facial recognition tool using a relevant deep learning algorithm, leveraging \n",
    "the provided resources.\n",
    "\n",
    "-----------------------------\n",
    "## 1.3. <a id='toc1_3_'></a>[**Project Dataset Description**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "The ORL Database of Faces consists of 400 images from 40 different subjects. \n",
    "The images were captured at different times, under varying lighting conditions, with different \n",
    "facial expressions (open, closed eyes, smiling, not smiling), and with or without glasses. All the \n",
    "images have a dark homogeneous background, and the subjects are positioned upright and \n",
    "frontal with some tolerance for side movement. Each image has a size of 92x112 pixels and 256 \n",
    "grey levels per pixel. \n",
    "  \n",
    "Data can be downloaded from the following link: \n",
    "https://www.kaggle.com/datasets/kasikrit/att-database-of-faces\n",
    "\n",
    "-----------------------------------\n",
    "## 1.4. <a id='toc1_4_'></a>[**Project Analysis Steps To Perform**](#toc0_)\n",
    "-----------------------------------\n",
    "\n",
    "The following steps will guide you in building the model. \n",
    "  \n",
    "1. Import the relevant packages and collect all the necessary dependencies. \n",
    "  \n",
    "2. Upload and import the data. \n",
    "  \n",
    "3. View a few images to get a sense of the data. \n",
    "  \n",
    "4. Create a validation framework and split the data into train, test, and validation datasets. \n",
    "  \n",
    "5. Perform necessary transformations to prepare the data for input to the CNN model. \n",
    "  \n",
    "6. Build a CNN model with three main layers: a convolutional layer, a pooling layer, and a fully \n",
    "connected layer. You can also consider utilizing state-of-the-art architectures using transfer \n",
    "learning. \n",
    "  \n",
    "7. Train the model using the prepared data. \n",
    "  \n",
    "8. Plot the results to evaluate the model's performance. \n",
    "  \n",
    "9. Iterate on the model, making adjustments and improvements, until you achieve an accuracy \n",
    "above 90%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. <a id='toc1_4_1_'></a>[**Preliminary analysis**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.1. <a id='toc1_4_1_1_'></a>[**Import Modules and Set Default Environment Variables**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import math\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras import backend as K\n",
    "from keras.applications import (EfficientNetB0, InceptionV3, MobileNetV2, ResNet50V2, VGG16)\n",
    "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from keras.callbacks import (Callback, EarlyStopping, LambdaCallback, LearningRateScheduler, ModelCheckpoint, ReduceLROnPlateau)\n",
    "from keras.layers import (BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Input)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- This code block imports necessary libraries (`pandas`, `numpy`, `matplotlib`, and `seaborn`) and reads the three CSV files into pandas DataFrames. It then displays the first few rows of each dataset to give an initial view of the data.\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- Importing and examining the datasets is crucial as it allows us to understand the structure and content of our data. This step helps identify any immediate issues with data formatting or missing values and provides a foundation for all subsequent analyses.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.2. <a id='toc1_4_1_2_'></a>[**Look for corrupt files [Optional]**](#toc0_)    [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_images(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif', '.pgm', '.pnm', '.webp')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    img = Image.open(file_path)\n",
    "                    img.verify()\n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    print(f'Bad file: {file_path}')\n",
    "                    os.remove(file_path)\n",
    "                    print(f'Deleted bad file: {file_path}')\n",
    "\n",
    "# verify_images(f'{DATASET_PATH}/dataset_test')\n",
    "# verify_images(f'{DATASET_PATH}/structure_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- This code examines the shape, structure, and quality of each dataset. It checks the number of rows and columns, data types of each column, presence of missing values, and existence of duplicate entries.\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- Understanding the dataset's structure and quality is crucial for data preprocessing and analysis. It helps identify potential issues like missing data or duplicates that need to be addressed before proceeding with the analysis.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.3. <a id='toc1_4_1_3_'></a>[**Rename Files [Optional]**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_string(length):\n",
    "    \"\"\"Generate a random string of fixed length\"\"\"\n",
    "    letters = string.ascii_lowercase + string.digits\n",
    "    return ''.join(random.choice(letters) for i in range(length))\n",
    "\n",
    "def rename_files(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Generate a unique name\n",
    "            new_name = str(uuid.uuid4())\n",
    "\n",
    "            # Get the file extension\n",
    "            file_extension = os.path.splitext(filename)[1]\n",
    "\n",
    "            # Create the new filename\n",
    "            new_filename = f\"{new_name}.{file_extension}\"\n",
    "\n",
    "            # Full paths\n",
    "            old_file = os.path.join(root, filename)\n",
    "            new_file = os.path.join(root, new_filename)\n",
    "\n",
    "            # Rename the file\n",
    "            os.rename(old_file, new_file)\n",
    "            print(f\"Renamed: {filename} -> {new_filename}\")\n",
    "\n",
    "# Uncomment if you want to rename all of the files in the dataset\n",
    "# directories = [f'{DATASET_PATH}/structures_dataset', f'{DATASET_PATH}/dataset_test']\n",
    "# for start_directory in directories:\n",
    "#     rename_files(start_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.4. <a id='toc1_4_1_4_'></a>[**Convert File Type [Optional]**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pgm_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Create corresponding subdirectories in output_dir\n",
    "        rel_path = os.path.relpath(root, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, rel_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.pgm'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    with Image.open(filepath) as img:\n",
    "                        img = img.convert('RGB')  # Convert to RGB\n",
    "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                        output_path = os.path.join(output_subdir, new_filename)\n",
    "                        img.save(output_path, 'PNG')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {filepath}: {e}\")\n",
    "\n",
    "# Usage\n",
    "# input_dir = 'att_faces_pgm'  # Your current dataset path with PGM files\n",
    "# output_dir = 'att_faces'  # New dataset path for PNG files\n",
    "convert_pgm_to_png(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.4. <a id='toc1_4_1_4_'></a>[**Plot Sample Images**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(dataset_path, num_samples=1):\n",
    "    classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "    fig, axes = plt.subplots(len(classes), num_samples, figsize=(20, 4*len(classes)))\n",
    "\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))][:num_samples]\n",
    "\n",
    "        for j, image_name in enumerate(images):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            img = cv2.imread(image_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[i, j].imshow(img)\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "        # Set the class name as the title for the first image in the row\n",
    "        axes[i, 0].set_title(class_name, fontsize=16, pad=20)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mount Google Drive if using Colab\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "    DATASET_PATH = os.getenv('COLAB_DATASET_PATH', default='/default/dataset/path')\n",
    "except ImportError:\n",
    "    load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "    DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
    "\n",
    "plot_sample_images(f'{DATASET_PATH}/structures_dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.5. <a id='toc1_4_1_5_'></a>[**Create a validation framework and split the data into train, test, and validation datasets**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.6. <a id='toc1_4_1_6_'></a>[**Perform necessary transformations to prepare the data for input to the CNN model**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.7. <a id='toc1_4_1_7_'></a>[**Thing G**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.8. <a id='toc1_4_1_8_'></a>[**Thing H**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1.9. <a id='toc1_4_1_9_'></a>[**Thing I**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. <a id='toc1_4_2_'></a>[**Train Model with Augmentation**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.6\n",
      "TensorFlow: 2.17.0\n",
      "Keras: 3.5.0\n",
      "Scikit-learn: 1.5.2\n",
      "GPUs: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import traceback\n",
    "import warnings\n",
    "import yaml\n",
    "from collections import Counter\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sklearn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.applications import (\n",
    "    EfficientNetB0,\n",
    "    InceptionV3,\n",
    "    MobileNetV2,\n",
    "    ResNet50V2,\n",
    "    VGG16\n",
    ")\n",
    "from keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "from keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
    "from keras.callbacks import (\n",
    "    Callback,\n",
    "    EarlyStopping,\n",
    "    LambdaCallback,\n",
    "    LearningRateScheduler,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau\n",
    ")\n",
    "from keras.layers import (\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    GlobalAveragePooling2D,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    "    RandomRotation,\n",
    "    RandomFlip,\n",
    "    RandomZoom,\n",
    "    RandomContrast,\n",
    "    RandomBrightness,\n",
    "    RandomTranslation,\n",
    "    Rescaling\n",
    ")\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "from keras.utils import Sequence\n",
    "from keras.metrics import Precision, Recall, AUC, Metric\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Import Keras Tuner modules\n",
    "from keras_tuner import (\n",
    "    Hyperband, \n",
    "    HyperModel, \n",
    "    HyperParameters, \n",
    "    BayesianOptimization, \n",
    "    RandomSearch\n",
    ")\n",
    "\n",
    "# Clear any existing TensorFlow session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Set up the logger\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Remove existing handlers from the logger\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# Set up the handler\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# Set the level for the handler\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a formatter (optional but recommended)\n",
    "formatter = logging.Formatter('%(levelname)s:%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Set the overall logger level to DEBUG\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Test logging\n",
    "# logger.debug(\"This is a debug message\")    # Should be displayed\n",
    "# logger.info(\"This is an info message\")     # Should be displayed\n",
    "\n",
    "# To ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configure Random Seed for Numpy and Tensorflow\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Display the version of tensorflow, sklearn, and the GPU\n",
    "print(f'Python: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}')\n",
    "print(f'TensorFlow: {tf.__version__}')\n",
    "print(f'Keras: {tf.keras.version()}')\n",
    "print(f'Scikit-learn: {sklearn.__version__}')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f'GPUs: {gpus if gpus else \"None\"}')\n",
    "print()\n",
    "\n",
    "class F1Score(Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name=name, **kwargs)\n",
    "        self.precision = Precision(name='precision')\n",
    "        self.recall = Recall(name='recall')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        # Update the precision and recall variables\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        # Compute the F1 score\n",
    "        precision = self.precision.result()\n",
    "        recall = self.recall.result()\n",
    "        return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        # Reset the state of the metrics\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()\n",
    "\n",
    "# Define mappings for architectures and preprocessing functions\n",
    "ARCHITECTURES = {\n",
    "    'ResNet50V2': ResNet50V2,\n",
    "    'VGG16': VGG16,\n",
    "    'InceptionV3': InceptionV3,\n",
    "    'MobileNetV2': MobileNetV2,\n",
    "    'EfficientNetB0': EfficientNetB0\n",
    "}\n",
    "\n",
    "PREPROCESSING_FUNCTIONS = {\n",
    "    'resnet_preprocess': resnet_preprocess,\n",
    "    'vgg_preprocess': vgg_preprocess,\n",
    "    'inception_preprocess': inception_preprocess,\n",
    "    'mobilenet_preprocess': mobilenet_preprocess,\n",
    "    'efficientnet_preprocess': efficientnet_preprocess\n",
    "}\n",
    "\n",
    "# Define metrics mapping\n",
    "METRICS = {\n",
    "    'Precision': Precision(name='precision'),\n",
    "    'Recall': Recall(name='recall'),\n",
    "    'AUC': AUC(name='auc'),\n",
    "    'F1Score': F1Score(name='f1_score')\n",
    "}\n",
    "\n",
    "class AccuracyCallback(Callback):\n",
    "    def __init__(self, target_accuracy):\n",
    "        super().__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs.get('val_accuracy') >= self.target_accuracy:\n",
    "            print(f\"\\nReached {self.target_accuracy*100}% validation accuracy. Stopping training.\")\n",
    "            print()\n",
    "            print(\"--------------------\")\n",
    "            print()\n",
    "            self.model.stop_training = True\n",
    "\n",
    "class CustomValidationCallback(Callback):\n",
    "    def __init__(self, validation_data, validation_steps):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.validation_steps = validation_steps\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = 0\n",
    "        val_accuracy = 0\n",
    "        for x, y in self.validation_data.take(self.validation_steps):\n",
    "            val_metrics = self.model.test_on_batch(x, y)\n",
    "            val_loss += val_metrics[0]\n",
    "            val_accuracy += val_metrics[1]\n",
    "\n",
    "        val_loss /= self.validation_steps\n",
    "        val_accuracy /= self.validation_steps\n",
    "\n",
    "        logs['val_loss'] = val_loss\n",
    "        logs['val_accuracy'] = val_accuracy\n",
    "        logging.debug(f\"\\nEpoch {epoch + 1} - Custom validation:\")\n",
    "        logging.debug(f\"Loss: {val_loss:.4f}\")\n",
    "        logging.debug(f\"Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "class DatasetLogger(Callback):\n",
    "    def __init__(self, train_dataset, val_dataset):\n",
    "        super().__init__()\n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nEpoch {epoch + 1} - Train samples: {tf.data.experimental.cardinality(self.train_dataset)}\")\n",
    "        logging.debug(f\"Epoch {epoch + 1} - Val samples: {tf.data.experimental.cardinality(self.val_dataset)}\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            logging.debug(f\"\\nEpoch {epoch + 1} - Train accuracy: {logs.get('accuracy', 'N/A'):.4f}\")\n",
    "            logging.debug(f\"Epoch {epoch + 1} - Val accuracy: {logs.get('val_accuracy', 'N/A'):.4f}\")\n",
    "\n",
    "class DebugCallback(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nStarting epoch {epoch + 1}\\n\")\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        if batch % 100 == 0:\n",
    "            # logging.debug(f\"\\nStarting batch {batch}\\n\")\n",
    "            pass\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logging.debug(f\"\\nEnd of epoch {epoch + 1}\\n\")\n",
    "        if logs:\n",
    "            for key, value in logs.items():\n",
    "                logging.debug(f\"{key}: {value}\")\n",
    "        logging.debug(\"\\n--------------------\\n\")\n",
    "\n",
    "class DataGenerator:\n",
    "    def __init__(self, config):\n",
    "        logging.debug(\"DataGenerator initialization starting.\")\n",
    "        self.config = config\n",
    "        self.batch_size = config['data']['batch_size']\n",
    "        self.target_size = tuple(config['data']['target_size'])\n",
    "        \n",
    "        # Determine preprocessing function\n",
    "        use_pretrained_weights = config['model'].get('use_pretrained_weights', True)\n",
    "        if use_pretrained_weights:\n",
    "            self.preprocessing_function = PREPROCESSING_FUNCTIONS[config['data']['preprocessing_function']]\n",
    "        else:\n",
    "            # When training from scratch you may choose to use a simple rescaling\n",
    "            self.preprocessing_function = None  # Or define a custom function\n",
    "            \n",
    "        self.augmentation_params = config['augmentation']\n",
    "        self.pre_split = config['data'].get('pre_split', True)\n",
    "\n",
    "        logging.debug(f'DG batch_size = {self.batch_size}')\n",
    "        logging.debug(f'DG target_zie = {self.target_size}')\n",
    "        logging.debug(f'DG preprocessing_function = {self.preprocessing_function}')\n",
    "        logging.debug(f'DG augmentation_params = {self.augmentation_params}')\n",
    "        logging.debug(f'DG pre_split = {self.pre_split}')\n",
    "\n",
    "        # Create data augmentation and rescaling layers\n",
    "        self.data_augmentation = self.create_data_augmentation()\n",
    "        self.rescale_layer = self.create_rescale_layer()\n",
    "\n",
    "        if self.pre_split:\n",
    "            logging.debug(\"DG Calling load_pre_split_data function.\")\n",
    "            self.load_pre_split_data()\n",
    "        else:\n",
    "            self.load_and_split_data()\n",
    "\n",
    "    def load_pre_split_data(self):\n",
    "        # Paths for pre-split data\n",
    "        logging.debug(\"DG LPSD Starting load_pre_split_data function.\")\n",
    "        self.train_path = self.config['data']['train_path']\n",
    "        logging.debug(f\"DG LPSD Train path: {self.train_path}\")\n",
    "        self.test_path = self.config['data']['test_path']\n",
    "        logging.debug(f\"DG LPSD Test path: {self.test_path}\")\n",
    "\n",
    "        # Validate paths\n",
    "        if not os.path.exists(self.train_path):\n",
    "            raise FileNotFoundError(f\"DG LPSD Training path not found: {self.train_path}\")\n",
    "        if not os.path.exists(self.test_path):\n",
    "            raise FileNotFoundError(f\"DG LPSD Testing path not found: {self.test_path}\")\n",
    "\n",
    "        # Load datasets\n",
    "        logging.debug(\"DG LPSD Loading train_dataset datasets\")\n",
    "        self.train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.train_path,\n",
    "            label_mode='categorical',\n",
    "            batch_size=None,  # Load as individual samples\n",
    "            image_size=self.target_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        logging.debug(\"DG LPSD Loading test_dataset datasets\")  \n",
    "        self.test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.test_path,\n",
    "            label_mode='categorical',\n",
    "            batch_size=None,\n",
    "            image_size=self.target_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        train_dataset_unbatched = self.train_dataset\n",
    "        test_dataset_unbatched = self.test_dataset\n",
    "\n",
    "        self.class_names = self.train_dataset.class_names\n",
    "\n",
    "        logging.debug(f\"DG LPSD Class names: {self.class_names}\")\n",
    "\n",
    "        # Prepare datasets\n",
    "        logging.debug(\"DG LPSD Preparing datasets\")\n",
    "        self.train_dataset = self.prepare_dataset(self.train_dataset, augment=True)\n",
    "        logging.debug(\"DG LPSD Train dataset prepared.\")\n",
    "        self.val_dataset = self.prepare_dataset(self.test_dataset, augment=False)\n",
    "        logging.debug(\"DG LPSD Val dataset prepared.\")\n",
    "        self.test_dataset = self.val_dataset  # Use the validation dataset for testing if appropriate\n",
    "        logging.debug(\"DG LPSD Test dataset prepared.\")\n",
    "\n",
    "        # Compute sample counts\n",
    "        self.train_sample_count = tf.data.experimental.cardinality(train_dataset_unbatched).numpy()\n",
    "        self.val_sample_count = tf.data.experimental.cardinality(test_dataset_unbatched).numpy()\n",
    "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
    "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
    "        \n",
    "        # Compute class counts directly from the dataset's file paths\n",
    "        self.class_counts = self.count_samples_from_directories(self.train_path, self.class_names)\n",
    "        \n",
    "        print(f'DG LPSD Train path: {self.train_path}')\n",
    "        print(f'DG LPSD Test path: {self.test_path}')\n",
    "        print(f'DG LPSD Batch size: {self.batch_size}')\n",
    "        print(f'DG LPSD Target size: {self.target_size}')\n",
    "        print(f'DG LPSD steps_per_epoch: {self.steps_per_epoch}')\n",
    "        print(f'DG LPSD validation_steps: {self.validation_steps}')\n",
    "        print(f'DG LPSD Preprocessing function: {self.preprocessing_function}')\n",
    "        print(f'DG LPSD Augmentation params: {self.augmentation_params}')\n",
    "        print(f'DG LPSD Class counts: {self.class_counts}')\n",
    "        print(f'DG LPSD Training set size: {self.train_sample_count}')\n",
    "        print(f'DG LPSD Validation set size: {self.val_sample_count}')\n",
    "        print(f'DG LPSD Testing set size: {self.val_sample_count}')\n",
    "\n",
    "    def count_samples_from_directories(self, dataset_path, class_names):\n",
    "        import os\n",
    "        counts = {}\n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(dataset_path, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                counts[class_name] = len([\n",
    "                    fname for fname in os.listdir(class_dir)\n",
    "                    if os.path.isfile(os.path.join(class_dir, fname))\n",
    "                ])\n",
    "            else:\n",
    "                counts[class_name] = 0\n",
    "        return counts\n",
    "\n",
    "    def load_and_split_data(self):\n",
    "        logging.debug(\"DG LASD Getting Class Names.\")\n",
    "        self.class_names = [\n",
    "            d for d in sorted(os.listdir(self.config['data']['dataset_path']))\n",
    "            if os.path.isdir(os.path.join(self.config['data']['dataset_path'], d))\n",
    "        ]\n",
    "        logging.debug(f\"DG LASD Class Names: {self.class_names}\")\n",
    "        class_indices = {name: index for index, name in enumerate(self.class_names)}\n",
    "        logging.debug(f\"DG LASD Class Indices: {class_indices}\")\n",
    "\n",
    "        # Collect file paths and labels\n",
    "        file_paths = []\n",
    "        labels = []\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(self.config['data']['dataset_path'], class_name)\n",
    "            class_files = glob.glob(os.path.join(class_dir, '*'))\n",
    "            file_paths.extend(class_files)\n",
    "            labels.extend([class_indices[class_name]] * len(class_files))\n",
    "\n",
    "        file_paths = np.array(file_paths)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        # First split: train and temp (val + test)\n",
    "        logging.debug(\"DG LASD Splitting data into train and temp sets.\")\n",
    "        train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
    "            file_paths, labels,\n",
    "            test_size=0.3,\n",
    "            stratify=labels,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Second split: validation and test\n",
    "        logging.debug(\"DG LASD Splitting temp data into val and test sets.\")\n",
    "        val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
    "            temp_paths, temp_labels,\n",
    "            test_size=0.5,\n",
    "            stratify=temp_labels,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Mapping indices back to class names for readability\n",
    "        index_to_class = {index: name for name, index in class_indices.items()}\n",
    "\n",
    "        # Training set class distribution\n",
    "        train_class_counts = Counter(train_labels)\n",
    "        train_class_counts_named = {index_to_class[k]: v for k, v in train_class_counts.items()}\n",
    "        logging.info(f\"Training class distribution: {train_class_counts_named}\")\n",
    "\n",
    "        # Validation set class distribution\n",
    "        val_class_counts = Counter(val_labels)\n",
    "        val_class_counts_named = {index_to_class[k]: v for k, v in val_class_counts.items()}\n",
    "        logging.info(f\"Validation class distribution: {val_class_counts_named}\")\n",
    "\n",
    "        # Test set class distribution\n",
    "        test_class_counts = Counter(test_labels)\n",
    "        test_class_counts_named = {index_to_class[k]: v for k, v in test_class_counts.items()}\n",
    "        logging.info(f\"Test class distribution: {test_class_counts_named}\")\n",
    "\n",
    "        # Store the training class counts as an attribute\n",
    "        self.class_counts = train_class_counts_named\n",
    "\n",
    "        # Create datasets from file paths and labels\n",
    "        logging.debug(\"DG LASD Creating datasets from file paths and labels.\")\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
    "        val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "\n",
    "        # Define the load_image function inside the method\n",
    "        def load_image(file_path, label):\n",
    "            # Read the image from file\n",
    "            image = tf.io.read_file(file_path)\n",
    "            # Decode the image data (supports JPEG, PNG, BMP, and GIF)\n",
    "            image = tf.image.decode_image(image, channels=3)\n",
    "            # Set static shape if possible\n",
    "            image.set_shape([None, None, 3])\n",
    "            # Convert image to float32 and resize\n",
    "            image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "            # Resize image to target size\n",
    "            image = tf.image.resize(image, self.target_size)\n",
    "            # Apply preprocessing function if specified\n",
    "            if self.preprocessing_function:\n",
    "                image = self.preprocessing_function(image)\n",
    "            else: \n",
    "                # Default normalization if no preprocessing function is specified\n",
    "                image = image / 255.0\n",
    "            \n",
    "            # One-hot encode the label\n",
    "            label = tf.one_hot(label, depth=len(self.class_names))\n",
    "            return image, label\n",
    "\n",
    "        # Map function to load images from file paths\n",
    "        logging.debug(\"DG LASD Mapping load_image function to datasets.\")\n",
    "        train_dataset = train_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        val_dataset = val_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        test_dataset = test_dataset.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "        # Prepare datasets\n",
    "        logging.debug(\"DG LASD Preparing datasets.\")\n",
    "        self.train_dataset = self.prepare_dataset(train_dataset, augment=True)\n",
    "        self.val_dataset = self.prepare_dataset(val_dataset, augment=False)\n",
    "        self.test_dataset = self.prepare_dataset(test_dataset, augment=False)\n",
    "\n",
    "        # Compute sample counts\n",
    "        logging.debug(\"DG LASD Computing sample counts.\")\n",
    "        self.train_sample_count = len(train_paths)\n",
    "        self.val_sample_count = len(val_paths)\n",
    "        self.test_sample_count = len(test_paths)\n",
    "        print(f\"DG LASD Training sample size: {self.train_sample_count}\")\n",
    "        print(f\"DG LASD Validation sample size: {self.val_sample_count}\")\n",
    "        print(f\"DG LASD Test sample size: {self.test_sample_count}\")\n",
    "\n",
    "        self.steps_per_epoch = math.ceil(self.train_sample_count / self.batch_size)\n",
    "        self.validation_steps = math.ceil(self.val_sample_count / self.batch_size)\n",
    "        self.test_steps = math.ceil(self.test_sample_count / self.batch_size)\n",
    "        print(f\"DG LASD Steps per epoch: {self.steps_per_epoch}\")\n",
    "        print(f\"DG LASD Validation steps: {self.validation_steps}\")\n",
    "        print(f\"DG LASD Test steps: {self.test_steps}\")\n",
    "\n",
    "    def split_dataset(self):\n",
    "        # Calculate dataset size\n",
    "        dataset_size = tf.data.experimental.cardinality(self.dataset).numpy()\n",
    "\n",
    "        # Define split sizes\n",
    "        train_size = int(0.7 * dataset_size)\n",
    "        val_size = int(0.15 * dataset_size)\n",
    "        test_size = dataset_size - train_size - val_size\n",
    "\n",
    "        # Shuffle and split\n",
    "        self.dataset = self.dataset.shuffle(buffer_size=dataset_size, seed=42)\n",
    "        train_dataset = self.dataset.take(train_size)\n",
    "        val_test_dataset = self.dataset.skip(train_size)\n",
    "        val_dataset = val_test_dataset.take(val_size)\n",
    "        test_dataset = val_test_dataset.skip(val_size)\n",
    "\n",
    "        logging.debug(f\"DG SD Dataset size: {dataset_size}\")\n",
    "        logging.debug(f\"DG SD Training size: {train_size}\")\n",
    "        logging.debug(f\"DG SD Validation size: {val_size}\")\n",
    "        logging.debug(f\"DG SD Test size: {test_size}\")\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    def prepare_dataset(self, dataset, augment):\n",
    "        if augment:\n",
    "            try:\n",
    "                dataset = dataset.map(self.augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                dataset = dataset.shuffle(1000).repeat()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"An error occurred trying to prepare dataset with augment true: {e}\")\n",
    "                logging.debug(traceback.format_exc())\n",
    "        else:\n",
    "            dataset = dataset.map(self.normalize_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            dataset = dataset.cache()\n",
    "        dataset = dataset.batch(self.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "        return dataset\n",
    "\n",
    "    def get_dataset_size(self, dataset):\n",
    "        return tf.data.experimental.cardinality(dataset).numpy() * self.batch_size\n",
    "\n",
    "    def create_data_augmentation(self):\n",
    "        layers = []\n",
    "        augmentation_params = self.augmentation_params\n",
    "\n",
    "        # Apply augmentations based on parameters\n",
    "        if augmentation_params.get('rotation_range'):\n",
    "            rotation_range = augmentation_params['rotation_range']\n",
    "            factor = rotation_range / 360.0  # Convert degrees to fraction of full circle\n",
    "            # Ensure factor is within [-1.0, 1.0]\n",
    "            factor = max(min(factor, 1.0), -1.0)\n",
    "            layers.append(RandomRotation(factor=(-factor, factor)))\n",
    "\n",
    "        if augmentation_params.get('horizontal_flip'):\n",
    "            layers.append(RandomFlip(mode='horizontal'))\n",
    "\n",
    "        if augmentation_params.get('vertical_flip'):\n",
    "            layers.append(RandomFlip(mode='vertical'))\n",
    "\n",
    "        if augmentation_params.get('zoom_range'):\n",
    "            zoom = augmentation_params['zoom_range']\n",
    "            # RandomZoom expects height_factor and width_factor in [-1.0, 1.0]\n",
    "            # Ensure zoom is within [0.0, 1.0] to avoid invalid factors\n",
    "            zoom = max(min(zoom, 1.0), 0.0)\n",
    "            layers.append(RandomZoom(height_factor=(-zoom, zoom), width_factor=(-zoom, zoom)))\n",
    "\n",
    "        if augmentation_params.get('width_shift_range') or augmentation_params.get('height_shift_range'):\n",
    "            width_shift = augmentation_params.get('width_shift_range', 0.0)\n",
    "            height_shift = augmentation_params.get('height_shift_range', 0.0)\n",
    "            # RandomTranslation expects height_factor and width_factor in [-1.0, 1.0]\n",
    "            width_shift = max(min(width_shift, 1.0), -1.0)\n",
    "            height_shift = max(min(height_shift, 1.0), -1.0)\n",
    "            layers.append(RandomTranslation(height_factor=height_shift, width_factor=width_shift))\n",
    "\n",
    "        if augmentation_params.get('brightness_range'):\n",
    "            brightness = augmentation_params['brightness_range']\n",
    "            # RandomBrightness expects factor in [0.0, inf), but to avoid extreme brightness, cap it\n",
    "            brightness = max(brightness, 0.0)\n",
    "            layers.append(RandomBrightness(factor=brightness))\n",
    "\n",
    "        if augmentation_params.get('contrast_range'):\n",
    "            contrast = augmentation_params['contrast_range']\n",
    "            # RandomContrast expects factor in [0.0, inf), but to avoid extreme contrast, cap it\n",
    "            contrast = max(contrast, 0.0)\n",
    "            layers.append(RandomContrast(factor=contrast))\n",
    "            \n",
    "        if not layers:\n",
    "            layers.append(tf.keras.layers.Lambda(lambda x: x))\n",
    "\n",
    "        data_augmentation = tf.keras.Sequential(layers)\n",
    "        return data_augmentation\n",
    "\n",
    "    def create_rescale_layer(self):\n",
    "        # Define which preprocessing functions expect which input ranges\n",
    "        preprocess_0_255 = [resnet_preprocess, vgg_preprocess]\n",
    "        preprocess_0_1 = [efficientnet_preprocess]\n",
    "        preprocess_minus1_1 = [mobilenet_preprocess, inception_preprocess]\n",
    "\n",
    "        if self.preprocessing_function in preprocess_0_255:\n",
    "            # No rescaling needed; images are already in [0, 255]\n",
    "            return None\n",
    "        elif self.preprocessing_function in preprocess_0_1:\n",
    "            # Rescaling needed to bring images to [0, 1]\n",
    "            return Rescaling(1./255)\n",
    "        elif self.preprocessing_function in preprocess_minus1_1:\n",
    "            # Rescaling needed to bring images to [0, 1]; preprocessing function will scale to [-1, 1]\n",
    "            return Rescaling(1./255)\n",
    "        else:\n",
    "            # Default to rescaling to [0, 1]\n",
    "            return Rescaling(1./255)\n",
    "\n",
    "    def augment(self, images, labels):\n",
    "        # Different preprocessing functions expect different ranges of images after augmentation\n",
    "        # ResNet50V2 and VGG16: Expect images in the range [0, 255] with mean subtraction.\n",
    "        # InceptionV3 and MobileNetV2: Expect images scaled to [-1, 1].\n",
    "        # EfficientNetB0: Expects images scaled to [0, 1].\n",
    "        \n",
    "        images = tf.cast(images, tf.float32)\n",
    "\n",
    "        # Apply rescaling if necessary\n",
    "        if self.rescale_layer:\n",
    "            images = self.rescale_layer(images)\n",
    "\n",
    "        # Apply data augmentation\n",
    "        images = self.data_augmentation(images)\n",
    "\n",
    "        # Apply preprocessing function\n",
    "        images = self.preprocessing_function(images)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def normalize_and_preprocess(self, images, labels):\n",
    "        images = tf.cast(images, tf.float32)\n",
    "\n",
    "        # Apply rescaling if necessary\n",
    "        if self.rescale_layer:\n",
    "            images = self.rescale_layer(images)\n",
    "\n",
    "        # Apply preprocessing function\n",
    "        images = self.preprocessing_function(images)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def create_datasets(self):\n",
    "        return None\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def __init__(self, config, num_classes, best_hyperparameters=None):\n",
    "        \"\"\"\n",
    "        Initializes the HyperModel.\n",
    "\n",
    "        Args:\n",
    "            config (dict): Configuration dictionary.\n",
    "            num_classes (int): Number of output classes.\n",
    "            best_hyperparameters (HyperParameters, optional): Best hyperparameters from tuning.\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.num_classes = num_classes\n",
    "        self.best_hyperparameters = best_hyperparameters\n",
    "\n",
    "    def build(self, hp):\n",
    "        \"\"\"\n",
    "        Builds the model based on whether to use pre-trained weights or not.\n",
    "\n",
    "        Args:\n",
    "            hp (HyperParameters): Hyperparameters for tuning.\n",
    "\n",
    "        Returns:\n",
    "            keras.Model: Compiled Keras model.\n",
    "        \"\"\"\n",
    "        # If hp is None, use best_hyperparameters or default fixed hyperparameters\n",
    "        if hp is None:\n",
    "            if self.best_hyperparameters is not None:\n",
    "                hp = self.best_hyperparameters\n",
    "            else:\n",
    "                # Create a default HyperParameters object with fixed values from config\n",
    "                from keras_tuner import HyperParameters\n",
    "                hp = HyperParameters()\n",
    "                \n",
    "                # Pre-trained model hyperparameters\n",
    "                hp.Fixed('dense_units', self.config['hyperparameters']['dense_units']['default'])\n",
    "                hp.Fixed('dropout_rate', self.config['hyperparameters']['dropout_rate']['default'])\n",
    "                hp.Fixed('learning_rate', self.config['hyperparameters']['learning_rate']['default'])\n",
    "                hp.Fixed('optimizer', self.config['hyperparameters']['optimizer']['default'])\n",
    "                \n",
    "                # Scratch model hyperparameters\n",
    "                hp.Fixed('dense_units_scratch', self.config['hyperparameters']['dense_units_scratch']['default'])\n",
    "                hp.Fixed('dropout_rate_scratch', self.config['hyperparameters']['dropout_rate_scratch']['default'])\n",
    "                hp.Fixed('learning_rate_scratch', self.config['hyperparameters']['learning_rate_scratch']['default'])\n",
    "                hp.Fixed('optimizer_scratch', self.config['hyperparameters']['optimizer_scratch']['default'])\n",
    "\n",
    "        model_config = self.config['model']\n",
    "        use_pretrained_weights = model_config.get('use_pretrained_weights', True)\n",
    "\n",
    "        if use_pretrained_weights:\n",
    "            # **Using Pre-trained Architecture**\n",
    "            architecture_name = model_config['name']\n",
    "            architecture = ARCHITECTURES[architecture_name]\n",
    "            input_shape = tuple(model_config['input_shape'])\n",
    "            base_model_weights = 'imagenet' if use_pretrained_weights else None\n",
    "            \n",
    "            print(f\"Building model with pre-trained model {architecture_name} with input shape {input_shape} and base model weights {base_model_weights}\")\n",
    "            print()\n",
    "\n",
    "            # Load the base model with or without pre-trained weights\n",
    "            base_model = architecture(\n",
    "                weights=base_model_weights,\n",
    "                include_top=False,\n",
    "                input_shape=input_shape,\n",
    "                name='base_model'  # Assign a name for easy access\n",
    "            )\n",
    "\n",
    "            # Freeze the base model initially\n",
    "            base_model.trainable = False\n",
    "\n",
    "            # Create the classification head\n",
    "            inputs = Input(shape=input_shape)\n",
    "            x = base_model(inputs, training=False)\n",
    "            x = Flatten()(x)\n",
    "\n",
    "            # Integrate hyperparameters for dense units and dropout rate\n",
    "            dense_units = hp.Int(\n",
    "                'dense_units',\n",
    "                min_value=self.config['hyperparameters']['dense_units']['min'],\n",
    "                max_value=self.config['hyperparameters']['dense_units']['max'],\n",
    "                step=self.config['hyperparameters']['dense_units']['step'],\n",
    "                default=self.config['hyperparameters']['dense_units']['default']\n",
    "            )\n",
    "            dropout_rate = hp.Float(\n",
    "                'dropout_rate',\n",
    "                min_value=self.config['hyperparameters']['dropout_rate']['min'],\n",
    "                max_value=self.config['hyperparameters']['dropout_rate']['max'],\n",
    "                step=self.config['hyperparameters']['dropout_rate']['step'],\n",
    "                default=self.config['hyperparameters']['dropout_rate']['default']\n",
    "            )\n",
    "\n",
    "            x = Dense(dense_units, activation='relu')(x)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            x = Dense(dense_units // 2, activation='relu')(x)\n",
    "            x = Dropout(dropout_rate)(x)\n",
    "            output = Dense(self.num_classes, activation='softmax')(x)\n",
    "\n",
    "            model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "            # Compile the model with hyperparameter-defined optimizer\n",
    "            learning_rate = hp.Float(\n",
    "                'learning_rate',\n",
    "                min_value=self.config['hyperparameters']['learning_rate']['min'],\n",
    "                max_value=self.config['hyperparameters']['learning_rate']['max'],\n",
    "                sampling='log',\n",
    "                default=self.config['hyperparameters']['learning_rate']['default']\n",
    "            )\n",
    "            optimizer_choice = hp.Choice(\n",
    "                'optimizer',\n",
    "                values=self.config['hyperparameters']['optimizer']['choices'],\n",
    "                default=self.config['hyperparameters']['optimizer']['default']\n",
    "            )\n",
    "\n",
    "            if optimizer_choice == 'adam':\n",
    "                optimizer = Adam(learning_rate=learning_rate)\n",
    "            elif optimizer_choice == 'sgd':\n",
    "                optimizer = SGD(learning_rate=learning_rate)\n",
    "            else:\n",
    "                optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
    "\n",
    "            metrics = ['accuracy'] + [METRICS[metric] for metric in self.config['model']['additional_metrics']]\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=metrics\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "        else:\n",
    "            # **Building Custom Model from Scratch**\n",
    "            print(\"Building model from scratch.\")\n",
    "            print()\n",
    "            # Define a Sequential model similar to build_model function\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=tuple(self.config['model']['input_shape'])))\n",
    "\n",
    "            # Hyperparameters for Conv2D layers\n",
    "            for i in range(1, 4):  # Assuming 3 Conv2D layers\n",
    "                filters = hp.Int(\n",
    "                    f'conv_{i}_filters_scratch',\n",
    "                    min_value=32,\n",
    "                    max_value=256,\n",
    "                    step=32,\n",
    "                    default=64\n",
    "                )\n",
    "                kernel_size = hp.Choice(\n",
    "                    f'conv_{i}_kernel_size_scratch',\n",
    "                    values=[3, 5],\n",
    "                    default=3\n",
    "                )\n",
    "                model.add(Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), activation='relu'))\n",
    "                model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            # Hyperparameters for Dense layers\n",
    "            dense_units = hp.Int(\n",
    "                'dense_units_scratch',\n",
    "                min_value=self.config['hyperparameters']['dense_units_scratch']['min'],\n",
    "                max_value=self.config['hyperparameters']['dense_units_scratch']['max'],\n",
    "                step=self.config['hyperparameters']['dense_units_scratch']['step'],\n",
    "                default=self.config['hyperparameters']['dense_units_scratch']['default']\n",
    "            )\n",
    "            dropout_rate = hp.Float(\n",
    "                'dropout_rate_scratch',\n",
    "                min_value=self.config['hyperparameters']['dropout_rate_scratch']['min'],\n",
    "                max_value=self.config['hyperparameters']['dropout_rate_scratch']['max'],\n",
    "                step=self.config['hyperparameters']['dropout_rate_scratch']['step'],\n",
    "                default=self.config['hyperparameters']['dropout_rate_scratch']['default']\n",
    "            )\n",
    "\n",
    "            model.add(Dense(dense_units, activation='relu'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(dense_units // 2, activation='relu'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "            # Compile the model with hyperparameter-defined optimizer\n",
    "            learning_rate = hp.Float(\n",
    "                'learning_rate_scratch',\n",
    "                min_value=self.config['hyperparameters']['learning_rate_scratch']['min'],\n",
    "                max_value=self.config['hyperparameters']['learning_rate_scratch']['max'],\n",
    "                sampling='log',\n",
    "                default=self.config['hyperparameters']['learning_rate_scratch']['default']\n",
    "            )\n",
    "            optimizer_choice = hp.Choice(\n",
    "                'optimizer_scratch',\n",
    "                values=self.config['hyperparameters']['optimizer_scratch']['choices'],\n",
    "                default=self.config['hyperparameters']['optimizer_scratch']['default']\n",
    "            )\n",
    "\n",
    "            if optimizer_choice == 'adam':\n",
    "                optimizer = Adam(learning_rate=learning_rate)\n",
    "            elif optimizer_choice == 'sgd':\n",
    "                optimizer = SGD(learning_rate=learning_rate)\n",
    "            else:\n",
    "                optimizer = Adam(learning_rate=learning_rate)  # Default to Adam\n",
    "\n",
    "            metrics = ['accuracy'] + [METRICS[metric] for metric in self.config['model']['additional_metrics']]\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=metrics\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "def setup_gpu(gpu_config):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Log the number of GPUs available\n",
    "            logging.debug(f\"GPU setup complete. Found {len(gpus)} GPU(s).\")\n",
    "\n",
    "            # Optionally, you can log more details about each GPU\n",
    "            for i, gpu in enumerate(gpus):\n",
    "                logging.debug(f\"GPU {i}: {gpu}\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"GPU setup failed: {e}\")\n",
    "    else:\n",
    "        logging.warning(\"No GPUs found. The model will run on CPU.\")\n",
    "\n",
    "def load_config(config_path):\n",
    "    with open(config_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "def setup_datasets(config):\n",
    "    try:\n",
    "        data_generator = DataGenerator(config)\n",
    "        logging.debug(\"DataGenerator initialized successfully.\")\n",
    "        train_dataset, test_dataset, steps_per_epoch, validation_steps = data_generator.get_data_generators()\n",
    "        class_names = data_generator.class_names  # Use class names from data generator\n",
    "        logging.debug(f\"Class names: {class_names}\")\n",
    "\n",
    "        return train_dataset, test_dataset, steps_per_epoch, validation_steps, class_names\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Dataset setup failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_callbacks(config, train_dataset, test_dataset, validation_steps, for_tuning=False):\n",
    "    \"\"\"\n",
    "    Returns a list of callbacks based on the configuration.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Configuration dictionary.\n",
    "        train_dataset (tf.data.Dataset): Training dataset.\n",
    "        test_dataset (tf.data.Dataset): Testing dataset.\n",
    "        validation_steps (int): Number of validation steps.\n",
    "        for_tuning (bool): Flag indicating if it's for hyperparameter tuning.\n",
    "\n",
    "    Returns:\n",
    "        list: List of Keras callbacks.\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config['training']['patience'],\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            filepath=config['training']['model_checkpoint_path'],\n",
    "            save_best_only=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Incorporate ReduceLROnPlateau if specified in config\n",
    "    reduce_lr_config = config.get('reduce_lr_on_plateau', None)\n",
    "    if reduce_lr_config:\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor=reduce_lr_config.get('monitor', 'val_loss'),\n",
    "            factor=reduce_lr_config.get('factor', 0.5),\n",
    "            patience=reduce_lr_config.get('patience', 5),\n",
    "            min_lr=reduce_lr_config.get('min_lr', 1e-6),\n",
    "            verbose=reduce_lr_config.get('verbose', 1)\n",
    "        )\n",
    "        callbacks.append(reduce_lr)\n",
    "    \n",
    "    if not for_tuning:\n",
    "        # Include custom callbacks only when not tuning\n",
    "        callbacks.extend([\n",
    "            AccuracyCallback(target_accuracy=config['training']['target_accuracy']),\n",
    "            CustomValidationCallback(test_dataset, validation_steps),\n",
    "            DebugCallback(),\n",
    "            DatasetLogger(train_dataset, test_dataset)\n",
    "        ])\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "def compute_class_weights_from_counts(class_counts, class_names):\n",
    "    total_samples = sum(class_counts.values())\n",
    "    class_weight_dict = {}\n",
    "    for idx, class_name in enumerate(class_names):\n",
    "        count = class_counts.get(class_name, 0)\n",
    "        if count > 0:\n",
    "            class_weight_dict[idx] = total_samples / (len(class_counts) * count)\n",
    "        else:\n",
    "            class_weight_dict[idx] = 0.0  # Handle classes with zero samples\n",
    "    return class_weight_dict\n",
    "\n",
    "def save_best_hyperparameters(best_hps, filepath='best_hyperparameters.json'):\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(best_hps.values, f)\n",
    "\n",
    "def load_best_hyperparameters(filepath='best_hyperparameters.json'):\n",
    "    with open(filepath, 'r') as f:\n",
    "        hps_dict = json.load(f)\n",
    "    hp = HyperParameters()\n",
    "    for key, value in hps_dict.items():\n",
    "        hp.Fixed(key, value)\n",
    "    return hp\n",
    "\n",
    "def convert_pgm_to_png(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # Create corresponding subdirectories in output_dir\n",
    "        rel_path = os.path.relpath(root, input_dir)\n",
    "        output_subdir = os.path.join(output_dir, rel_path)\n",
    "        os.makedirs(output_subdir, exist_ok=True)\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith('.pgm'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                try:\n",
    "                    with Image.open(filepath) as img:\n",
    "                        img = img.convert('RGB')  # Convert to RGB\n",
    "                        new_filename = os.path.splitext(filename)[0] + '.png'\n",
    "                        output_path = os.path.join(output_subdir, new_filename)\n",
    "                        img.save(output_path, 'PNG')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {filepath}: {e}\")\n",
    "\n",
    "def main(config_path):\n",
    "    \"\"\"\n",
    "    The main function to orchestrate data loading, model building, training, and evaluation.\n",
    "\n",
    "    Args:\n",
    "        config_path (str): Path to the configuration YAML file.\n",
    "    \"\"\"\n",
    "    # Load the configuration\n",
    "    config = load_config(config_path)\n",
    "    logging.debug(f\"Loaded configuration: {config}\")\n",
    "    performance_tuning = config.get('tuning', {}).get('perform_tuning', True)\n",
    "    logging.debug(f\"Perform tuning: {performance_tuning}\")\n",
    "\n",
    "    # Set up GPU if available\n",
    "    setup_gpu(config.get('gpu', {}))\n",
    "    logging.debug(\"Completed GPU setup.\")\n",
    "\n",
    "    # Load environment variables\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        # drive.mount('/content/drive')\n",
    "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "        DATASET_PATH = os.getenv('COLAB_DATASET_PATH')\n",
    "        logging.debug(\"Running in Colab environment\")\n",
    "    except ImportError:\n",
    "        load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "        DATASET_PATH = os.getenv('DATASET_PATH', default='/default/dataset/path')\n",
    "        logging.debug(\"Running in local environment\")\n",
    "\n",
    "    # Update the dataset paths based on whether the data is pre-split or not\n",
    "    pre_split = config['data'].get('pre_split', True)\n",
    "    if pre_split:\n",
    "        # For pre-split data\n",
    "        train_path = os.path.join(DATASET_PATH, config['data']['train_dir'])\n",
    "        test_path = os.path.join(DATASET_PATH, config['data']['test_dir'])\n",
    "        config['data']['train_path'] = train_path\n",
    "        config['data']['test_path'] = test_path\n",
    "        logging.debug(f\"Train path: {train_path}\")\n",
    "        logging.debug(f\"Test path: {test_path}\")\n",
    "    else:\n",
    "        # For single directory data\n",
    "        dataset_path = os.path.join(DATASET_PATH, config['data']['dataset_dir'])\n",
    "        config['data']['dataset_path'] = dataset_path\n",
    "        logging.debug(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "    try:\n",
    "        # Initialize DataGenerator\n",
    "        data_generator = DataGenerator(config)\n",
    "        logging.debug(\"DataGenerator initialized successfully.\")\n",
    "        train_dataset = data_generator.train_dataset\n",
    "        val_dataset = data_generator.val_dataset\n",
    "        test_dataset = data_generator.test_dataset\n",
    "        class_names = data_generator.class_names\n",
    "        logging.debug(f\"Class names: {class_names}\")\n",
    "        steps_per_epoch = data_generator.steps_per_epoch\n",
    "        validation_steps = data_generator.validation_steps\n",
    "\n",
    "        num_classes = len(class_names)\n",
    "\n",
    "        # Compute class weights using training data\n",
    "        logging.debug(\"Main Function Counting Classes and Computing Weights\")\n",
    "        class_counts = data_generator.class_counts\n",
    "        logging.debug(f\"Class counts: {class_counts}\")\n",
    "        class_weight_dict = compute_class_weights_from_counts(class_counts, class_names)\n",
    "        logging.debug(f\"Computed class weights: {class_weight_dict}\")\n",
    "\n",
    "        # Retrieve training parameters\n",
    "        initial_epochs = config['training'].get('initial_epochs', 10)\n",
    "        fine_tune_epochs = config['training'].get('fine_tune_epochs', 0)\n",
    "        total_epochs = initial_epochs + fine_tune_epochs\n",
    "\n",
    "        # Check if using pre-trained weights\n",
    "        use_pretrained_weights = config['model'].get('use_pretrained_weights', True)\n",
    "\n",
    "        if performance_tuning:\n",
    "            # Instantiate the hypermodel\n",
    "            hypermodel = MyHyperModel(config, num_classes)\n",
    "            logging.debug(\"HyperModel instantiated successfully.\")\n",
    "\n",
    "            # Get callbacks for tuning (only deepcopyable ones)\n",
    "            tuning_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=True)\n",
    "\n",
    "            # Set up the tuner\n",
    "            tuner = RandomSearch(\n",
    "                hypermodel,\n",
    "                objective='val_accuracy',\n",
    "                max_trials=config['tuner']['max_trials'],\n",
    "                executions_per_trial=config['tuner']['executions_per_trial'],\n",
    "                directory='hyperparameter_tuning',\n",
    "                project_name='keras_tuner_project'\n",
    "            )\n",
    "            logging.debug(\"Keras Tuner initialized successfully.\")\n",
    "\n",
    "            # Run the hyperparameter search\n",
    "            tuner.search(\n",
    "                train_dataset,\n",
    "                epochs=initial_epochs,\n",
    "                validation_data=val_dataset,\n",
    "                callbacks=tuning_callbacks,\n",
    "                class_weight=class_weight_dict,\n",
    "                steps_per_epoch=steps_per_epoch\n",
    "            )\n",
    "\n",
    "            # Get the optimal hyperparameters\n",
    "            best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "            logging.debug(f\"\"\"\n",
    "            The hyperparameter search is complete.\n",
    "            Best learning rate: {best_hps.get('learning_rate')}\n",
    "            Best dense units: {best_hps.get('dense_units')}\n",
    "            Best dropout rate: {best_hps.get('dropout_rate')}\n",
    "            Best optimizer: {best_hps.get('optimizer')}\n",
    "            \"\"\")\n",
    "            \n",
    "            save_best_hyperparameters(best_hps)\n",
    "            logging.debug(\"Best hyperparameters saved to file.\")\n",
    "\n",
    "            # Build the best model\n",
    "            model = tuner.hypermodel.build(best_hps)\n",
    "            logging.debug(\"Best model built with optimal hyperparameters.\")\n",
    "        else:\n",
    "            # Load the best hyperparameters from file\n",
    "            best_hps = load_best_hyperparameters()\n",
    "            logging.debug(\"Loaded best hyperparameters from file.\")\n",
    "\n",
    "            if best_hps is None:\n",
    "                logging.error(\"Best hyperparameters could not be loaded. Ensure they are saved correctly.\")\n",
    "                raise ValueError(\"Best hyperparameters are not available.\")\n",
    "\n",
    "            # Instantiate the hypermodel with best hyperparameters\n",
    "            hypermodel = MyHyperModel(config, num_classes, best_hyperparameters=best_hps)\n",
    "            model = hypermodel.build(hp=None)  # hp is None, so it uses best_hyperparameters\n",
    "            print(f\"Model built with loaded hyperparameters: {best_hps}\")\n",
    "\n",
    "        # Get all callbacks including custom ones for final training\n",
    "        final_callbacks = get_callbacks(config, train_dataset, val_dataset, validation_steps, for_tuning=False)\n",
    "\n",
    "        # **Initial Training Phase**\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=initial_epochs,\n",
    "            validation_data=val_dataset,\n",
    "            callbacks=final_callbacks,\n",
    "            class_weight=class_weight_dict,\n",
    "            steps_per_epoch=steps_per_epoch\n",
    "        )\n",
    "\n",
    "        logging.debug(\"Initial training completed.\")\n",
    "\n",
    "        # **Fine-Tuning Phase**\n",
    "        if use_pretrained_weights and fine_tune_epochs > 0:\n",
    "            logging.debug(\"Starting fine-tuning phase.\")\n",
    "\n",
    "            # Unfreeze the base model\n",
    "            # Ensure that the base model was named 'base_model' in MyHyperModel\n",
    "            try:\n",
    "                base_model = model.get_layer('base_model')\n",
    "            except ValueError:\n",
    "                # If not found, iterate through layers to find the base model\n",
    "                base_model = None\n",
    "                for layer in model.layers:\n",
    "                    if isinstance(layer, Model):\n",
    "                        base_model = layer\n",
    "                        break\n",
    "                if base_model is None:\n",
    "                    raise ValueError(\"Base model layer not found for fine-tuning.\")\n",
    "\n",
    "            base_model.trainable = True\n",
    "\n",
    "            # Recompile the model with a lower learning rate\n",
    "            if use_pretrained_weights:\n",
    "                if performance_tuning:\n",
    "                    optimizer_choice = best_hps.get('optimizer', 'adam')\n",
    "                    fine_tune_learning_rate = float(config['training'].get('fine_tune_learning_rate', 1e-5))\n",
    "                else:\n",
    "                    optimizer_choice = config['hyperparameters']['optimizer']['default']\n",
    "                    fine_tune_learning_rate = float(config['training'].get('fine_tune_learning_rate', 1e-5))\n",
    "            else:\n",
    "                if performance_tuning:\n",
    "                    optimizer_choice = best_hps.get('optimizer', 'adam')\n",
    "                    fine_tune_learning_rate = float(config['training'].get('fine_tune_learning_rate_scratch', 1e-5))\n",
    "                else:\n",
    "                    optimizer_choice = config['hyperparameters']['optimizer_scratch']['default']\n",
    "                    fine_tune_learning_rate = float(config['training'].get('fine_tune_learning_rate_scratch', 1e-5))\n",
    "\n",
    "            if optimizer_choice == 'adam':\n",
    "                optimizer = Adam(learning_rate=fine_tune_learning_rate)\n",
    "            elif optimizer_choice == 'sgd':\n",
    "                optimizer = SGD(learning_rate=fine_tune_learning_rate)\n",
    "            else:\n",
    "                optimizer = Adam(learning_rate=fine_tune_learning_rate)  # Default to Adam\n",
    "\n",
    "            # Recompile the model\n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'] + [METRICS[metric] for metric in config['model']['additional_metrics']]\n",
    "            )\n",
    "\n",
    "            logging.debug(\"Model recompiled for fine-tuning.\")\n",
    "\n",
    "            # Continue training\n",
    "            history_fine = model.fit(\n",
    "                train_dataset,\n",
    "                epochs=total_epochs,\n",
    "                initial_epoch=initial_epochs,\n",
    "                validation_data=val_dataset,\n",
    "                callbacks=final_callbacks,\n",
    "                class_weight=class_weight_dict,\n",
    "                steps_per_epoch=steps_per_epoch\n",
    "            )\n",
    "\n",
    "            logging.debug(\"Fine-tuning completed.\")\n",
    "\n",
    "        # Evaluate the model\n",
    "        logging.debug(\"Final evaluation:\")\n",
    "        final_evaluation = model.evaluate(test_dataset)\n",
    "        logging.debug(f\"Final evaluation metrics: {final_evaluation}\")\n",
    "\n",
    "        # Save the trained model\n",
    "        model.save('final_model.h5')\n",
    "        logging.debug(\"Model saved successfully.\")\n",
    "\n",
    "        return history, model, class_names, config['data']['target_size'], config['data']['preprocessing_function'], config['model']['name']\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        logging.debug(traceback.format_exc())\n",
    "\n",
    "        return None, None, None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Loaded configuration: {'pretrain_model_eval': False, 'model': {'use_pretained_weights': True, 'name': 'ResNet50V2', 'input_shape': [128, 128, 3], 'initial_learning_rate': 0.001, 'decay_steps': 100, 'decay_rate': 0.96, 'dense_units': 512, 'dropout_rate': 0.5, 'additional_metrics': ['Precision', 'Recall', 'AUC', 'F1Score']}, 'augmentation': {'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}, 'data': {'pre_split': True, 'dataset_path': 'dataset', 'dataset_dir': 'att_faces', 'train_dir': 'train_dataset', 'test_dir': 'test_dataset', 'validation_dir': 'validation_dataset', 'batch_size': 32, 'target_size': [128, 128], 'preprocessing_function': 'resnet_preprocess'}, 'tuning': {'perform_tuning': False}, 'training': {'initial_epochs': 2, 'fine_tune_epochs': 10, 'fine_tune_learning_rate': '1e-5', 'patience': 5, 'target_accuracy': 0.99, 'find_lr': False, 'model_checkpoint_path': 'checkpoint.h5.keras'}, 'tuner': {'max_trials': 5, 'executions_per_trial': 1}, 'hyperparameters': {'learning_rate_pretrained': {'min': '1e-5', 'max': '1e-3', 'default': '1e-4'}, 'learning_rate': {'min': '1e-4', 'max': '1e-2', 'default': '1e-3'}, 'dense_units': {'min': 128, 'max': 1024, 'step': 128, 'default': 128}, 'dropout_rate': {'min': 0.0, 'max': 0.7, 'step': 0.1, 'default': 0.1}, 'unfreeze_layers': {'min': 0, 'max': 100, 'step': 10, 'default': 0}, 'optimizer': {'choices': ['adam', 'sgd'], 'default': 'adam'}, 'dense_units_scratch': {'min': 64, 'max': 512, 'step': 64, 'default': 128}, 'dropout_rate_scratch': {'min': 0.1, 'max': 0.5, 'step': 0.1, 'default': 0.3}, 'learning_rate_scratch': {'min': '1e-5', 'max': '1e-2', 'default': '1e-3'}, 'optimizer_scratch': {'choices': ['adam', 'sgd'], 'default': 'adam'}}, 'reduce_lr_on_plateau': {'monitor': 'val_loss', 'factor': 0.2, 'patience': 10, 'min_lr': '1e-6', 'verbose': 1}, 'visualization': {'figure_size': [12, 4], 'history_plot_path': 'history_plot.png'}, 'gpu': {'memory_growth': True, 'allow_growth': True}}\n",
      "DEBUG:Perform tuning: False\n",
      "WARNING:No GPUs found. The model will run on CPU.\n",
      "DEBUG:Completed GPU setup.\n",
      "DEBUG:Running in local environment\n",
      "DEBUG:Train path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/train_dataset\n",
      "DEBUG:Test path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/test_dataset\n",
      "DEBUG:DataGenerator initialization starting.\n",
      "DEBUG:DG batch_size = 32\n",
      "DEBUG:DG target_zie = (128, 128)\n",
      "DEBUG:DG preprocessing_function = <function preprocess_input at 0x16cda0b80>\n",
      "DEBUG:DG augmentation_params = {'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
      "DEBUG:DG pre_split = True\n",
      "DEBUG:DG Calling load_pre_split_data function.\n",
      "DEBUG:DG LPSD Starting load_pre_split_data function.\n",
      "DEBUG:DG LPSD Train path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/train_dataset\n",
      "DEBUG:DG LPSD Test path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/test_dataset\n",
      "DEBUG:DG LPSD Loading train_dataset datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10235 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:DG LPSD Loading test_dataset datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1474 files belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:DG LPSD Class names: ['altar', 'apse', 'bell_tower', 'column', 'dome(inner)', 'dome(outer)', 'flying_buttress', 'gargoyle', 'stained_glass', 'vault']\n",
      "DEBUG:DG LPSD Preparing datasets\n",
      "DEBUG:DG LPSD Train dataset prepared.\n",
      "DEBUG:DG LPSD Val dataset prepared.\n",
      "DEBUG:DG LPSD Test dataset prepared.\n",
      "DEBUG:DataGenerator initialized successfully.\n",
      "DEBUG:Class names: ['altar', 'apse', 'bell_tower', 'column', 'dome(inner)', 'dome(outer)', 'flying_buttress', 'gargoyle', 'stained_glass', 'vault']\n",
      "DEBUG:Main Function Counting Classes and Computing Weights\n",
      "DEBUG:Class counts: {'altar': 829, 'apse': 514, 'bell_tower': 1059, 'column': 1919, 'dome(inner)': 616, 'dome(outer)': 1177, 'flying_buttress': 407, 'gargoyle': 1571, 'stained_glass': 1033, 'vault': 1110}\n",
      "DEBUG:Computed class weights: {0: 1.2346200241254524, 1: 1.9912451361867705, 2: 0.9664778092540132, 3: 0.5333507034914018, 4: 1.661525974025974, 5: 0.8695836873406967, 6: 2.5147420147420148, 7: 0.6514958625079568, 8: 0.9908034849951597, 9: 0.9220720720720721}\n",
      "DEBUG:Loaded best hyperparameters from file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DG LPSD Train path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/train_dataset\n",
      "DG LPSD Test path: /Users/toddwalters/Development/data/1703138137_dataset/part_1/dataset_hist_structures/test_dataset\n",
      "DG LPSD Batch size: 32\n",
      "DG LPSD Target size: (128, 128)\n",
      "DG LPSD steps_per_epoch: 320\n",
      "DG LPSD validation_steps: 47\n",
      "DG LPSD Preprocessing function: <function preprocess_input at 0x16cda0b80>\n",
      "DG LPSD Augmentation params: {'rotation_range': 5, 'width_shift_range': 0.1, 'height_shift_range': 0.1, 'horizontal_flip': True, 'vertical_flip': False, 'zoom_range': 0.2, 'brightness_range': 0.8}\n",
      "DG LPSD Class counts: {'altar': 829, 'apse': 514, 'bell_tower': 1059, 'column': 1919, 'dome(inner)': 616, 'dome(outer)': 1177, 'flying_buttress': 407, 'gargoyle': 1571, 'stained_glass': 1033, 'vault': 1110}\n",
      "DG LPSD Training set size: 10235\n",
      "DG LPSD Validation set size: 1474\n",
      "DG LPSD Testing set size: 1474\n",
      "Building model with pre-trained model ResNet50V2 with input shape (128, 128, 3) and base model weights imagenet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 1\n",
      "\n",
      "DEBUG:\n",
      "Epoch 1 - Train samples: -1\n",
      "DEBUG:Epoch 1 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built with loaded hyperparameters: <keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x956767620>\n",
      "Epoch 1/2\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.2880 - auc: 0.6969 - f1_score: 0.2351 - loss: 2.3168 - precision: 0.4283 - recall: 0.1626"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 1 - Custom validation:\n",
      "DEBUG:Loss: 0.6739\n",
      "DEBUG:Accuracy: 0.8083\n",
      "DEBUG:\n",
      "End of epoch 1\n",
      "\n",
      "DEBUG:accuracy: 0.4419921934604645\n",
      "DEBUG:auc: 0.8230413794517517\n",
      "DEBUG:f1_score: 0.4029155373573303\n",
      "DEBUG:loss: 1.720815658569336\n",
      "DEBUG:precision: 0.6521739363670349\n",
      "DEBUG:recall: 0.29150390625\n",
      "DEBUG:val_accuracy: 0.8082509015468841\n",
      "DEBUG:val_auc: 0.9715503454208374\n",
      "DEBUG:val_f1_score: 0.7932177782058716\n",
      "DEBUG:val_loss: 0.6738812948795075\n",
      "DEBUG:val_precision: 0.8684422969818115\n",
      "DEBUG:val_recall: 0.7299864292144775\n",
      "DEBUG:learning_rate: 1.0294584171788301e-05\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 1 - Train accuracy: 0.4420\n",
      "DEBUG:Epoch 1 - Val accuracy: 0.8083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 518ms/step - accuracy: 0.2885 - auc: 0.6973 - f1_score: 0.2356 - loss: 2.3150 - precision: 0.4290 - recall: 0.1630 - val_accuracy: 0.8083 - val_auc: 0.9716 - val_f1_score: 0.7932 - val_loss: 0.6739 - val_precision: 0.8684 - val_recall: 0.7300 - learning_rate: 1.0295e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 2\n",
      "\n",
      "DEBUG:\n",
      "Epoch 2 - Train samples: -1\n",
      "DEBUG:Epoch 2 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.6566 - auc: 0.9360 - f1_score: 0.6520 - loss: 1.0457 - precision: 0.8059 - recall: 0.5478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 2 - Custom validation:\n",
      "DEBUG:Loss: 0.5068\n",
      "DEBUG:Accuracy: 0.8499\n",
      "DEBUG:\n",
      "End of epoch 2\n",
      "\n",
      "DEBUG:accuracy: 0.6773437261581421\n",
      "DEBUG:auc: 0.9416456818580627\n",
      "DEBUG:f1_score: 0.6751474738121033\n",
      "DEBUG:loss: 1.004749059677124\n",
      "DEBUG:precision: 0.8169463276863098\n",
      "DEBUG:recall: 0.5752929449081421\n",
      "DEBUG:val_accuracy: 0.8498702302892157\n",
      "DEBUG:val_auc: 0.9820093512535095\n",
      "DEBUG:val_f1_score: 0.857746422290802\n",
      "DEBUG:val_loss: 0.5067670155078807\n",
      "DEBUG:val_precision: 0.8916544914245605\n",
      "DEBUG:val_recall: 0.8263229131698608\n",
      "DEBUG:learning_rate: 1.0294584171788301e-05\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 2 - Train accuracy: 0.6773\n",
      "DEBUG:Epoch 2 - Val accuracy: 0.8499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 520ms/step - accuracy: 0.6567 - auc: 0.9360 - f1_score: 0.6521 - loss: 1.0456 - precision: 0.8059 - recall: 0.5479 - val_accuracy: 0.8499 - val_auc: 0.9820 - val_f1_score: 0.8577 - val_loss: 0.5068 - val_precision: 0.8917 - val_recall: 0.8263 - learning_rate: 1.0295e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Initial training completed.\n",
      "DEBUG:Starting fine-tuning phase.\n",
      "DEBUG:Model recompiled for fine-tuning.\n",
      "DEBUG:\n",
      "Starting epoch 3\n",
      "\n",
      "DEBUG:\n",
      "Epoch 3 - Train samples: -1\n",
      "DEBUG:Epoch 3 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5208 - auc: 0.9372 - f1_score: 0.6690 - loss: 1.4615 - precision: 0.8460 - recall: 0.5562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 3 - Custom validation:\n",
      "DEBUG:Loss: 0.5880\n",
      "DEBUG:Accuracy: 0.8155\n",
      "DEBUG:\n",
      "End of epoch 3\n",
      "\n",
      "DEBUG:accuracy: 0.5790039300918579\n",
      "DEBUG:auc: 0.9287867546081543\n",
      "DEBUG:f1_score: 0.6321043372154236\n",
      "DEBUG:loss: 1.2811696529388428\n",
      "DEBUG:precision: 0.8338924050331116\n",
      "DEBUG:recall: 0.5089475512504578\n",
      "DEBUG:val_accuracy: 0.8154890943080821\n",
      "DEBUG:val_auc: 0.9766857028007507\n",
      "DEBUG:val_f1_score: 0.8249999284744263\n",
      "DEBUG:val_loss: 0.5879973934051839\n",
      "DEBUG:val_precision: 0.8710407018661499\n",
      "DEBUG:val_recall: 0.7835820913314819\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 3 - Train accuracy: 0.5790\n",
      "DEBUG:Epoch 3 - Val accuracy: 0.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.5210 - auc: 0.9372 - f1_score: 0.6689 - loss: 1.4610 - precision: 0.8460 - recall: 0.5560 - val_accuracy: 0.8155 - val_auc: 0.9767 - val_f1_score: 0.8250 - val_loss: 0.5880 - val_precision: 0.8710 - val_recall: 0.7836 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 4\n",
      "\n",
      "DEBUG:\n",
      "Epoch 4 - Train samples: -1\n",
      "DEBUG:Epoch 4 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6924 - auc: 0.9453 - f1_score: 0.6831 - loss: 0.9623 - precision: 0.8362 - recall: 0.5775"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 4 - Custom validation:\n",
      "DEBUG:Loss: 0.4941\n",
      "DEBUG:Accuracy: 0.8474\n",
      "DEBUG:\n",
      "End of epoch 4\n",
      "\n",
      "DEBUG:accuracy: 0.6993163824081421\n",
      "DEBUG:auc: 0.9485158324241638\n",
      "DEBUG:f1_score: 0.6974703073501587\n",
      "DEBUG:loss: 0.9335967898368835\n",
      "DEBUG:precision: 0.837117075920105\n",
      "DEBUG:recall: 0.5977538824081421\n",
      "DEBUG:val_accuracy: 0.8473589065227103\n",
      "DEBUG:val_auc: 0.9822778701782227\n",
      "DEBUG:val_f1_score: 0.8545390367507935\n",
      "DEBUG:val_loss: 0.49414092936414356\n",
      "DEBUG:val_precision: 0.8839738965034485\n",
      "DEBUG:val_recall: 0.8270013332366943\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 4 - Train accuracy: 0.6993\n",
      "DEBUG:Epoch 4 - Val accuracy: 0.8474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 1s/step - accuracy: 0.6924 - auc: 0.9453 - f1_score: 0.6831 - loss: 0.9622 - precision: 0.8362 - recall: 0.5776 - val_accuracy: 0.8474 - val_auc: 0.9823 - val_f1_score: 0.8545 - val_loss: 0.4941 - val_precision: 0.8840 - val_recall: 0.8270 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 5\n",
      "\n",
      "DEBUG:\n",
      "Epoch 5 - Train samples: -1\n",
      "DEBUG:Epoch 5 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7345 - auc: 0.9596 - f1_score: 0.7402 - loss: 0.8114 - precision: 0.8570 - recall: 0.6514"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 5 - Custom validation:\n",
      "DEBUG:Loss: 0.4245\n",
      "DEBUG:Accuracy: 0.8705\n",
      "DEBUG:\n",
      "End of epoch 5\n",
      "\n",
      "DEBUG:accuracy: 0.7393554449081421\n",
      "DEBUG:auc: 0.962197482585907\n",
      "DEBUG:f1_score: 0.7459756731987\n",
      "DEBUG:loss: 0.7992476224899292\n",
      "DEBUG:precision: 0.8564556837081909\n",
      "DEBUG:recall: 0.6607421636581421\n",
      "DEBUG:val_accuracy: 0.870477945246595\n",
      "DEBUG:val_auc: 0.9883548021316528\n",
      "DEBUG:val_f1_score: 0.8775085806846619\n",
      "DEBUG:val_loss: 0.4244942176849284\n",
      "DEBUG:val_precision: 0.895480215549469\n",
      "DEBUG:val_recall: 0.8602442145347595\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 5 - Train accuracy: 0.7394\n",
      "DEBUG:Epoch 5 - Val accuracy: 0.8705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 1s/step - accuracy: 0.7345 - auc: 0.9596 - f1_score: 0.7402 - loss: 0.8114 - precision: 0.8570 - recall: 0.6514 - val_accuracy: 0.8705 - val_auc: 0.9884 - val_f1_score: 0.8775 - val_loss: 0.4245 - val_precision: 0.8955 - val_recall: 0.8602 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 6\n",
      "\n",
      "DEBUG:\n",
      "Epoch 6 - Train samples: -1\n",
      "DEBUG:Epoch 6 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7681 - auc: 0.9679 - f1_score: 0.7736 - loss: 0.7198 - precision: 0.8690 - recall: 0.6971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 6 - Custom validation:\n",
      "DEBUG:Loss: 0.3621\n",
      "DEBUG:Accuracy: 0.8911\n",
      "DEBUG:\n",
      "End of epoch 6\n",
      "\n",
      "DEBUG:accuracy: 0.775097668170929\n",
      "DEBUG:auc: 0.9701160788536072\n",
      "DEBUG:f1_score: 0.778304934501648\n",
      "DEBUG:loss: 0.6980725526809692\n",
      "DEBUG:precision: 0.8688011765480042\n",
      "DEBUG:recall: 0.704882800579071\n",
      "DEBUG:val_accuracy: 0.8911000705779867\n",
      "DEBUG:val_auc: 0.9897130131721497\n",
      "DEBUG:val_f1_score: 0.8986206650733948\n",
      "DEBUG:val_loss: 0.3621019974667975\n",
      "DEBUG:val_precision: 0.9137447476387024\n",
      "DEBUG:val_recall: 0.883989155292511\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 6 - Train accuracy: 0.7751\n",
      "DEBUG:Epoch 6 - Val accuracy: 0.8911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 1s/step - accuracy: 0.7682 - auc: 0.9679 - f1_score: 0.7736 - loss: 0.7198 - precision: 0.8690 - recall: 0.6971 - val_accuracy: 0.8911 - val_auc: 0.9897 - val_f1_score: 0.8986 - val_loss: 0.3621 - val_precision: 0.9137 - val_recall: 0.8840 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 7\n",
      "\n",
      "DEBUG:\n",
      "Epoch 7 - Train samples: -1\n",
      "DEBUG:Epoch 7 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7941 - auc: 0.9731 - f1_score: 0.8007 - loss: 0.6465 - precision: 0.8823 - recall: 0.7329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 7 - Custom validation:\n",
      "DEBUG:Loss: 0.3505\n",
      "DEBUG:Accuracy: 0.8956\n",
      "DEBUG:\n",
      "End of epoch 7\n",
      "\n",
      "DEBUG:accuracy: 0.7969726324081421\n",
      "DEBUG:auc: 0.9744469523429871\n",
      "DEBUG:f1_score: 0.8036056160926819\n",
      "DEBUG:loss: 0.6326016187667847\n",
      "DEBUG:precision: 0.8854019641876221\n",
      "DEBUG:recall: 0.735644519329071\n",
      "DEBUG:val_accuracy: 0.895570677645663\n",
      "DEBUG:val_auc: 0.9902635216712952\n",
      "DEBUG:val_f1_score: 0.8988299369812012\n",
      "DEBUG:val_loss: 0.35053094904473486\n",
      "DEBUG:val_precision: 0.9120111465454102\n",
      "DEBUG:val_recall: 0.8860244154930115\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 7 - Train accuracy: 0.7970\n",
      "DEBUG:Epoch 7 - Val accuracy: 0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 1s/step - accuracy: 0.7941 - auc: 0.9731 - f1_score: 0.8007 - loss: 0.6465 - precision: 0.8823 - recall: 0.7329 - val_accuracy: 0.8956 - val_auc: 0.9903 - val_f1_score: 0.8988 - val_loss: 0.3505 - val_precision: 0.9120 - val_recall: 0.8860 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 8\n",
      "\n",
      "DEBUG:\n",
      "Epoch 8 - Train samples: -1\n",
      "DEBUG:Epoch 8 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8031 - auc: 0.9773 - f1_score: 0.8112 - loss: 0.5942 - precision: 0.8833 - recall: 0.7501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 8 - Custom validation:\n",
      "DEBUG:Loss: 0.3265\n",
      "DEBUG:Accuracy: 0.9082\n",
      "DEBUG:\n",
      "End of epoch 8\n",
      "\n",
      "DEBUG:accuracy: 0.8047851324081421\n",
      "DEBUG:auc: 0.9776273369789124\n",
      "DEBUG:f1_score: 0.8106938600540161\n",
      "DEBUG:loss: 0.5939251184463501\n",
      "DEBUG:precision: 0.8811324834823608\n",
      "DEBUG:recall: 0.750683605670929\n",
      "DEBUG:val_accuracy: 0.9082222897955712\n",
      "DEBUG:val_auc: 0.9909502863883972\n",
      "DEBUG:val_f1_score: 0.9150325655937195\n",
      "DEBUG:val_loss: 0.32646301452149734\n",
      "DEBUG:val_precision: 0.9281228184700012\n",
      "DEBUG:val_recall: 0.9023066759109497\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 8 - Train accuracy: 0.8048\n",
      "DEBUG:Epoch 8 - Val accuracy: 0.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 1s/step - accuracy: 0.8031 - auc: 0.9773 - f1_score: 0.8112 - loss: 0.5942 - precision: 0.8833 - recall: 0.7501 - val_accuracy: 0.9082 - val_auc: 0.9910 - val_f1_score: 0.9150 - val_loss: 0.3265 - val_precision: 0.9281 - val_recall: 0.9023 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 9\n",
      "\n",
      "DEBUG:\n",
      "Epoch 9 - Train samples: -1\n",
      "DEBUG:Epoch 9 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8211 - auc: 0.9812 - f1_score: 0.8297 - loss: 0.5415 - precision: 0.8960 - recall: 0.7726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 9 - Custom validation:\n",
      "DEBUG:Loss: 0.3124\n",
      "DEBUG:Accuracy: 0.9092\n",
      "DEBUG:\n",
      "End of epoch 9\n",
      "\n",
      "DEBUG:accuracy: 0.823925793170929\n",
      "DEBUG:auc: 0.9808762073516846\n",
      "DEBUG:f1_score: 0.8313239812850952\n",
      "DEBUG:loss: 0.5501124262809753\n",
      "DEBUG:precision: 0.8972617983818054\n",
      "DEBUG:recall: 0.7744140625\n",
      "DEBUG:val_accuracy: 0.9091663436686739\n",
      "DEBUG:val_auc: 0.9917534589767456\n",
      "DEBUG:val_f1_score: 0.9140302538871765\n",
      "DEBUG:val_loss: 0.3124172605098562\n",
      "DEBUG:val_precision: 0.926778256893158\n",
      "DEBUG:val_recall: 0.9016281962394714\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 9 - Train accuracy: 0.8239\n",
      "DEBUG:Epoch 9 - Val accuracy: 0.9092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 1s/step - accuracy: 0.8211 - auc: 0.9812 - f1_score: 0.8297 - loss: 0.5415 - precision: 0.8960 - recall: 0.7726 - val_accuracy: 0.9092 - val_auc: 0.9918 - val_f1_score: 0.9140 - val_loss: 0.3124 - val_precision: 0.9268 - val_recall: 0.9016 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 10\n",
      "\n",
      "DEBUG:\n",
      "Epoch 10 - Train samples: -1\n",
      "DEBUG:Epoch 10 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8246 - auc: 0.9790 - f1_score: 0.8291 - loss: 0.5509 - precision: 0.8903 - recall: 0.7758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 10 - Custom validation:\n",
      "DEBUG:Loss: 0.2801\n",
      "DEBUG:Accuracy: 0.9194\n",
      "DEBUG:\n",
      "End of epoch 10\n",
      "\n",
      "DEBUG:accuracy: 0.826171875\n",
      "DEBUG:auc: 0.9794520735740662\n",
      "DEBUG:f1_score: 0.83173668384552\n",
      "DEBUG:loss: 0.5491080284118652\n",
      "DEBUG:precision: 0.8907225728034973\n",
      "DEBUG:recall: 0.780078113079071\n",
      "DEBUG:val_accuracy: 0.9194389809953406\n",
      "DEBUG:val_auc: 0.9931852221488953\n",
      "DEBUG:val_f1_score: 0.9228129386901855\n",
      "DEBUG:val_loss: 0.2800960490044127\n",
      "DEBUG:val_precision: 0.933379590511322\n",
      "DEBUG:val_recall: 0.9124830365180969\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 10 - Train accuracy: 0.8262\n",
      "DEBUG:Epoch 10 - Val accuracy: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 1s/step - accuracy: 0.8246 - auc: 0.9790 - f1_score: 0.8291 - loss: 0.5509 - precision: 0.8903 - recall: 0.7758 - val_accuracy: 0.9194 - val_auc: 0.9932 - val_f1_score: 0.9228 - val_loss: 0.2801 - val_precision: 0.9334 - val_recall: 0.9125 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 11\n",
      "\n",
      "DEBUG:\n",
      "Epoch 11 - Train samples: -1\n",
      "DEBUG:Epoch 11 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/12\n",
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8379 - auc: 0.9839 - f1_score: 0.8438 - loss: 0.4877 - precision: 0.8997 - recall: 0.7945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Epoch 11 - Custom validation:\n",
      "DEBUG:Loss: 0.2881\n",
      "DEBUG:Accuracy: 0.9174\n",
      "DEBUG:\n",
      "End of epoch 11\n",
      "\n",
      "DEBUG:accuracy: 0.841992199420929\n",
      "DEBUG:auc: 0.9842396974563599\n",
      "DEBUG:f1_score: 0.8460740447044373\n",
      "DEBUG:loss: 0.4846786558628082\n",
      "DEBUG:precision: 0.9021234512329102\n",
      "DEBUG:recall: 0.796582043170929\n",
      "DEBUG:val_accuracy: 0.9173531063059543\n",
      "DEBUG:val_auc: 0.9933714270591736\n",
      "DEBUG:val_f1_score: 0.9192885756492615\n",
      "DEBUG:val_loss: 0.28808773832118256\n",
      "DEBUG:val_precision: 0.9268965721130371\n",
      "DEBUG:val_recall: 0.9118046164512634\n",
      "DEBUG:learning_rate: 9.999999747378752e-06\n",
      "DEBUG:\n",
      "--------------------\n",
      "\n",
      "DEBUG:\n",
      "Epoch 11 - Train accuracy: 0.8420\n",
      "DEBUG:Epoch 11 - Val accuracy: 0.9174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m320/320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 1s/step - accuracy: 0.8379 - auc: 0.9839 - f1_score: 0.8438 - loss: 0.4877 - precision: 0.8997 - recall: 0.7945 - val_accuracy: 0.9174 - val_auc: 0.9934 - val_f1_score: 0.9193 - val_loss: 0.2881 - val_precision: 0.9269 - val_recall: 0.9118 - learning_rate: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:\n",
      "Starting epoch 12\n",
      "\n",
      "DEBUG:\n",
      "Epoch 12 - Train samples: -1\n",
      "DEBUG:Epoch 12 - Val samples: 47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/12\n",
      "\u001b[1m 18/320\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:58\u001b[0m 1s/step - accuracy: 0.8273 - auc: 0.9807 - f1_score: 0.8349 - loss: 0.5599 - precision: 0.8923 - recall: 0.7845"
     ]
    }
   ],
   "source": [
    "history, compiled_model, class_names, target_size, preprocessing_function, ptm_name = main('config.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2.1. <a id='toc1_4_2_1_'></a>[**Thing A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def plot_training_history(history, ptm_name, y_true=None, y_pred=None):\n",
    "    # Plot training history and learning rate\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Model Accuracy using the {ptm_name} Pre-Trained Model')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Model Loss using the {ptm_name} Pre-Trained Model')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print metrics after training\n",
    "    if y_true is not None and y_pred is not None:\n",
    "        precision = precision_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        print(f\"Final Loss: {history.history['loss'][-1]:.4f}\")\n",
    "        print(f\"Final Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "        print(f\"Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")\n",
    "        print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Example call\n",
    "# plot_training_history(history, ptm_name, y_true=ground_truth, y_pred=predicted_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.1. <a id='toc1_4_2_1_1_'></a>[**Thing A.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.2. <a id='toc1_4_2_1_2_'></a>[**Thing A.B**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.3. <a id='toc1_4_2_1_3_'></a>[**Thing A.C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.2.1.4. <a id='toc1_4_2_1_4_'></a>[**Thing A.D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.3. <a id='toc1_4_3_'></a>[**Part 3**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.1. <a id='toc1_4_3_1_'></a>[**Thing A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.2. <a id='toc1_4_3_2_'></a>[**Thing B**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.1. <a id='toc1_4_3_2_1_'></a>[**Thing B.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.2. <a id='toc1_4_3_2_2_'></a>[**Thing B.A**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.3. <a id='toc1_4_3_2_3_'></a>[**Thing B.C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.3.2.4. <a id='toc1_4_3_2_4_'></a>[**Thing B.D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.3. <a id='toc1_4_3_3_'></a>[**Thing C**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3.4. <a id='toc1_4_3_4_'></a>[**Thing D**](#toc0_) [&#8593;](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Why It Is Important:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "- [Placeholder for observations after running the code]\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "- [Placeholder for conclusions based on initial data view]\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "- [Placeholder for recommendations based on initial data examination]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
