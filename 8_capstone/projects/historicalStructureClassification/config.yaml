model:
  name: 'ResNet50V2'                 # Model name
  use_pretrained_weights: True       # Use pre-trained weights or not
  input_shape: [128, 128, 3]         # Input image dimensions
  dense_units: 128                   # Units in the dense layer
  dropout_rate: 0.1                  # Dropout rate
  initial_learning_rate: 1.0294583766002546e-05       # Initial learning rate
  decay_steps: 100                   # Learning rate decay steps
  decay_rate: 0.96                   # Learning rate decay rate
  additional_metrics:                # List of metrics to track
    - Precision
    - Recall
    - AUC
    - F1Score
  fine_tune_learning_rate: 1e-5      # Learning rate for fine-tuning
  pretrained_model_eval: True        # Evaluate pre-trained model before training

augmentation:
  enabled: True                      # Toggle to enable/disable data augmentation
  rotation_range: 5                  # Rotation in degrees (<= 360)
  width_shift_range: 0.1             # Width shift fraction (<= 1.0)
  height_shift_range: 0.1            # Height shift fraction (<= 1.0)
  horizontal_flip: True              # Enable horizontal flipping
  vertical_flip: False               # Enable vertical flipping
  zoom_range: 0.2                    # Zoom range (<= 1.0)
  brightness_range: 0.8              # Brightness adjustment
  # contrast_range: 0.1              # adjust as needed
  # saturation_range: 0.1
  # hue_range: 0.05
  # gaussian_blur: 0.5
  # shear_range: 0.2
  # cutout_size: [10, 10]

data:
  pre_split: False                    # Pre-split dataset directories or not
  dataset_dir: 'att_faces'           # Root dataset directory (used if pre_split=True)
  train_dir: 'train_dataset'         # Directory for training data
  test_dir: 'test_dataset'           # Directory for test data
  validation_dir: 'validation_dataset' # Directory for validation data
  color_mode: 'rgb'            # Image color mode 'rgb' or 'grayscale'
  batch_size: 32                     # Batch size for training
  input_shape: [128, 128, 3]         # Input image dimensions
  target_size: [128, 128]            # Image resizing dimensions
  preprocessing_function: 'resnet_preprocess' # Function for preprocessing images

tuning:
  perform_tuning: False              # Toggle for performing hyperparameter tuning
  max_trials: 50                      # Maximum number of tuning trials
  executions_per_trial: 1            # Number of executions per tuning trial

training:
  override: False                    
  initial_epochs: 50                 # Number of initial epochs
  fine_tune_epochs: 0                # Number of fine-tuning epochs
  patience: 10                        # Early stopping patience
  target_accuracy: 0.99              # Desired target accuracy
  find_lr: False                     # Enable learning rate finder
  model_checkpoint_path: 'checkpoint.h5.keras' # Path for saving the model checkpoint

hyperparameters:
  pretrained_model:                  # Hyperparameters for pre-trained models
    num_dense_layers:
      min: 1
      max: 3
      default: 2
    dense_units:
      min: 128
      max: 1024
      step: 128
      default: 128
    dropout_rate:
      min: 0.0
      max: 0.7
      step: 0.1
      default: 0.1
    use_batch_norm:
      default: False
    optimizer:
      choices: ['adam', 'sgd']
      default: 'adam'
    learning_rate:
      min: 1e-5
      max: 1e-3
      default: 1.0294583766002546e-05

  scratch_model:
    num_conv_layers:
      min: 1
      max: 5
      default: 3
    conv_filters_scratch:
      min: 32
      max: 256
      step: 32
      default: 32
    conv_kernel_size_scratch:
      choices: [3, 5]
      default: 3
    use_conv_batch_norm_scratch:
      default: False
    conv_dropout_rate_scratch:
      min: 0.0
      max: 0.5
      step: 0.1
      default: 0.0
    num_dense_layers_scratch:
      min: 1
      max: 4
      default: 2
    dense_units_scratch:
      min: 64
      max: 512
      step: 64
      default: 128
    use_dense_batch_norm_scratch:
      default: False
    dropout_rate_scratch:
      min: 0.0
      max: 0.5
      step: 0.1
      default: 0.3
    optimizer_scratch:
      choices: ['adam', 'sgd']
      default: 'adam'
    learning_rate_scratch:
      min: 1e-5
      max: 1e-2
      default: 0.0003

reduce_lr_on_plateau:
  monitor: 'val_loss'                # Metric to monitor for reducing LR
  factor: 0.2                        # Factor to reduce LR by
  patience: 10                       # Patience before reducing LR
  min_lr: 1e-6                       # Minimum learning rate allowed
  verbose: 1                         # Verbosity level for logging LR changes

visualization:
  figure_size: [12, 4]               # Size of the training history plot
  history_plot_path: 'history_plot.png' # Path for saving the training history plot

gpu:
  memory_growth: true                # Allow GPU memory growth
  allow_growth: true                 # Allow dynamic GPU memory allocation

# ARCHITECTURES = {
#   'ResNet50V2': ResNet50V2,
#   'VGG16': VGG16,
#   'InceptionV3': InceptionV3,
#   'MobileNetV2': MobileNetV2,
#   'EfficientNetB0': EfficientNetB0
# }
#
# ARCHITECTURE_INPUT_SHAPES = {
#   'ResNet50V2': (128, 128, 3),
#   'VGG16': (224, 224, 3),
#   'InceptionV3': (299, 299, 3),
#   'MobileNetV2': (224, 224, 3),
#   'EfficientNetB0': (224, 224, 3)
# }
#
# PREPROCESSING_FUNCTIONS = {
#   'ResNet50V2': resnet_preprocess,
#   'VGG16': vgg_preprocess,
#   'InceptionV3': inception_preprocess,
#   'MobileNetV2': mobilenet_preprocess,
#   'EfficientNetB0': efficientnet_preprocess
# }
