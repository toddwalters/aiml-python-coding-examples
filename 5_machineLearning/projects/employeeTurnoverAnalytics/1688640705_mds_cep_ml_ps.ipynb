{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[**Employee Turnover Analytics**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [**Employee Turnover Analytics**](#toc1_)    \n",
    "  - [**Context**](#toc1_1_)    \n",
    "  - [**Objectives**](#toc1_2_)    \n",
    "  - [**Dataset**](#toc1_3_)    \n",
    "  - [**Analysis Steps to Perform**](#toc1_4_)    \n",
    "    - [**Setup: Import Necessary Libraries**](#toc1_4_1_)    \n",
    "    - [**Load the dataset**](#toc1_4_2_)    \n",
    "    - [**1. Perform data quality check by checking for missing values.**](#toc1_4_3_)    \n",
    "    - [**2. Understand what factors contributed most to employee turnover by EDA**](#toc1_4_4_)    \n",
    "      - [**2.1. Draw a heatmap of the Correlation Matrix between all numerical features/columns in the data.**](#toc1_4_4_1_)    \n",
    "      - [**2.2. Draw the distribution plot of:**](#toc1_4_4_2_)    \n",
    "      - [**2.3.\tDraw the bar plot of Employee Project Count of both employees who left and who stayed in the organization (use column number_project and hue column left) and give your inferences from the plot**](#toc1_4_4_3_)    \n",
    "        - [**Observations/Inferences**](#toc1_4_4_3_1_)    \n",
    "    - [**3. Perform clustering of Employees who left based on their satisfaction and evaluation**](#toc1_4_5_)    \n",
    "      - [**3.1.\tChoose columns satisfaction_level, last_evaluation and left**](#toc1_4_5_1_)    \n",
    "      - [**3.2.\tDo KMeans clustering of employees who left the company into 3 clusters.**](#toc1_4_5_2_)    \n",
    "      - [**3.3.\tBased on the satisfaction and evaluation factors, give your thoughts on the employee clusters**](#toc1_4_5_3_)    \n",
    "    - [**4.\tHandle the left Class Imbalance using SMOTE technique**](#toc1_4_6_)    \n",
    "      - [**4.1.\tPre-Process the data by converting categorical columns to numerical columns by:**](#toc1_4_6_1_)    \n",
    "      - [**4.2.\tDo the stratified split of the dataset to train and test in the ratio 80:20 with random_state=123**](#toc1_4_6_2_)    \n",
    "      - [**4.3.\tOver-sample the train dataset using SMOTE technique from the `imblearn` module**](#toc1_4_6_3_)    \n",
    "    - [**5. Perform 5-Fold cross-validation model training and evaluate performance**](#toc1_4_7_)    \n",
    "      - [**5.1.\tTrain a Logistic Regression model and apply a 5-Fold CV and plot the classification report**](#toc1_4_7_1_)    \n",
    "      - [**5.2.\tTrain a Random Forest Classifier model and apply the 5-Fold CV and plot the classification report**](#toc1_4_7_2_)    \n",
    "      - [**5.3.\tTrain a  Gradient Boosting Classifier model and apply the 5-Fold CV and plot the classification report**](#toc1_4_7_3_)    \n",
    "    - [**6. Identify the best model and justify the evaluation metrics used**](#toc1_4_8_)    \n",
    "      - [**6.1.\tFind the ROC/AUC for each model and plot the ROC curve**](#toc1_4_8_1_)    \n",
    "      - [**6.2.\tFind the confusion matrix for each of the models**](#toc1_4_8_2_)    \n",
    "      - [**6.3.\tFrom the confusion matrix, explain which metric needs to be used- Recall or Precision?**](#toc1_4_8_3_)    \n",
    "    - [**7. Suggest various retention strategies for targeted employees**](#toc1_4_9_)    \n",
    "      - [**7.1.\tUsing the best model, predict the probability of employee turnover in the test data**](#toc1_4_9_1_)    \n",
    "      - [**7.2.\tBased on the below probability score range, categorize the employees into four zones and suggest your thoughts on the retention strategies for each zone**](#toc1_4_9_2_)    \n",
    "      - [**Retention strategies**](#toc1_4_9_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## <a id='toc1_1_'></a>[**Context**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Portobello Tech is an app innovator that has devised an intelligent way of predicting employee turnover within the company. It periodically evaluates employees' work details including the number of projects they worked upon, average monthly working hours, time spent in the company, promotions in the last 5 years, and salary level.\n",
    "Data from prior evaluations show the employee’s satisfaction at the workplace. The data could be used to identify patterns in work style and their interest to continue to work in the company. \n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_2_'></a>[**Objectives**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "1.\tPerform data quality check by checking for missing values if any.\n",
    "2.\tUnderstand what factors contributed most to employee turnover by EDA.\n",
    "3.\tPerform clustering of Employees who left based on their satisfaction and evaluation.\n",
    "4.\tHandle the left Class Imbalance using SMOTE technique.\n",
    "5.\tPerform k-fold cross-validation model training and evaluate performance. \n",
    "6.\tIdentify the best model and justify the evaluation metrics used. \n",
    "7.\tSuggest various retention strategies for targeted employees.\n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_3_'></a>[**Dataset**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "- **satisfaction_level\t:** Satisfaction level at the job of an employee\n",
    "\n",
    "- **last_evaluation :**\tRating between 0 to 1, received by an employee at his last evaluation\n",
    "\n",
    "- **number_project :** Number of projects, an employee involved in\n",
    "\n",
    "- **average_monthly_hours :** Average number of hours in a month, spent by an employee at office\n",
    "\n",
    "- **time_spend_company :** Number of years spent in the company\n",
    "\n",
    "- **Work_accident :** 0 - no accident during employee stay, 1 - accident during employee stay\n",
    "\n",
    "- **left :** 0 indicates employee stays in the company, 1 indicates - employee left the company\n",
    "\n",
    "- **promotion_last_5years :** Number of promotions in his stay\n",
    "\n",
    "- **Department :** Department, an employee belongs to\n",
    "\n",
    "- **salary :** Salary in USD\n",
    "\n",
    "-----------------------------------\n",
    "## <a id='toc1_4_'></a>[**Analysis Steps to Perform**](#toc0_)\n",
    "-----------------------------------\n",
    "\n",
    "1.\tPerform data quality check by checking for missing values if any.\n",
    "2.\tUnderstand what factors contributed most to employee turnover by EDA.\n",
    "\n",
    "    2.1. Draw a heatmap of the Correlation Matrix between all numerical features/columns in the data.\n",
    "\n",
    "    2.2. Draw the distribution plot of:\n",
    "\n",
    "            - Employee Satisfaction (use column satisfaction_level)\n",
    "            - Employee Evaluation (use column last_evaluation)\n",
    "            - Employee Average Monthly Hours (use column average_monthly_hours)\n",
    "\n",
    "    2.3.\tDraw the bar plot of Employee Project Count of both employees who left and who stayed in the organization (use column number_project and hue column left)  and give your inferences from the plot.\n",
    "    \n",
    "3.\tPerform clustering of Employees who left based on their satisfaction and evaluation.\n",
    "\n",
    "    3.1.\tChoose columns satisfaction_level, last_evaluation and left.\n",
    "\n",
    "    3.2.\tDo KMeans clustering of employees who left the company into 3 clusters.\n",
    "\n",
    "    3.3.\tBased on the satisfaction and evaluation factors, give your thoughts on the employee clusters.\n",
    "\n",
    "4.\tHandle the left Class Imbalance using SMOTE technique.\n",
    "\n",
    "    4.1.\tPre-Process the data by converting categorical columns to numerical columns by\n",
    "\n",
    "            - Separating categorical variables and numeric variables.\n",
    "            - Applying get_dummies() to the categorical variables.\n",
    "            - Combining categorical variables and numeric variables.\n",
    " \n",
    "    4.2.\tDo the stratified split of the dataset to train and test in the ratio 80:20 with random_state=123.\n",
    "\n",
    "    4.3.\tOver-sample the train dataset using SMOTE technique from the imblearn module (`from imblearn.over_sampling import SMOTE`).\n",
    "\n",
    "5.\tPerform 5-Fold cross-validation model training and evaluate performance.\n",
    "\n",
    "    5.1.\tTrain a Logistic Regression model and apply a 5-Fold CV and plot the classification report.\n",
    "\n",
    "    5.2.\tTrain a Gradient Boosting model and apply the 5-Fold CV and plot the classification report.\n",
    "\n",
    "    5.3.\tTrain a  Gradient Boosting Classifier model and apply the 5-Fold CV and plot the classification report.\n",
    "\n",
    "6.\tIdentify the best model and justify the evaluation metrics used.\n",
    "\n",
    "    6.1.\tFind the ROC/AUC for each model and plot the ROC curve.\n",
    "\n",
    "    6.2.\tFind the confusion matrix for each of the models.\n",
    "\n",
    "    6.3.\tFrom the confusion matrix, explain which metric needs to be used- Recall or Precision?\n",
    "\n",
    "7.\tSuggest various retention strategies for targeted employees.\n",
    "\n",
    "    7.1.\tUsing the best model, predict the probability of employee turnover in the test data.\n",
    "\n",
    "    7.2.\tBased on the below probability score range, categorize the employees into four zones and suggest your thoughts on the retention strategies for each zone.\n",
    "\n",
    "            - Safe Zone (Green) (Score < 20%)\n",
    "            - Low Risk Zone (Yellow) (20% < Score < 60%)\n",
    "            - Medium Risk Zone (Orange) (60% < Score < 90%)\n",
    "            - High Risk Zone (Red) (Score > 90%).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[**Setup: Import Necessary Libraries**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define a seed value for consistency\n",
    "RANDOM_STATE = 123  \n",
    "\n",
    "# Define the cross-validation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[**Load the dataset**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_excel('1688640705_hr_comma_sep.xlsx')  # Update the path to where your dataset is stored\n",
    "\n",
    "# Rename the 'average_montly_hours' column to 'average_monthly_hours'\n",
    "data_df = data_df.rename(columns={'average_montly_hours': 'average_monthly_hours'})\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[**1. Perform data quality check by checking for missing values.**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any missing values in the dataset\n",
    "\n",
    "data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_4_'></a>[**2. Understand what factors contributed most to employee turnover by EDA**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_4_1_'></a>[**2.1. Draw a heatmap of the Correlation Matrix between all numerical features/columns in the data.**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df with only numerical columns\n",
    "data_numerical_df = data_df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(data_numerical_df.corr(), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_4_2_'></a>[**2.2. Draw the distribution plot of:**](#toc0_)\n",
    "\n",
    "- Employee Satisfaction (use column satisfaction_level)\n",
    "- Employee Evaluation (use column last_evaluation)\n",
    "- Employee Average Monthly Hours (use column average_monthly_hours)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "for column in ['satisfaction_level', 'last_evaluation', 'average_monthly_hours']:\n",
    "    sns.distplot(data_numerical_df[column])\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_4_3_'></a>[**2.3.\tDraw the bar plot of Employee Project Count of both employees who left and who stayed in the organization (use column number_project and hue column left) and give your inferences from the plot**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for number of projects by employee status\n",
    "sns.countplot(x='number_project', hue='left', data=data_numerical_df)\n",
    "plt.title('Number of Projects by Employee Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_4_4_3_1_'></a>[**Observations/Inferences**](#toc0_)\n",
    "Based on the bar plot of the Employee Project Count comparing employees who left and those who stayed in the organization, several inferences can be made:\n",
    "\n",
    "1.\tModerate Workload is Preferable: Employees handling 3 or 4 projects are more likely to stay with the organization. This range might represent an optimal workload where employees feel challenged yet not overwhelmed.\n",
    "\n",
    "2.\tHigh Turnover with Low and High Project Counts:\n",
    "\t- Employees with only 2 projects had a higher likelihood to leave than those with 3 or 4 projects. This might suggest that these employees feel underutilized or not sufficiently challenged.\n",
    "\t- Similarly, employees with 5 or more projects show increasing rates of leaving, particularly those with 6 or 7 projects. This suggests that a very high workload could be leading to burnout and dissatisfaction.\n",
    "\n",
    "3.\tPeak Retention at 3 and 4 Projects: The majority of employees who stayed are in the 3 or 4 projects category, indicating these are likely comfortable, sustainable workloads that contribute to employee satisfaction and retention.\n",
    "\n",
    "4.\tProject Overload and Burnout: The sharp increase in the proportion of employees leaving who have 6 or 7 projects could be an indicator of burnout due to overload. This is a critical area for HR to address, perhaps by redistributing workload or providing additional support.\n",
    "\n",
    "5.\tRisk Management: Employees at the extremes (either too few or too many projects) are at higher risk of turnover. Tailored interventions, such as career development opportunities for those with fewer projects and workload management for those with many, could be effective retention strategies.\n",
    "\n",
    "This plot clearly illustrates the importance of balancing employee workload to enhance satisfaction and retention. Organizations might consider these insights to adjust project assignments or to implement support mechanisms for those handling high numbers of projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_5_'></a>[**3. Perform clustering of Employees who left based on their satisfaction and evaluation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_5_1_'></a>[**3.1.\tChoose columns satisfaction_level, last_evaluation and left**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting employees who left\n",
    "left_employees_df = data_df[data_df['left'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_5_2_'></a>[**3.2.\tDo KMeans clustering of employees who left the company into 3 clusters.**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=RANDOM_STATE)\n",
    "clusters = kmeans.fit_predict(left_employees_df[['satisfaction_level', 'last_evaluation']])\n",
    "left_employees_df['cluster'] = clusters\n",
    "\n",
    "# Visualizing clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='satisfaction_level', y='last_evaluation', hue='cluster', data=left_employees_df, palette='viridis')\n",
    "plt.title('Clustering of Employees Who Left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_5_3_'></a>[**3.3.\tBased on the satisfaction and evaluation factors, give your thoughts on the employee clusters**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot displaying the clustering of employees who left the organization based on their last evaluation and satisfaction level reveals three distinct clusters. Let’s analyze each:\n",
    "\n",
    "**Cluster 0 (Purple Dots)**\n",
    "\n",
    "- *Characteristics:* Located with low to moderate satisfaction levels (around 0.4 to 0.6) and varying last evaluation scores (mostly 0.5 to 0.8).\n",
    "- *Inference:* This cluster appears to consist of a mix of moderately satisfied and evaluated employees. Their reasons for leaving could be diverse and might include lack of growth opportunities, compensation issues, or a desire for a change in work environment. Interventions for this group might need to be more personalized based on individual circumstances.\n",
    "\n",
    "**Cluster 1 (Yellow Dots)**\n",
    "\n",
    "- *Characteristics:* This cluster is characterized by low satisfaction levels (around 0.1 to 0.2) and moderate last evaluation scores (around 0.6 to 0.8).\n",
    "- *Inference:* Employees in this cluster are likely disillusioned or unhappy despite receiving fairly reasonable evaluation scores. This could indicate a misalignment between their expectations or needs and what the company provides. They might feel underappreciated or that their work does not lead to satisfactory rewards.\n",
    "\n",
    "**Cluster 2 (Cyan Dots)**\n",
    "\n",
    "- *Characteristics:* This cluster groups employees with high last evaluation scores (close to 1.0) and high satisfaction levels (around 0.8 to 1.0).\n",
    "- *Inference:* These employees are both highly satisfied and highly evaluated, suggesting they are well-aligned with the company’s goals and are performing effectively. Their departure might be a significant loss for the company, possibly driven by external opportunities rather than internal dissatisfaction. Retention efforts should be strong with this group, as they are likely top performers.\n",
    "\n",
    "**Overall Strategy Implications:**\n",
    "\n",
    "- *Cluster 0:* Conducting exit interviews or feedback sessions to understand their diverse needs and address them may help reduce turnover.\n",
    "- *Cluster 1:* Management needs to explore ways to improve the work environment and ensure that contributions are recognized and rewarded properly.\n",
    "- *Cluster 2:* Offering career development opportunities, competitive compensation, and recognizing their contributions could help retain these high-value employees.\n",
    "\n",
    "Each cluster shows a unique set of needs and characteristics, and thus, tailored strategies are required to address the specific reasons behind their turnover. Recognizing these patterns can help the organization take proactive measures to improve employee satisfaction and retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_6_'></a>[**4.\tHandle the left Class Imbalance using SMOTE technique**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_6_1_'></a>[**4.1.\tPre-Process the data by converting categorical columns to numerical columns by:**](#toc0_)\n",
    "\n",
    "- Separating categorical variables and numeric variables.\n",
    "- Applying get_dummies() to the categorical variables.\n",
    "- Combining categorical variables and numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Data\n",
    "numeric_features_df = data_df.select_dtypes(include=['int64', 'float64'])\n",
    "categorical_features_df = data_df.select_dtypes(include=['object'])\n",
    "\n",
    "# Applying pd.get_dummies() to categorical variables\n",
    "categorical_encoded_df = pd.get_dummies(categorical_features_df)\n",
    "\n",
    "# Combining encoded categorical data with numeric data\n",
    "features_df = pd.concat([numeric_features_df, categorical_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_6_2_'></a>[**4.2.\tDo the stratified split of the dataset to train and test in the ratio 80:20 with random_state=123**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified Split\n",
    "X = features_df.drop('left', axis=1)  # Assuming 'left' is the target variable\n",
    "y = data_df['left']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "print(f'Training set shape: {X_train.shape}')\n",
    "print(f'Training labels distribution: {np.bincount(y_train)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_6_3_'></a>[**4.3.\tOver-sample the train dataset using SMOTE technique from the `imblearn` module**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying SMOTE\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'Training set shape after SMOTE: {X_train_smote.shape}')\n",
    "print(f'Training labels distribution after SMOTE: {np.bincount(y_train_smote)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_7_'></a>[**5. Perform 5-Fold cross-validation model training and evaluate performance**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot_classification_report(model_name, y_test, y_pred):\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(f\"{model_name} Model Classification Report:\")\n",
    "    print(report)\n",
    "    report_df = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True)).transpose()\n",
    "    report_df = report_df.drop(['support'], axis=1)  # Optionally drop the 'support' column\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(report_df, annot=True, cmap='Blues', fmt='.2f', cbar=False)\n",
    "    plt.title(f\"{model_name} Model Classification Report\")\n",
    "    plt.show()\n",
    "\n",
    "def create_and_plot_roc_curve(model, model_name, X_train, y_train, cv):\n",
    "    y_scores = cross_val_predict(model, X_train, y_train, cv=cv, method='predict_proba')[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_train, y_scores)\n",
    "    roc_auc = roc_auc_score(y_train, y_scores)\n",
    "    print (f\"{model_name} Model ROC_AUC Score is {roc_auc}\")\n",
    "    print()\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{model_name} Model - Receiver Operating Characteristic (ROC) Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def create_and_plot_confusion_matrix(model_name, y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f\"{model_name} Model - Confusion Matrix\")\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "def train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, cv, print_accuracy_score=True, plot_classification=True, plot_roc_curve=True, plot_confusion_matrix=True):\n",
    "    # Create and train the model\n",
    "    model_base = model.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    model_accuracy = model_base.score(X_test, y_test)\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    y_pred = cross_val_predict(model, X_test, y_test, cv=cv, method='predict')\n",
    "\n",
    "    # Calculate the accuracy of the model\n",
    "    model_cv_accuracy = np.mean(cross_val_score(model, X_train, y_train, cv=cv))\n",
    "\n",
    "    if print_accuracy_score:\n",
    "        print(f\"Accuracy of {model_name} Model is {model_accuracy}\")\n",
    "        print()\n",
    "        print(f\"Accuracy of {model_name} Model with 5-Fold Cross Validation is {model_cv_accuracy}\")\n",
    "        print()\n",
    "\n",
    "    if plot_classification:\n",
    "        create_plot_classification_report(model_name, y_test, y_pred)\n",
    "\n",
    "    if plot_roc_curve:\n",
    "        create_and_plot_roc_curve(model, model_name, X_train, y_train, cv)\n",
    "        \n",
    "    if plot_confusion_matrix:\n",
    "        create_and_plot_confusion_matrix(model_name, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_7_1_'></a>[**5.1.\tTrain a Logistic Regression model and apply a 5-Fold CV and plot the classification report**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "model_name = 'Logistic Regression'\n",
    "model = LogisticRegression(random_state=RANDOM_STATE)\n",
    "\n",
    "train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, cv, print_accuracy_score=True, plot_classification=True, plot_roc_curve=False, plot_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_7_2_'></a>[**5.2.\tTrain a Random Forest Classifier model and apply the 5-Fold CV and plot the classification report**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "model_name = 'Random Forest'\n",
    "model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, cv, print_accuracy_score=True, plot_classification=True, plot_roc_curve=False, plot_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_7_3_'></a>[**5.3.\tTrain a  Gradient Boosting Classifier model and apply the 5-Fold CV and plot the classification report**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "model_name = 'Gradient Boosting'\n",
    "model = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "train_and_evaluate(model_name, model, X_train, y_train, X_test, y_test, cv, print_accuracy_score=True, plot_classification=True, plot_roc_curve=False, plot_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_8_'></a>[**6. Identify the best model and justify the evaluation metrics used**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_8_1_'></a>[**6.1.\tFind the ROC/AUC for each model and plot the ROC curve**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model using the function\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    train_and_evaluate(model_name, model, X_train_smote, y_train_smote, X_test, y_test, cv, print_accuracy_score=False, plot_classification=False, plot_roc_curve=True, plot_confusion_matrix=False)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_8_2_'></a>[**6.2.\tFind the confusion matrix for each of the models**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model using the function\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    train_and_evaluate(model_name, model, X_train_smote, y_train_smote, X_test, y_test, cv, print_accuracy_score=False, plot_classification=False, plot_roc_curve=False, plot_confusion_matrix=True)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_8_3_'></a>[**6.3.\tFrom the confusion matrix, explain which metric needs to be used- Recall or Precision?**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When to Use Recall or Precision?**\n",
    "\n",
    "•\tRecall is more important when:\n",
    "•\tThe cost of missing a positive case (False Negative) is high.\n",
    "•\tYou want to ensure that all actual positive cases are captured.\n",
    "•\tFor example, in medical diagnostics or fraud detection, where failing to identify a positive case can have severe consequences.\n",
    "•\tPrecision is more important when:\n",
    "•\tThe cost of a false positive is high.\n",
    "•\tYou want to ensure that positive predictions are highly accurate.\n",
    "•\tFor example, in spam detection, where marking a legitimate email as spam can be problematic.\n",
    "\n",
    "**Analysis for Employee Turnover**\n",
    "\n",
    "For predicting employee turnover, Recall is typically more important than Precision. Here’s why:\n",
    "\n",
    "•\tRecall Focus:\n",
    "•\tIn the context of employee turnover, it is crucial to identify all employees who are likely to leave. Missing an at-risk employee (False Negative) means missing the opportunity to intervene and potentially retain them.\n",
    "•\tHigh Recall ensures that most of the at-risk employees are identified, even if it means having some false positives (employees predicted to leave who actually don’t).\n",
    "•\tPrecision Focus:\n",
    "•\tWhile high Precision means fewer false positives, the main priority is to ensure that all possible cases of turnover are captured, even at the expense of having more false positives.\n",
    "\n",
    "**Conclusion**\n",
    "\n",
    "Given the importance of identifying all employees at risk of leaving, Recall should be the primary metric to focus on in your models. Here are the Recall values from the confusion matrices:\n",
    "\n",
    "1.\tLogistic Regression:\n",
    "\t\n",
    "    - Recall = TP / (TP + FN) = 506 / (506 + 208) ≈ 0.71\n",
    "  \n",
    "2.\tRandom Forest Classifier:\n",
    "\n",
    "    - Recall = TP / (TP + FN) = 666 / (666 + 48) ≈ 0.93\n",
    "  \n",
    "3.\tGradient Boosting Classifier:\n",
    "\n",
    "    - Recall = TP / (TP + FN) = 659 / (659 + 55) ≈ 0.92\n",
    "\n",
    "Based on Recall, **the Random Forest Classifier performs the best in terms of identifying employees who are likely to leave**, followed closely by the Gradient Boosting Classifier. Therefore, you should prioritize the model with the highest Recall for your employee turnover prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_9_'></a>[**7. Suggest various retention strategies for targeted employees**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_9_1_'></a>[**7.1.\tUsing the best model, predict the probability of employee turnover in the test data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model (Random Forest Classifier) to predict the probability of employee turnover\n",
    "best_model_instance = RandomForestClassifier(random_state=RANDOM_STATE)  # Assuming Random Forest Classifier is the best model\n",
    "best_model_instance.fit(X_train, y_train)\n",
    "y_prob = best_model_instance.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_9_2_'></a>[**7.2.\tBased on the below probability score range, categorize the employees into four zones and suggest your thoughts on the retention strategies for each zone**](#toc0_)\n",
    "\n",
    "- Safe Zone (Green) (Score < 20%)\n",
    "- Low Risk Zone (Yellow) (20% < Score < 60%)\n",
    "- Medium Risk Zone (Orange) (60% < Score < 90%)\n",
    "- High Risk Zone (Red) (Score > 90%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model (Random Forest Classifier) to predict the probability of employee turnover\n",
    "best_model_instance = RandomForestClassifier(random_state=RANDOM_STATE)  # Assuming Random Forest Classifier is the best model\n",
    "best_model_instance.fit(X_train, y_train)\n",
    "y_prob = best_model_instance.predict_proba(X_test)[:, 1]\n",
    "y_pred = best_model_instance.predict(X_test)\n",
    "\n",
    "# Categorize the employees into four zones\n",
    "zones = pd.cut(y_prob, bins=[0, 0.2, 0.6, 0.9, 1.0], labels=['Safe Zone (Green)', 'Low Risk Zone (Yellow)', 'Medium Risk Zone (Orange)', 'High Risk Zone (Red)'], include_lowest=True)\n",
    "\n",
    "# Handle the case where probability is 0\n",
    "zones[y_prob == 0] = 'Safe Zone (Green)'\n",
    "\n",
    "# Add the zones to the test data\n",
    "test_results = X_test.copy()\n",
    "test_results['Turnover Probability'] = y_prob\n",
    "test_results['Risk Zone'] = zones\n",
    "test_results['Actual Left'] = y_test.values\n",
    "test_results['Predicted Left'] = y_pred\n",
    "test_results['Correctly Predicted'] = test_results['Actual Left'] == test_results['Predicted Left']\n",
    "\n",
    "# Display the results\n",
    "display(test_results.head())\n",
    "\n",
    "\n",
    "\n",
    "# Save the results to a CSV file if needed\n",
    "# test_results.to_csv(\"employee_turnover_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_9_3_'></a>[**Retention strategies**](#toc0_)\n",
    "\n",
    "**Safe Zone (Green):**\n",
    "- *Maintain current engagement strategies and monitor periodically.*\n",
    "- *Offering career development opportunities, competitive compensation, and recognizing their contributions could help retain these high-value employees.*\n",
    "\n",
    "**Low Risk Zone (Yellow):**\n",
    "- *Increase engagement and provide development opportunities to prevent any potential dissatisfaction.*\n",
    "- *Offering career development opportunities, competitive compensation, and recognizing their contributions could help retain these high-value employees.*\n",
    "\n",
    "**Medium Risk Zone (Orange):**\n",
    "- *Conduct individual assessments to understand specific concerns and address them proactively.*\n",
    "- *Management needs to explore ways to improve the work environment and ensure that contributions are recognized and rewarded properly.*\n",
    "\n",
    "**High Risk Zone (Red):**\n",
    "- *Implement immediate interventions, such as personal engagement, to address critical issues and prevent turnover.*\n",
    "- *Conducting exit interviews or feedback sessions to understand their diverse needs and address them may help reduce turnover.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
