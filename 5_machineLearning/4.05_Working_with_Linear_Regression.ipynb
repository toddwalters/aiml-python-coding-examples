{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz1N-R2_lZXU"
   },
   "source": [
    "## **Working with Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1QOfSodb3Nx"
   },
   "source": [
    "## Step 1: Data Preparation\n",
    "\n",
    "- Import the required libraries\n",
    "- Load the Boston housing data set\n",
    "- Prepare the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2bWUm6Rb3N0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGzEXIplb3N1"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True, parser='auto')\n",
    "data = boston.data\n",
    "target = boston.target\n",
    "feature_names = boston.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibc51nHjd2CV"
   },
   "source": [
    "## Step 2: Create a DataFrame and Check for Missing Values\n",
    "\n",
    "- Create a DataFrame using the Boston housing data\n",
    "- Display basic statistics\n",
    "- Check for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVV5gD0Cb3N1",
    "outputId": "a34b2108-60c7-435a-b484-dc3cc9a5554a"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['HousePrice'] = boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lRXzMVsRl3l"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- This is the head of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwGH3zYVb3N2",
    "outputId": "86e47772-1a8f-4e9d-c8f3-e78cba8b405c"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Myu1DvhsR-tI"
   },
   "source": [
    "__Observation__:\n",
    "- Here, you can see the statistical analysis of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6HKwO5ub3N3",
    "outputId": "afb54069-c3fb-42d5-c6f8-ae27866af72c"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oW0CDYQSRAF"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- There are no empty rows in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3K1ODY7d-1B"
   },
   "source": [
    "## Step 3: Remove Outliers from the HousePrice Column\n",
    "\n",
    "\n",
    "- Use a boxplot to visualize the outliers\n",
    "- Remove outliers from the __HousePrice__ column using the 1% and 99% quantiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-k9RGwnZb3N3",
    "outputId": "22fc3226-cc45-40c8-ab5c-38eda94e2a0c"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df['HousePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZp3K8QKSdZK"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- There are outliers in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yN1zIWAxb3N3"
   },
   "outputs": [],
   "source": [
    "upper_limit = df['HousePrice'].quantile(0.99)\n",
    "lower_limit = df['HousePrice'].quantile(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randint(0,100,(5,2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(x<30,99,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZRLEq0Ob3N4"
   },
   "outputs": [],
   "source": [
    "df['HousePrice'] = np.where(df['HousePrice'] < lower_limit, lower_limit, df['HousePrice'])\n",
    "df['HousePrice'] = np.where(df['HousePrice'] > upper_limit, upper_limit, df['HousePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(df.drop(columns=\"HousePrice\"), df['HousePrice'],\n",
    "                                                 test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"y=\"\n",
    "for i,j in zip(X_train.columns,linear.coef_):\n",
    "    y+= (i+ \"*\"+str(j)+\"+\")\n",
    "y += str(linear.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mEcChrUb3N4"
   },
   "source": [
    "## Step 4: Test for Linearity of the Model\n",
    "\n",
    "- Fit the model and display the summary\n",
    "- Define functions to calculate residuals and plot actual vs. predicted values\n",
    "- Test for linearity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAqXRl2Tb3N4",
    "outputId": "109dec1e-f200-423b-d549-ef7a0a6a5b83"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "boston.data = boston.data.apply(pd.to_numeric)\n",
    "\n",
    "X_constant = sm.add_constant(np.asarray(boston.data))\n",
    "boston_model = sm.OLS(boston.target, np.asarray(boston.data)).fit()\n",
    "boston_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aguo5LjvoeXp"
   },
   "source": [
    "- Define a function to calculate residual values by taking the actual and predicted values\n",
    "- The value of residuals is equal to the difference between the actual and  predicted values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQUh_OUPb3N5"
   },
   "outputs": [],
   "source": [
    "def calculate_residuals(model, features, label):\n",
    "    predictions =  model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual' : label, 'Predicted' : predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ1Cwq1oo3bH"
   },
   "source": [
    "- Next, define a function to plot the actual and predicted values using __lmplot__.\n",
    "- The orange line will show the fitted line created by the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MK9yWdfb3N5"
   },
   "outputs": [],
   "source": [
    "def linear_assumptions(model, features, label):\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, height=7)\n",
    "    line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "    plt.plot(line_coords, line_coords, color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81fWml2JpgsP"
   },
   "source": [
    "- Now, run the function __linear_assumptions__ to show the graph with the model as __boston_model__, features as __boston.data__, and label as __boston.taget__ variables as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSJXWOmqb3N5",
    "outputId": "72063509-c60c-4193-922b-9e41ef31e7e2"
   },
   "outputs": [],
   "source": [
    "linear_assumptions(boston_model, boston.data, boston.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1QeMWd_Sx8D"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- We can observe that the line does not represent all the data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJ64i1QvebOr"
   },
   "source": [
    "## Step 5: Check for Multicollinearity\n",
    "\n",
    "- Let's check the correlation between the variables in the data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_Hez1HTb3N6",
    "outputId": "8f819fda-b933-4d20-8932-df6ecd9d93e0"
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVjEhxwjp9fQ"
   },
   "source": [
    "- Calculate the variance inflation factor (VIF) for each feature\n",
    "- Import the __variance_inflation_factor__ module from the __statsmodels.stats.outliers_influence__ library\n",
    "- Set the features as the DataFrame, except the target variable\n",
    "- Assign the __vif_data__ to the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7CHlcPYb3N6",
    "outputId": "643807fe-e355-4015-c028-84cfc515d0fb"
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "x = df.drop(['HousePrice'], axis=1)\n",
    "x = x.astype(float)  # Convert the array to float type\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Features'] = x.columns\n",
    "\n",
    "vif_data['vif'] = [variance_inflation_factor(x.values, i) for i in range(len(x.columns))]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hL40hTUwTCBW"
   },
   "source": [
    "__Observation__:\n",
    "- From the above output, we can infer that the columns **NOX, RM, AGE,** and **PTRATIO** have higher multicollinearity. Hence, we can drop them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1vuRpFCefRs"
   },
   "source": [
    "## Step 6: Remove Multicollinear Features and Split the Data set\n",
    "\n",
    "- Remove highly multicollinear features from the data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvyyBRtQb3N6"
   },
   "outputs": [],
   "source": [
    "df1 = df.drop(['NOX', 'RM', 'AGE', 'PTRATIO'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ph0xpq82qc-Q"
   },
   "source": [
    "- Now, set the feature and target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehssSh0qb3N6"
   },
   "outputs": [],
   "source": [
    "x = df1.drop(['HousePrice'], axis =1)\n",
    "y = df1['HousePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT81ot6jqiew"
   },
   "source": [
    "- Next, split the data into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3U5AxGSb3N7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(x, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UBAT-l1e19z"
   },
   "source": [
    "\n",
    "## Step 7: Fit the Model and Evaluate Performance\n",
    "\n",
    "- Fit the model using OLS and display the summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tz7MY5keb3N7",
    "outputId": "6eda9551-7764-448d-aeff-bad4ef5b0d17"
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "X_test = pd.DataFrame(X_test) \n",
    "\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce')\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test) \n",
    "\n",
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n",
    "print(np.isnan(X_train).sum())\n",
    "print(np.isnan(y_train).sum())\n",
    "\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_oMwiNrq6wj"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRE4WtfLrR1I"
   },
   "source": [
    "- Now, fit the model using linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LP9yZhRkb3N7"
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_train = reg.predict(X_train)\n",
    "y_pred_test = reg.predict(X_test)\n",
    "\n",
    "X_test = pd.DataFrame(X_test)  # Convert X_test to a pandas DataFrame\n",
    "X_test = X_test.apply(pd.to_numeric, errors='coerce')  # Convert non-numeric values to NaN\n",
    "X_test = np.asarray(X_test)  # Convert X_test to a numpy array\n",
    "\n",
    "y_pred_test = reg.predict(X_test)  # Predict using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6-F069arUDW"
   },
   "source": [
    "- Evaluate the model using various metrics such as the **r2_score, mean_absolute_error, and mean_squared_error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2k4xmEqeb3N8",
    "outputId": "65b17121-b20e-46ff-a536-25bdce70dc08"
   },
   "outputs": [],
   "source": [
    "print(\"R Square: {}\".format(r2_score(y_train, y_pred_train)))\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_train, y_pred_train)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhZgiVzgTc9b"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- From the above output, we can observe that the model is a moderate fit for the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiYT-wChb3N8",
    "outputId": "8509410f-2c52-41ef-ca2a-afbb17152c60"
   },
   "outputs": [],
   "source": [
    "print(\"R Square: {}\".format(r2_score(y_test, y_pred_test)))\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_test, y_pred_test)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AxD0wfGUFPi"
   },
   "source": [
    "__Observation__:\n",
    "\n",
    "- The model moderately explains the testing data, as indicated by the **R** **Square** value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "sgd.fit(X_train.astype(\"float\"),y_train)\n",
    "\n",
    "y_pred_test = sgd.predict(X_test.astype(\"float\"))\n",
    "\n",
    "r2_score(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X, y = make_regression(n_samples=100, n_features=20, noise=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train models (adjust hyperparameters as needed)\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.1),  # Tune alpha for Lasso\n",
    "    'Ridge': Ridge(alpha=1.0),  # Tune alpha for Ridge\n",
    "    'Elastic Net': ElasticNet(alpha=0.5, l1_ratio=0.7),  # Tune alpha and l1_ratio for Elastic Net\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"r2 score is {r2_score(y_test,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
