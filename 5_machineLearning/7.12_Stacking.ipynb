{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQgVhxQczN5h"
   },
   "source": [
    "#__Stacking__\n",
    "Let's understand the ensemble technique of stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbTsQjoj82Im"
   },
   "source": [
    "## Step 1: Import the Required Libraries\n",
    "\n",
    "- Install vecstack, if it is not already installed or is giving errors while importing the library\n",
    "- Import pandas, sklearn, xgboost, and vecstack libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5210,
     "status": "ok",
     "timestamp": 1684145749657,
     "user": {
      "displayName": "Akshay Kukkaje",
      "userId": "07529526247935866270"
     },
     "user_tz": -330
    },
    "id": "wVeuwzWyEECu",
    "outputId": "c8501534-4a38-4415-a630-e1b2f56f713b"
   },
   "outputs": [],
   "source": [
    "pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 1939,
     "status": "error",
     "timestamp": 1684145751592,
     "user": {
      "displayName": "Akshay Kukkaje",
      "userId": "07529526247935866270"
     },
     "user_tz": -330
    },
    "id": "eirtTBS58fyb",
    "outputId": "0f98048c-d203-4107-bead-1fab05ce732c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from vecstack import stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGLtoAYP86HB"
   },
   "source": [
    "## Step 2: Load and Preprocess the Dataset\n",
    "\n",
    "- Load the dataset wine.data\n",
    "- Add the names to the dataset as the indices\n",
    "- Peek at the dataset using the head() command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhMiQOhk8fyd"
   },
   "outputs": [],
   "source": [
    "link = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "names = ['Class', 'Alcohol', 'Malic acid', 'Ash',\n",
    "         'Alcalinity of ash' ,'Magnesium', 'Total phenols',\n",
    "         'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',     'Color intensity', 'Hue', 'OD280/OD315 of diluted wines',\n",
    "         'Proline']\n",
    "df = pd.read_csv(link, header=None, names=names)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kjCTxoOG6ue"
   },
   "source": [
    "__Observations:__\n",
    "- This is the head of the dataset.\n",
    "- Define X and y and split the data into train and test\n",
    "- Assign the target variable class to y\n",
    "- Assign all the rows and every column but the first to X\n",
    "- Use the train_test_split method to split the data into an 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J75c5LQY8fye"
   },
   "outputs": [],
   "source": [
    "y = df[['Class']]\n",
    "X = df.iloc[:,1:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqZWargS893k"
   },
   "source": [
    "## Step 3: Define the Base Models for Stacking\n",
    "\n",
    "- Create the models using KNeighborsClassifier, RandomForestClassifier, and XGBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dVFNYKwt8fye"
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(n_neighbors=5,\n",
    "                        n_jobs=-1),\n",
    "        \n",
    "    RandomForestClassifier(random_state=0, n_jobs=-1, \n",
    "                           n_estimators=100, max_depth=5),\n",
    "        \n",
    "    XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                  n_estimators=100, max_depth=5)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CryqA56a1ug"
   },
   "source": [
    "__Observation:__\n",
    "- The different classifiers are set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKy-U7zC9Ddh"
   },
   "source": [
    "## Step 4: Perform Stacking\n",
    "\n",
    "- Let us do the S-train and S-tests, as we will be stacking the models by passing train of X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost\n",
    "\n",
    "base_learner = [(\"rf\", RandomForestClassifier()),\n",
    "                (\"log\", LogisticRegression()),\n",
    "                ('dtree',DecisionTreeClassifier())]\n",
    "meta_learner = xgboost.XGBClassifier() \n",
    "\n",
    "from vecstack import StackingClassifier\n",
    "\n",
    "stack = StackingClassifier(base_learners = base_learner,\n",
    "                           meta_learner = meta_learner,\n",
    "                           mode = 'oof_pred_bag',\n",
    "                           n_folds=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8mHHItx8fyf"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "S_train, S_test = stacking(models, X_train, y_train, X_test, regression=False, mode='oof_pred_bag', \n",
    "                           needs_proba=False, save_dir=None, metric=accuracy_score, n_folds=4, \n",
    "                           stratified=True, shuffle=True, random_state=0, verbose=2)\n",
    "warnings.filterwarnings(\"default\", category=UserWarning)\n",
    "warnings.filterwarnings(\"default\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lz6MhCUSa9F4"
   },
   "source": [
    "__Observations:__\n",
    "- You can observe the accuracy score and other metrics for different models.\n",
    "- For the k-nearest neighbor, the mean is 72.\n",
    "- For random forest, the mean is 97.\n",
    "- For the XGBoost classifier, the mean is 76. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
