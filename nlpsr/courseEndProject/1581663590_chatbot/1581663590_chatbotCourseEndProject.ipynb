{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWQZWNRKqHAJ"
   },
   "source": [
    "# 1. <a id='toc1_'></a>[**NLP and Speech Recognition Chatbot**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtr98vUhqHAJ"
   },
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [**NLP and Speech Recognition Chatbot**](#toc1_)    \n",
    "  - 1.1. [**Problem Statement**](#toc1_1_)    \n",
    "  - 1.2. [**Objectives**](#toc1_2_)    \n",
    "  - 1.3. [**Analysis To Be Done**](#toc1_3_)    \n",
    "    - 1.3.1. [**Ensure Necessary Modules are Installed**](#toc1_3_1_)    \n",
    "    - 1.3.2. [**Import Modules and Set Default Environment Variables and Load Data**](#toc1_3_2_)    \n",
    "    - 1.3.3. [**Preprocess Data**](#toc1_3_3_)    \n",
    "    - 1.3.4. [**Create Pickle Files**](#toc1_3_4_)    \n",
    "    - 1.3.5. [**Create Training And Testing Datasets**](#toc1_3_5_)    \n",
    "    - 1.3.6. [**Build the Model**](#toc1_3_6_)    \n",
    "    - 1.3.7. [**Predict The Responses**](#toc1_3_7_)    \n",
    "      - 1.3.7.1. [**Load Required Python Modules**](#toc1_3_7_1_)    \n",
    "      - 1.3.7.2. [**Establish Environment Variables and Load Data**](#toc1_3_7_2_)    \n",
    "      - 1.3.7.3. [**Creat Prediction Functions**](#toc1_3_7_3_)    \n",
    "      - 1.3.7.4. [**Interactive loop for testing**](#toc1_3_7_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "    numbering=true\n",
    "    anchor=true\n",
    "    flat=false\n",
    "    minLevel=1\n",
    "    maxLevel=6\n",
    "    /vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIduNT6aqHAK"
   },
   "source": [
    "-----------------------------\n",
    "## 1.1. <a id='toc1_1_'></a>[**Problem Statement**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWrA8qbAqHAK"
   },
   "source": [
    "A company holds an event that has been given the deserved promotion through marketing in\n",
    "hopes of attracting as big an audience as possible. Now, it’s up to the customer support team to\n",
    "guide the audience and answer any queries. Providing high-quality support and guidance is the\n",
    "challenge. The chatbot is very helpful for its 24/7 presence and ability to reply instantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JihNq7qpqHAK"
   },
   "source": [
    "-----------------------------\n",
    "## 1.2. <a id='toc1_2_'></a>[**Objectives**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f38n6faeqHAK"
   },
   "source": [
    "Develop a real-time chatbot to engage with the customers in order to boost their\n",
    "business growth by using NLP and Speech Recognition.\n",
    "\n",
    "**Domain:** Customer Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOcoXoeZqHAK"
   },
   "source": [
    "-----------------------------\n",
    "## 1.3. <a id='toc1_3_'></a>[**Analysis To Be Done**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uU_GIISdqHAK"
   },
   "source": [
    "Create a set of prebuilt commands or inputs as a dataset. Here, we use\n",
    "command .json as Dataset that contains the patterns we need to find and the responses we\n",
    "want to return to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKXt2X08qHAK"
   },
   "source": [
    "-----------------------------\n",
    "### 1.3.1. <a id='toc1_3_1_'></a>[**Ensure Necessary Modules are Installed**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76SMXDZwqHAK",
    "outputId": "fd20e1d0-0b76-47ea-f5c5-0508ff0d9c56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
      "Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.11.0\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install nltk\n",
    "%pip install keras\n",
    "%pip install SpeechRecognition\n",
    "%pip install tensorflow\n",
    "# %pip install pickle - standard library in python does not need to be installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIrtuKUnqHAK"
   },
   "source": [
    "-----------------------------\n",
    "### 1.3.2. <a id='toc1_3_2_'></a>[**Import Modules and Set Default Environment Variables and Load Data**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4e5k7C-lqHAL"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section loads essential libraries and initializes the lemmatizer (for processing words) and sets up arrays to store words, classes, and documents. The dataset_dir is defined for file management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IqPoXAc6qHAL",
    "outputId": "63c0ed95-1722-45ff-b901-b80c7483e5f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK data if not already downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Directory for dataset and dependency files\n",
    "dataset_dir = '/content'\n",
    "\n",
    "# Initialize lists\n",
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load intents file\n",
    "with open(f'{dataset_dir}/commands.json') as data_file:\n",
    "    intents = json.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the `commands.json` file, which contains chatbot intents in JSON format. Each intent includes **tags, patterns, and responses**, which will later be used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVX551E9qHAL"
   },
   "source": [
    "-----------------------------\n",
    "### 1.3.3. <a id='toc1_3_3_'></a>[**Preprocess Data**](#toc0_)\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvB50jxkqHAL",
    "outputId": "35a85f73-afda-47f6-caec-3a46135616e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 documents\n",
      "9 classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
      "88 unique lemmatized words [\"'s\", ',', 'a', 'adverse', 'all', 'anyone', 'are', 'awesome', 'be', 'behavior', 'blood', 'by', 'bye', 'can', 'causing', 'chatting', 'check', 'could', 'data', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'give', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'history', 'hola', 'hospital', 'how', 'i', 'id', 'is', 'later', 'list', 'load', 'locate', 'log', 'looking', 'lookup', 'management', 'me', 'module', 'nearby', 'next', 'nice', 'of', 'offered', 'open', 'patient', 'pharmacy', 'pressure', 'provide', 'reaction', 'related', 'result', 'search', 'searching', 'see', 'show', 'suitable', 'support', 'task', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'transfer', 'up', 'want', 'what', 'which', 'with', 'you']\n"
     ]
    }
   ],
   "source": [
    "# Loop through each intent in the intents dataset\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # Tokenize each word in the sentence\n",
    "        word_list = nltk.word_tokenize(pattern)\n",
    "        words.extend(word_list)\n",
    "\n",
    "        # Add to documents in our corpus\n",
    "        documents.append((word_list, intent['tag']))\n",
    "\n",
    "        # Add to our classes if it's not already there\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "\n",
    "# Lemmatize, lower each word, and remove duplicates\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# Sort classes\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "# Display basic stats\n",
    "print(len(documents), \"documents\")\n",
    "print(len(classes), \"classes\", classes)\n",
    "print(len(words), \"unique lemmatized words\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation**\n",
    "\n",
    "**Overview**\n",
    "This part of the script is responsible for preprocessing natural language data from an `intents` dataset to prepare it for training a machine learning model. The script:\n",
    "1. Tokenizes each sentence pattern in the dataset.\n",
    "2. Organizes tokenized words and intents into separate lists for easier processing.\n",
    "3. Lemmatizes and deduplicates words to standardize the vocabulary.\n",
    "4. Prints basic statistics about the processed data to verify that it is correct and ready for further use.\n",
    "\n",
    "The output of this section will be three main lists:\n",
    "- **`words`**: A sorted, unique list of all words in the dataset.\n",
    "- **`classes`**: A sorted, unique list of intent tags.\n",
    "- **`documents`**: A list of tuples containing tokenized words and their associated intent tags.\n",
    "\n",
    "---\n",
    "\n",
    "**Step-by-Step Explanation of the Code**\n",
    "\n",
    "**1. Loop Through Each Intent in the Dataset**\n",
    "\n",
    "This section iterates over each intent in the `intents` dataset, which is structured as a list of intents, each containing `patterns` (example phrases) and a `tag` (the intent category). Here’s a breakdown of each step:\n",
    "\n",
    "1. **Tokenization**:\n",
    "   - For each sentence in `patterns`, the `nltk.word_tokenize()` function splits the sentence into individual words, creating a list called `word_list`.\n",
    "   - This list is then extended into `words`, which will eventually hold every token (word) across all sentences.\n",
    "\n",
    "2. **Document Creation**:\n",
    "   - Each sentence and its associated intent tag are combined as a tuple and appended to the `documents` list.\n",
    "   - This list serves as the core data structure for training, where each entry in `documents` will map a sentence (as a list of words) to a specific intent.\n",
    "\n",
    "3. **Intent Tag Collection**:\n",
    "   - The `classes` list is used to collect unique intent tags from the dataset. If an intent tag hasn’t been seen before, it is added to `classes`.\n",
    "   - This ensures `classes` contains one entry for each unique intent in the dataset.\n",
    "\n",
    "**2. Lemmatize, Lowercase, and Remove Duplicates from `words`**\n",
    "\n",
    "This step processes the `words` list to create a standardized vocabulary for the model:\n",
    "\n",
    "1. **Lemmatization**:\n",
    "   - The `lemmatizer.lemmatize()` function reduces each word to its base (or root) form, helping to standardize the vocabulary. For example, words like \"running\" and \"runs\" are reduced to \"run.\"\n",
    "   \n",
    "2. **Lowercasing**:\n",
    "   - Converts each word to lowercase to ensure that words are treated case-insensitively (i.e., \"Hello\" and \"hello\" are treated as the same word).\n",
    "\n",
    "3. **Duplicate Removal**:\n",
    "   - The `set()` function removes duplicate words, and the `sorted()` function organizes the vocabulary alphabetically.\n",
    "\n",
    "4. **Exclusion of Irrelevant Words**:\n",
    "   - The `ignore_words` list contains words (such as punctuation marks) that are irrelevant to understanding intent. The script excludes any word in `ignore_words` from the final `words` list.\n",
    "\n",
    "After this step, `words` becomes a sorted list of unique, standardized vocabulary items, which will be used as input features for training.\n",
    "\n",
    "**3. Sort Classes**\n",
    "\n",
    "Here, the script sorts and deduplicates the `classes` list, ensuring each intent tag appears only once and in alphabetical order. This list will be the output labels for the model.\n",
    "\n",
    "**4. Display Basic Statistics**\n",
    "\n",
    "The script provides a summary of the processed data, including:\n",
    "- **Number of Documents**: The total count of `(word_list, intent)` pairs in `documents`, representing all examples in the dataset.\n",
    "- **Number of Classes**: The count of unique intent categories (i.e., classes) in the dataset.\n",
    "- **Vocabulary Size**: The count of unique lemmatized words in `words`, giving an idea of the feature space size for the model.\n",
    "\n",
    "This information is useful for confirming that the data was processed as expected and gives insights into the dataset’s composition.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "This portion of the script tokenizes, lemmatizes, and organizes the text data from the intents dataset. By creating lists of vocabulary words (`words`), unique intent tags (`classes`), and document pairs (`documents`), this script prepares the raw text for further processing and model training. The lemmatization and deduplication ensure that the vocabulary is concise, while the organization into `documents` and `classes` enables straightforward mapping of inputs to outputs in a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xYDiY3bXqHAL"
   },
   "source": [
    "### 1.3.4. <a id='toc1_3_4_'></a>[**Create Pickle Files**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D6_T2T9wqHAL"
   },
   "outputs": [],
   "source": [
    "pickle.dump(words,open(f'{dataset_dir}/words.pkl','wb'))\n",
    "pickle.dump(classes,open(f'{dataset_dir}/classes.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The processed `words` and `classes` lists are saved as `.pkl` files for later use, making future model training or testing easier without reprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdJhTj4zqHAL"
   },
   "source": [
    "### 1.3.5. <a id='toc1_3_5_'></a>[**Create Training And Testing Datasets**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ooxxpziYqHAL",
    "outputId": "cba3b385-a719-4ca5-f193-fa32aa5e69af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying train_x...\n",
      "Verifying train_y...\n",
      "train_x and train_y successfully stacked.\n",
      "Shape of train_x: (47, 88)\n",
      "Shape of train_y: (47, 9)\n",
      "Data type of train_x: float32\n",
      "Data type of train_y: float32\n",
      "Sample values from train_x:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Sample values from train_y:\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Define output_empty based on the number of classes\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# Create separate lists for training data inputs (X) and outputs (Y)\n",
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "# Create bag of words for each sentence and corresponding output\n",
    "for doc in documents:\n",
    "    # Initialize our bag of words\n",
    "    bag = []\n",
    "    # List of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # Lemmatize each word to create the base form\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # Create the bag of words array with 1 if word match found in current pattern\n",
    "    bag = [1 if w in pattern_words else 0 for w in words]\n",
    "\n",
    "    # Output is '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    # Append the bag of words and output row to their respective lists\n",
    "    train_x.append(bag)\n",
    "    train_y.append(output_row)\n",
    "\n",
    "# Initial deep verification of train_x and train_y\n",
    "def verify_array(array, name):\n",
    "    print(f\"Verifying {name}...\")\n",
    "    for i, row in enumerate(array):\n",
    "        if not isinstance(row, np.ndarray):\n",
    "            print(f\"Row {i} in {name} is not a numpy array. Found type: {type(row)}\")\n",
    "        elif row.shape[0] != array.shape[1]:\n",
    "            print(f\"Row {i} in {name} has inconsistent shape. Expected {array.shape[1]}, found {row.shape[0]}\")\n",
    "        elif row.dtype != np.float32:\n",
    "            print(f\"Row {i} in {name} has incorrect dtype. Expected float32, found {row.dtype}\")\n",
    "\n",
    "# Convert train_x and train_y to numpy arrays\n",
    "train_x = np.array(train_x, dtype=np.float32)\n",
    "train_y = np.array(train_y, dtype=np.float32)\n",
    "\n",
    "# Deep verification before proceeding\n",
    "verify_array(train_x, \"train_x\")\n",
    "verify_array(train_y, \"train_y\")\n",
    "\n",
    "# Ensure consistency by stacking rows\n",
    "try:\n",
    "    train_x = np.vstack(train_x)\n",
    "    train_y = np.vstack(train_y)\n",
    "    print(\"train_x and train_y successfully stacked.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error in stacking train_x or train_y: {e}\")\n",
    "    raise\n",
    "\n",
    "# Print shapes and types for debugging\n",
    "print(\"Shape of train_x:\", train_x.shape)\n",
    "print(\"Shape of train_y:\", train_y.shape)\n",
    "print(\"Data type of train_x:\", train_x.dtype)\n",
    "print(\"Data type of train_y:\", train_y.dtype)\n",
    "\n",
    "# Double-check by printing sample values if needed\n",
    "print(f\"Sample values from train_x:\\n\", train_x[:5])\n",
    "print(f\"Sample values from train_y:\\n\", train_y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation**\n",
    "\n",
    "**Overview**\n",
    "This script is part of a data preprocessing pipeline designed for training a neural network model for intent classification in a chatbot. The script processes natural language data into structured arrays that a machine learning model can understand. This includes creating a \"bag of words\" representation for each sentence, building a one-hot encoded array for intents, and ensuring consistency within the data.\n",
    "\n",
    "**Step-by-Step Explanation of the Script**\n",
    "\n",
    "**1. Define `output_empty` Based on the Number of Classes**\n",
    "\n",
    "The `output_empty` list serves as a template for encoding each intent. It creates a one-hot encoded list with the length equal to the number of unique classes (intents), filled with zeros. For each pattern, only one position in this array will be set to `1`, representing the associated intent.\n",
    "\n",
    "**2. Create Separate Lists for Training Data Inputs (`train_x`) and Outputs (`train_y`)**\n",
    "\n",
    "The `train_x` and `train_y` lists store the input and output data that will be used for training the model:\n",
    "- **`train_x`**: Holds the \"bag of words\" representation for each pattern (input sentence).\n",
    "- **`train_y`**: Holds the one-hot encoded class label for each pattern.\n",
    "\n",
    "**3. Create Bag of Words and One-Hot Encoded Labels for Each Sentence**\n",
    "\n",
    "This loop iterates through each document in the `documents` list and performs the following steps:\n",
    "\n",
    "1. **Bag of Words Creation**:\n",
    "   - Initializes an empty list `bag` to store the presence/absence of each word.\n",
    "   - Tokenizes and lemmatizes each word in the pattern to reduce variations to their root forms.\n",
    "   - For each word in the vocabulary (`words`), checks if it appears in the current pattern. If it does, `1` is added to `bag`; otherwise, `0` is added.\n",
    "\n",
    "2. **One-Hot Encoding of Output**:\n",
    "   - Creates a copy of `output_empty`.\n",
    "   - Sets the index corresponding to the pattern’s intent (from `classes`) to `1`, making this vector a one-hot representation of the intent.\n",
    "\n",
    "3. **Data Appending**:\n",
    "   - Adds the completed `bag` and `output_row` to `train_x` and `train_y`, respectively.\n",
    "\n",
    "**4. Verify the Structure and Consistency of `train_x` and `train_y`**\n",
    "\n",
    "This function checks the contents of each row in `train_x` and `train_y` to ensure they are consistent:\n",
    "- **Type Check**: Verifies that each row is a numpy array.\n",
    "- **Shape Consistency**: Ensures each row has the same shape as expected.\n",
    "- **Data Type Check**: Confirms each row is of type `float32`, which is required for compatibility with TensorFlow.\n",
    "\n",
    "**5. Convert `train_x` and `train_y` to Numpy Arrays**\n",
    "\n",
    "This step converts `train_x` and `train_y` into numpy arrays of type `float32`, which ensures compatibility with the neural network model. The `float32` type is particularly important for TensorFlow.\n",
    "\n",
    "**6. Perform Deep Verification Using `verify_array`**\n",
    "\n",
    "After converting the data to numpy arrays, the `verify_array` function is called for both `train_x` and `train_y` to confirm that there are no inconsistencies in type, shape, or data type. This step ensures data integrity before proceeding.\n",
    "\n",
    "**7. Ensure Consistency by Stacking Rows with `np.vstack`**\n",
    "\n",
    "The `np.vstack` function is used to stack all rows vertically, forming a consistent 2D array for both `train_x` and `train_y`. If the data has irregularities, this function will raise a `ValueError`, which can help in diagnosing any hidden inconsistencies. \n",
    "\n",
    "**8. Print Shapes, Data Types, and Sample Values for Debugging**\n",
    "\n",
    "These print statements provide final checks of `train_x` and `train_y` by displaying:\n",
    "- **Shapes**: Ensures both arrays have the expected shape.\n",
    "- **Data Types**: Confirms that both arrays are of type `float32`.\n",
    "- **Sample Values**: Provides the first few entries for inspection, allowing a final verification that the data looks correct before model training.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "This section of the script preprocesses data for model training by creating bag-of-words vectors and one-hot encoded labels for each training example. It verifies data consistency using type, shape, and content checks, making sure everything conforms to the structure expected by TensorFlow.\n",
    "\n",
    "The output of this section will be two numpy arrays, `train_x` and `train_y`, that are ready to be fed into a neural network model for training. This ensures the data is accurately structured and validated, minimizing errors during the training phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRNce5JCqHAL"
   },
   "source": [
    "### 1.3.6. <a id='toc1_3_6_'></a>[**Build the Model**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhnNne1LqHAL",
    "outputId": "d736ef30-dedb-4b96-9757-daf62bc6d917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.0225 - loss: 2.2943\n",
      "Epoch 2/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0875 - loss: 2.1613      \n",
      "Epoch 3/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1442 - loss: 2.1039 \n",
      "Epoch 4/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.2066 - loss: 2.0551  \n",
      "Epoch 5/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2533 - loss: 1.9286     \n",
      "Epoch 6/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4563 - loss: 1.7430 \n",
      "Epoch 7/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4178 - loss: 1.6951 \n",
      "Epoch 8/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 1.5733 \n",
      "Epoch 9/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6280 - loss: 1.4621 \n",
      "Epoch 10/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6161 - loss: 1.3698 \n",
      "Epoch 11/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5657 - loss: 1.3686 \n",
      "Epoch 12/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7085 - loss: 0.9618 \n",
      "Epoch 13/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6010 - loss: 1.1272 \n",
      "Epoch 14/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8476 - loss: 0.9853 \n",
      "Epoch 15/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7121 - loss: 0.8652 \n",
      "Epoch 16/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6977 - loss: 0.8643 \n",
      "Epoch 17/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7108 - loss: 0.9278 \n",
      "Epoch 18/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8067 - loss: 0.8040 \n",
      "Epoch 19/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8396 - loss: 0.6257 \n",
      "Epoch 20/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7907 - loss: 0.6845 \n",
      "Epoch 21/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.6692  \n",
      "Epoch 22/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.4649 \n",
      "Epoch 23/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8296 - loss: 0.4774 \n",
      "Epoch 24/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 0.6732 \n",
      "Epoch 25/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.4208 \n",
      "Epoch 26/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8495 - loss: 0.4069 \n",
      "Epoch 27/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.4295 \n",
      "Epoch 28/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.4461 \n",
      "Epoch 29/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9235 - loss: 0.2879 \n",
      "Epoch 30/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9305 - loss: 0.3442 \n",
      "Epoch 31/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.2629  \n",
      "Epoch 32/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.3792 \n",
      "Epoch 33/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.2449 \n",
      "Epoch 34/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.2476 \n",
      "Epoch 35/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.1623 \n",
      "Epoch 36/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.1734 \n",
      "Epoch 37/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.1233 \n",
      "Epoch 38/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0735 \n",
      "Epoch 39/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1715 \n",
      "Epoch 40/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0872 \n",
      "Epoch 41/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.1009 \n",
      "Epoch 42/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.2570 \n",
      "Epoch 43/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1371 \n",
      "Epoch 44/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.1812 \n",
      "Epoch 45/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.1018 \n",
      "Epoch 46/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0940 \n",
      "Epoch 47/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2095 \n",
      "Epoch 48/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0728 \n",
      "Epoch 49/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.1635 \n",
      "Epoch 50/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.1378 \n",
      "Epoch 51/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.2453 \n",
      "Epoch 52/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9547 - loss: 0.1370 \n",
      "Epoch 53/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9267 - loss: 0.2441 \n",
      "Epoch 54/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9301 - loss: 0.1185 \n",
      "Epoch 55/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0573 \n",
      "Epoch 56/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.1114 \n",
      "Epoch 57/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0753 \n",
      "Epoch 58/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.1431 \n",
      "Epoch 59/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0533 \n",
      "Epoch 60/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9642 - loss: 0.1072 \n",
      "Epoch 61/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0807 \n",
      "Epoch 62/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.0859 \n",
      "Epoch 63/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0567 \n",
      "Epoch 64/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.1259 \n",
      "Epoch 65/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0522 \n",
      "Epoch 66/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0364 \n",
      "Epoch 67/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0779 \n",
      "Epoch 68/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0775 \n",
      "Epoch 69/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9309 - loss: 0.1160 \n",
      "Epoch 70/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.1171 \n",
      "Epoch 71/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0372 \n",
      "Epoch 72/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0552 \n",
      "Epoch 73/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.1997 \n",
      "Epoch 74/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0199 \n",
      "Epoch 75/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0446 \n",
      "Epoch 76/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0745 \n",
      "Epoch 77/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0390 \n",
      "Epoch 78/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0257 \n",
      "Epoch 79/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.1090 \n",
      "Epoch 80/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0328 \n",
      "Epoch 81/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0481 \n",
      "Epoch 82/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.0672 \n",
      "Epoch 83/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0672 \n",
      "Epoch 84/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9629 - loss: 0.0406 \n",
      "Epoch 85/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0916 \n",
      "Epoch 86/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0362 \n",
      "Epoch 87/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0222 \n",
      "Epoch 88/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0232 \n",
      "Epoch 89/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0887 \n",
      "Epoch 90/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0341 \n",
      "Epoch 91/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0548 \n",
      "Epoch 92/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0442 \n",
      "Epoch 93/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9629 - loss: 0.0659 \n",
      "Epoch 94/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9447 - loss: 0.1216 \n",
      "Epoch 95/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0223 \n",
      "Epoch 96/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0587 \n",
      "Epoch 97/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.0988  \n",
      "Epoch 98/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9826 - loss: 0.0557 \n",
      "Epoch 99/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0368  \n",
      "Epoch 100/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1003     \n",
      "Epoch 101/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0199 \n",
      "Epoch 102/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0339 \n",
      "Epoch 103/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0169\n",
      "Epoch 104/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.0490  \n",
      "Epoch 105/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0277 \n",
      "Epoch 106/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0182 \n",
      "Epoch 107/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0322\n",
      "Epoch 108/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0166 \n",
      "Epoch 109/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.0871 \n",
      "Epoch 110/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9826 - loss: 0.0301\n",
      "Epoch 111/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1576 \n",
      "Epoch 112/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0918 \n",
      "Epoch 113/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0725  \n",
      "Epoch 114/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0362     \n",
      "Epoch 115/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0481 \n",
      "Epoch 116/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.0563 \n",
      "Epoch 117/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0358 \n",
      "Epoch 118/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1082 \n",
      "Epoch 119/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0203 \n",
      "Epoch 120/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0102      \n",
      "Epoch 121/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0181 \n",
      "Epoch 122/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0485 \n",
      "Epoch 123/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0090     \n",
      "Epoch 124/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0058     \n",
      "Epoch 125/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0419 \n",
      "Epoch 126/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0957 \n",
      "Epoch 127/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0391 \n",
      "Epoch 128/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.0784     \n",
      "Epoch 129/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9439 - loss: 0.0743 \n",
      "Epoch 130/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 131/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1437 \n",
      "Epoch 132/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0236 \n",
      "Epoch 133/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0451 \n",
      "Epoch 134/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0279     \n",
      "Epoch 135/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0105 \n",
      "Epoch 136/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0339 \n",
      "Epoch 137/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0274 \n",
      "Epoch 138/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0061     \n",
      "Epoch 139/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0141 \n",
      "Epoch 140/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0131 \n",
      "Epoch 141/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0502 \n",
      "Epoch 142/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0158 \n",
      "Epoch 143/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0422 \n",
      "Epoch 144/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0130     \n",
      "Epoch 145/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0153 \n",
      "Epoch 146/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 147/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0213 \n",
      "Epoch 148/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.0424     \n",
      "Epoch 149/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0188 \n",
      "Epoch 150/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 151/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9862 - loss: 0.0463 \n",
      "Epoch 152/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0297 \n",
      "Epoch 153/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0220 \n",
      "Epoch 154/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0244 \n",
      "Epoch 155/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.0525     \n",
      "Epoch 156/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0164     \n",
      "Epoch 157/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.1620 \n",
      "Epoch 158/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0197 \n",
      "Epoch 159/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0182 \n",
      "Epoch 160/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0056     \n",
      "Epoch 161/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0095     \n",
      "Epoch 162/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0080     \n",
      "Epoch 163/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0071 \n",
      "Epoch 164/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0134 \n",
      "Epoch 165/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0154 \n",
      "Epoch 166/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0122     \n",
      "Epoch 167/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0381     \n",
      "Epoch 168/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0717 \n",
      "Epoch 169/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0094 \n",
      "Epoch 170/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0667 \n",
      "Epoch 171/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0116 \n",
      "Epoch 172/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0110 \n",
      "Epoch 173/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9780 - loss: 0.0322     \n",
      "Epoch 174/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0072 \n",
      "Epoch 175/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0093 \n",
      "Epoch 176/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0196 \n",
      "Epoch 177/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0312 \n",
      "Epoch 178/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0328  \n",
      "Epoch 179/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0062 \n",
      "Epoch 180/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0154 \n",
      "Epoch 181/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0153 \n",
      "Epoch 182/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9582 - loss: 0.1122      \n",
      "Epoch 183/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0198 \n",
      "Epoch 184/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0164     \n",
      "Epoch 185/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0298 \n",
      "Epoch 186/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0365 \n",
      "Epoch 187/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1334 \n",
      "Epoch 188/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0330 \n",
      "Epoch 189/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0158  \n",
      "Epoch 190/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0097 \n",
      "Epoch 191/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0262 \n",
      "Epoch 192/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0112 \n",
      "Epoch 193/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0602 \n",
      "Epoch 194/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0036 \n",
      "Epoch 195/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0098 \n",
      "Epoch 196/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0565     \n",
      "Epoch 197/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0253 \n",
      "Epoch 198/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0276 \n",
      "Epoch 199/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0174 \n",
      "Epoch 200/200\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0435 \n",
      "Model created and saved\n"
     ]
    }
   ],
   "source": [
    "# Define model structure\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(train_x.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(train_y.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile model with updated learning rate parameter\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# Train and save the model\n",
    "hist = model.fit(train_x, train_y, epochs=200, batch_size=5, verbose=1)\n",
    "model.save(f'{dataset_dir}/chatbot_model.keras', hist)\n",
    "\n",
    "print(\"Model created and saved\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation**\n",
    "\n",
    "**Overview**\n",
    "This section of the script defines, compiles, trains, and saves a neural network model for intent classification in a chatbot. The model is built using Keras and is designed to classify user input into predefined intents. By training on the `train_x` and `train_y` data, the model learns to associate different patterns of words with corresponding intents, making it suitable for use in a chatbot or other natural language understanding applications.\n",
    "\n",
    "**Step-by-Step Explanation of the Code**\n",
    "\n",
    "**1. Define Model Structure**\n",
    "\n",
    "This block defines a neural network model with multiple layers, using Keras' Sequential API to stack each layer in a linear progression:\n",
    "\n",
    "1. **Input Layer**:\n",
    "   - `Input(shape=(train_x.shape[1],))` specifies the input shape, which corresponds to the number of features in each training sample (the length of each \"bag of words\" vector in `train_x`).\n",
    "   - `train_x.shape[1]` gives the number of features (words) the model expects as input.\n",
    "\n",
    "2. **First Hidden Layer**:\n",
    "   - `Dense(128, activation='relu')` is a fully connected layer with 128 neurons and a ReLU activation function.\n",
    "   - The ReLU activation function introduces non-linearity, allowing the network to learn more complex patterns.\n",
    "\n",
    "3. **First Dropout Layer**:\n",
    "   - `Dropout(0.5)` is a dropout layer that randomly sets 50% of the input units to zero during training. This helps prevent overfitting by ensuring the model doesn’t rely too heavily on specific neurons.\n",
    "\n",
    "4. **Second Hidden Layer**:\n",
    "   - `Dense(64, activation='relu')` adds a second dense layer with 64 neurons and ReLU activation. This layer refines the learned features from the previous layer.\n",
    "\n",
    "5. **Second Dropout Layer**:\n",
    "   - `Dropout(0.5)` applies dropout again with a 50% dropout rate, further reducing overfitting by encouraging the model to generalize.\n",
    "\n",
    "6. **Output Layer**:\n",
    "   - `Dense(train_y.shape[1], activation='softmax')` is the output layer, where the number of neurons matches the number of unique classes (intents) in `train_y`.\n",
    "   - The `softmax` activation function outputs a probability distribution across the classes, making it suitable for multi-class classification. The model will output the probability of each intent, allowing the chatbot to select the most likely intent based on user input.\n",
    "\n",
    "**2. Compile the Model**\n",
    "\n",
    "In this step, the model is configured with an optimizer, loss function, and evaluation metric:\n",
    "\n",
    "1. **Optimizer**:\n",
    "   - The optimizer used is `SGD` (Stochastic Gradient Descent) with a learning rate of 0.01, momentum of 0.9, and Nesterov momentum enabled.\n",
    "   - **Momentum** helps accelerate the optimizer in the direction of the gradient, allowing it to navigate more effectively through shallow regions of the loss surface.\n",
    "   - **Nesterov Momentum** is a variation that looks ahead in the gradient direction, often resulting in faster convergence.\n",
    "\n",
    "2. **Loss Function**:\n",
    "   - `categorical_crossentropy` is used as the loss function because this is a multi-class classification problem. Categorical cross-entropy compares the predicted probability distribution of intents with the actual one-hot encoded distribution, guiding the model to adjust weights for better predictions.\n",
    "\n",
    "3. **Metrics**:\n",
    "   - `metrics=['accuracy']` tells Keras to calculate and display accuracy during training, allowing us to monitor how well the model is performing on the training data.\n",
    "\n",
    "**3. Train the Model**\n",
    "\n",
    "This line initiates the training process. The `fit()` function iteratively updates the model weights to minimize the loss on the training data:\n",
    "\n",
    "1. **Inputs (`train_x` and `train_y`)**:\n",
    "   - `train_x` contains the input patterns in the form of bag-of-words vectors.\n",
    "   - `train_y` contains the one-hot encoded labels for each intent.\n",
    "\n",
    "2. **Epochs**:\n",
    "   - `epochs=200` specifies that the model should go through the entire training dataset 200 times, giving it ample opportunity to learn the relationship between input patterns and intents.\n",
    "\n",
    "3. **Batch Size**:\n",
    "   - `batch_size=5` splits the training data into mini-batches of 5 samples. The model updates its weights after each batch, which can make training faster and reduce memory usage.\n",
    "\n",
    "4. **Verbosity**:\n",
    "   - `verbose=1` enables detailed logging of the training progress, allowing us to see the accuracy and loss values after each epoch.\n",
    "\n",
    "**4. Save the Model**\n",
    "\n",
    "After training, the model is saved to disk using `model.save()`. This allows the trained model to be loaded and used later for predictions without retraining. The model file is saved with the `.keras` extension, which stores the model architecture, weights, and optimizer state.\n",
    "\n",
    "- **File Path**:\n",
    "  - `f'{dataset_dir}/chatbot_model.keras'` saves the model in the specified directory with a filename of `chatbot_model.keras`.\n",
    "  \n",
    "**5. Print Confirmation**\n",
    "\n",
    "This line confirms that the model has been successfully created and saved, signaling the end of the training process.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "This section of the script builds, compiles, trains, and saves a neural network model for classifying intents in a chatbot. The model uses two hidden layers with dropout for regularization, and it outputs a probability distribution across possible intents. Training is performed over 200 epochs with mini-batches of size 5. The final model is saved to disk, making it ready for use in a chatbot application. \n",
    "\n",
    "This model structure and training configuration enable the chatbot to understand a variety of intents from user input and respond appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vowd9bYnqHAL"
   },
   "source": [
    "### 1.3.7. <a id='toc1_3_7_'></a>[**Predict The Responses**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FprArylxqHAL"
   },
   "source": [
    "#### 1.3.7.1. <a id='toc1_3_7_1_'></a>[**Load Required Python Modules**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yup_qQVlqHAL"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQrFgIE5qHAL"
   },
   "source": [
    "#### 1.3.7.2. <a id='toc1_3_7_2_'></a>[**Establish Environment Variables and Load Data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "__thxU4aqHAL"
   },
   "outputs": [],
   "source": [
    "# Define dataset directory\n",
    "dataset_dir = '/content'\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(f'{dataset_dir}/chatbot_model.keras')\n",
    "\n",
    "# Load words and classes\n",
    "with open(f'{dataset_dir}/words.pkl', 'rb') as f:\n",
    "    words = pickle.load(f)\n",
    "with open(f'{dataset_dir}/classes.pkl', 'rb') as f:\n",
    "    classes = pickle.load(f)\n",
    "\n",
    "# Load intents\n",
    "with open(f'{dataset_dir}/commands.json', 'r') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BQa5HEcqHAL"
   },
   "source": [
    "#### 1.3.7.3. <a id='toc1_3_7_3_'></a>[**Creat Prediction Functions**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rDpH-5R5qHAM"
   },
   "outputs": [],
   "source": [
    "# Function to clean up the sentence\n",
    "def clean_up_sentence(sentence):\n",
    "    # Tokenize the sentence\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # Lemmatize each word\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Function to create a bag of words from the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(f'found in bag: {w}')\n",
    "    return np.array(bag)\n",
    "\n",
    "# Function to predict the class\n",
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "# Function to get the response\n",
    "def get_response(intents_list, intents_json):\n",
    "    \"\"\"\n",
    "    Retrieves the chatbot's response based on predicted intent.\n",
    "\n",
    "    Args:\n",
    "        intents_list: A list of predicted intents.\n",
    "        intents_json: The JSON data containing intents and responses.\n",
    "\n",
    "    Returns:\n",
    "        The chatbot's response string.\n",
    "    \"\"\"\n",
    "    if intents_list:\n",
    "        tag = intents_list[0]['intent']\n",
    "        # Access the 'intents' key from the intents_json dictionary\n",
    "        # Previously: list_of_intents = intents_json['intents'] # intents_json is actually a list and not a dictionary\n",
    "        list_of_intents = intents_json.get('intents', []) # Get the 'intents' key from the dictionary 'intents' declared on line 12 of ipython-input-12-858ce5ee1d16\n",
    "                                                    # or assign an empty list in case of absence of an 'intents' key.\n",
    "        for i in list_of_intents:\n",
    "            if i['tag'] == tag:\n",
    "                result = random.choice(i['responses'])\n",
    "                break\n",
    "    else:\n",
    "        result = \"I don't understand, please try again.\"\n",
    "    return result\n",
    "\n",
    "# Function to chat with the model\n",
    "def chatbot_response(text):\n",
    "    \"\"\"\n",
    "    Gets the chatbot's response to the user's input.\n",
    "\n",
    "    Args:\n",
    "        text: The user's input text.\n",
    "\n",
    "    Returns:\n",
    "        The chatbot's response string.\n",
    "    \"\"\"\n",
    "    intents_list = predict_class(text, model)\n",
    "    # Pass the intents data (intents) loaded from JSON as the second argument\n",
    "    # Previously: response = get_response(intents, intents)\n",
    "    response = get_response(intents_list, intents) # Pass 'intents' variable from line 12 of ipython-input-12-858ce5ee1d16 to get_response() method.\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Explanation**\n",
    "\n",
    "**Overview**\n",
    "This script defines functions to process user input and generate a chatbot response based on a trained machine learning model. It includes functions to clean and tokenize input, convert text to a bag-of-words format, predict the most likely intent class, and retrieve a suitable response for the user. The script uses a trained model to classify intents and a JSON file containing the intent definitions and possible responses.\n",
    "\n",
    "**Step-by-Step Explanation of Each Function**\n",
    "\n",
    "**1. Function to Clean Up the Sentence**\n",
    "\n",
    "The `clean_up_sentence` function preprocesses user input to make it consistent with the training data. This ensures that the model receives clean, standardized text, helping to improve prediction accuracy.\n",
    "\n",
    "1. **Tokenization**: \n",
    "   - Uses `nltk.word_tokenize(sentence)` to split the sentence into individual words (tokens).\n",
    "   \n",
    "2. **Lemmatization**:\n",
    "   - Converts each word to lowercase and applies lemmatization using `lemmatizer.lemmatize(word.lower())`, which reduces words to their base form. This helps handle variations of the same word, like \"running\" and \"run,\" treating them as identical.\n",
    "\n",
    "The function returns a list of lemmatized words (tokens) from the input sentence.\n",
    "\n",
    "**2. Function to Create a Bag of Words from the Sentence**\n",
    "\n",
    "The `bow` (bag-of-words) function converts the input sentence into a numerical format that the model can understand.\n",
    "\n",
    "1. **Clean and Tokenize**:\n",
    "   - Calls `clean_up_sentence(sentence)` to preprocess the sentence and convert it into a list of lemmatized words.\n",
    "\n",
    "2. **Initialize Bag of Words**:\n",
    "   - Creates an array, `bag`, initialized with zeros. The length of `bag` matches the length of `words` (vocabulary).\n",
    "\n",
    "3. **Map Words to Bag of Words**:\n",
    "   - For each word in `sentence_words`, the function checks if it exists in the vocabulary (`words`). If it does, the corresponding index in `bag` is set to `1`.\n",
    "   - If `show_details` is set to `True`, the function prints each word that is found in `words`.\n",
    "\n",
    "The function returns a numpy array (`bag`) representing the presence or absence of each word from `words` in the input sentence.\n",
    "\n",
    "**3. Function to Predict the Class**\n",
    "\n",
    "The `predict_class` function uses the trained model to predict the most likely intent class for a given sentence.\n",
    "\n",
    "1. **Convert Sentence to Bag of Words**:\n",
    "   - Calls `bow(sentence, words, show_details=False)` to convert the sentence into the bag-of-words format.\n",
    "\n",
    "2. **Make Prediction**:\n",
    "   - Passes the bag-of-words vector to `model.predict(np.array([p]))[0]` to get prediction probabilities for each class.\n",
    "\n",
    "3. **Filter Predictions by Error Threshold**:\n",
    "   - Sets an `ERROR_THRESHOLD` to filter out low-confidence predictions. Only classes with prediction probabilities above `0.25` are kept.\n",
    "\n",
    "4. **Sort and Prepare Results**:\n",
    "   - Sorts the results in descending order based on confidence scores.\n",
    "   - Creates `return_list`, which stores dictionaries with \"intent\" and \"probability\" keys for each high-confidence prediction.\n",
    "\n",
    "The function returns `return_list`, a sorted list of possible intents with their respective confidence probabilities.\n",
    "\n",
    "**4. Function to Get the Response**\n",
    "\n",
    "The `get_response` function retrieves an appropriate response from `intents_json` based on the predicted intent.\n",
    "\n",
    "1. **Identify Top Intent**:\n",
    "   - Extracts the intent tag with the highest probability from `intents_list` (i.e., the first item in the list).\n",
    "\n",
    "2. **Search for Responses in JSON**:\n",
    "   - Searches for the matching intent in `intents_json['intents']`.\n",
    "   - If a match is found, the function randomly selects a response from `responses` associated with that intent.\n",
    "\n",
    "3. **Default Response**:\n",
    "   - If `intents_list` is empty, or no intent matches are found, a default message (\"I don't understand, please try again.\") is returned.\n",
    "\n",
    "The function returns the chatbot's response as a string.\n",
    "\n",
    "**5. Function to Chat with the Model**\n",
    "\n",
    "The `chatbot_response` function acts as the main interface for interacting with the chatbot. It handles user input, predicts the intent, and retrieves a response.\n",
    "\n",
    "1. **Predict Class**:\n",
    "   - Calls `predict_class(text, model)` to determine the most probable intent classes for the input `text`.\n",
    "\n",
    "2. **Get Response**:\n",
    "   - Calls `get_response(intents_list, intents)` to fetch a response based on the predicted intents.\n",
    "\n",
    "The function returns the chatbot’s response as a string.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary**\n",
    "This script processes user input, predicts the intent using a trained model, and returns a response from a predefined JSON file of intents and responses. The sequence of functions is as follows:\n",
    "1. **`clean_up_sentence`**: Tokenizes and lemmatizes user input.\n",
    "2. **`bow`**: Converts the sentence into a bag-of-words vector.\n",
    "3. **`predict_class`**: Predicts the intent class of the input using the model.\n",
    "4. **`get_response`**: Retrieves a response from the intents JSON file based on the predicted intent.\n",
    "5. **`chatbot_response`**: Coordinates these functions to provide a complete response to user input.\n",
    "\n",
    "This modular approach allows each function to perform a specific task, making the code easy to understand and maintain. The final result is a chatbot capable of understanding and responding to user intents based on predefined data and a trained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mccS_A_RqHAM"
   },
   "source": [
    "#### 1.3.7.4. <a id='toc1_3_7_4_'></a>[**Interactive loop for testing**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxdBXttkqHAM",
    "outputId": "d0b8b20b-5126-4c0c-834d-904fc19cd7a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is ready to chat! (Type 'exit' to stop)\n",
      "You: Hello\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Bot: Hi there, how can I help?\n",
      "You: Hey, is anyone there?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Hi there, how can I help?\n",
      "You: Hola\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Hello, thanks for asking\n",
      "You: Goodbye\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: See you!\n",
      "You: Nice chatting with you, bye!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Bye! Come back again soon.\n",
      "You: Till next time\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Bot: See you!\n",
      "You: Thank you for your help\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Happy to help!\n",
      "You: That's helpful\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Any time!\n",
      "You: Awesome, thanks\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Bot: My pleasure\n",
      "You: How can you help me?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
      "You: What support do you offer?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Bot: Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
      "You: What can you do?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
      "You: How do I check for adverse drug reactions?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Bot: Navigating to Adverse drug reaction module\n",
      "You: Can you open the adverse drugs module?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Navigating to Adverse drug reaction module\n",
      "You: Give me a list of drugs causing adverse reactions\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Bot: Navigating to Adverse drug reaction module\n",
      "You: Which drugs are suitable for a patient with adverse reactions?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Navigating to Adverse drug reaction module\n",
      "You: Can you manage blood pressure data?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Bot: Navigating to Blood Pressure module\n",
      "You: Show me the blood pressure results for a patient\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Patient ID?\n",
      "You: abc123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Good to see you again\n",
      "You: I want to log blood pressure results\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Navigating to Blood Pressure module\n",
      "You: Find a pharmacy for me\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Please provide pharmacy name\n",
      "You: CVS\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Bot: Good to see you again\n",
      "You: Locate nearby pharmacies\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Please provide pharmacy name\n",
      "You: CVS\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Bot: Good to see you again\n",
      "You: List pharmacies close by\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Please provide pharmacy name\n",
      "You: CVS\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Bot: Hello, thanks for asking\n",
      "You: Find me a hospital\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Please provide hospital name or location\n",
      "You: Community Health\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Hi there, how can I help?\n",
      "You: Look up hospital information for patient transfer\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Please provide hospital name or location\n",
      "You: Community Health\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: Hi there, how can I help?\n",
      "You: Can you book a table for me?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "Bot: I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies\n",
      "You: I need help with my car insurance\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Bot: Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
      "You: What’s the weather like?\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Bot: Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
      "You: Tell me a joke\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Bot: Bye! Come back again soon.\n",
      "You: Play some music\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Bot: Hi there, how can I help?\n",
      "You: exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"Chatbot is ready to chat! (Type 'exit' to stop)\")\n",
    "while True:\n",
    "    message = input(\"You: \")\n",
    "    if message.lower() == \"exit\":\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    response = chatbot_response(message)\n",
    "    print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49RmR3wVuwHd",
    "outputId": "5c90018e-5f03-4f88-87f6-cb3d34720100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n",
      "TensorFlow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
