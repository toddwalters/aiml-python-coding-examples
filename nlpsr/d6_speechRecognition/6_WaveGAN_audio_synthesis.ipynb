{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-g5omysaWXs"
   },
   "source": [
    "# <center> <font size = 24 color = 'steelblue'>**WaveGAN Audio Synthesis Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jRqvOnBasS6"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<font size = 4>\n",
    "\n",
    "**By the end of this notebook you will be able to:**\n",
    "\n",
    "- Learn how to synthesize short audio sounds of various types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaytJGMQfGMQ"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 4>\n",
    "\n",
    "**Note:**\n",
    "\n",
    "- **This notebook requires the use of a working GPU.**\n",
    "- **You may use AWS or Google colab.**\n",
    "\n",
    "To ensure colab is using GPU you may follw these steps: <br>\n",
    "    \n",
    "**Steps**: Runtime -> Change Runtime Type > Select GPU -> Save\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id= 'w0'> \n",
    "<font size = 4>\n",
    "    \n",
    "**Table of Contents:**<br>\n",
    "[1. Introduction](#w1)<br>\n",
    "[2. Load models](#w2)<br>\n",
    "[3. Tensorflow compatiility](#w3)<br>\n",
    "[4. Audio synthesis](#w4)<br>\n",
    "[5. Summary](#w5)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id = 'w1'>\n",
    "<font size = 10 color = 'midnightblue'> **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEU7auHDf4xP"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "\n",
    "- The authors of WaveGAN have meticulously trained separate models, each fine-tuned for a specific sound category.\n",
    "- This methodology guarantees that each model specializes in and excels at generating audio within its designated category.\n",
    "- In the upcoming code cell, you can explore these specialized models.\n",
    "- By specifying the 'dataset' field, you determine the pre-trained WaveGAN model to utilize.\n",
    "- The available options align with various sound categories, enabling the generation of representative audio from the chosen category:\n",
    ">*   digits\n",
    ">*   speech\n",
    ">*   birds\n",
    ">*   drums\n",
    ">*   piano\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJxWzrFfbObL"
   },
   "outputs": [],
   "source": [
    "dataset = 'drums' # one of 'digits', 'speech', 'birds', 'drums', 'piano'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwXHbX1epaP7"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 4>\n",
    "\n",
    "**GPU Check**\n",
    "\n",
    "- To ensure efficient audio synthesis and processing, this notebook is designed to run on a GPU-accelerated environment.\n",
    "- The next code cell performs a check to verify if the session is currently utilizing GPU support. \n",
    "- If a GPU is not detected, it will print a notification message guiding you to enable GPU acceleration. \n",
    "\n",
    "**This step is crucial as it ensures that the WaveGAN models operate with the expected speed and performance.**\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRGgTM3dpOdc"
   },
   "outputs": [],
   "source": [
    "# Confirm GPU is running\n",
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "if len(get_available_gpus()) == 0:\n",
    "  print('GPU missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VblR5JaEqUCM"
   },
   "source": [
    "##### <a id = 'w2'>\n",
    "<font size = 10 color = 'midnightblue'> **Load Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VblR5JaEqUCM"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "\n",
    "- Audio synthesis involves the use of a pre-trained GAN model, specifically trained on a dataset matching the chosen sound category from previous steps.\n",
    "- The following code cell is tasked with retrieving the required pre-trained model artifacts for the synthesis process.\n",
    "- Upon execution, it automatically downloads the model parameters linked to the chosen dataset.\n",
    "- These artifacts, containing learned weights, are crucial as they empower the WaveGAN to generate new audio samples from random noise inputs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuGxBn-Ppvc5",
    "outputId": "3a56ea97-384f-4f9c-c0c5-15eb6fe19fc9"
   },
   "outputs": [],
   "source": [
    "# Download model\n",
    "if dataset == 'digits':\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/sc09.ckpt.index -O model.ckpt.index\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/sc09.ckpt.data-00000-of-00001 -O model.ckpt.data-00000-of-00001\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/sc09_infer.meta -O infer.meta\n",
    "elif dataset == 'speech':\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/timit.ckpt.index -O model.ckpt.index\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/timit.ckpt.data-00000-of-00001 -O model.ckpt.data-00000-of-00001\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/timit_infer.meta -O infer.meta\n",
    "elif dataset == 'birds':\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/birds.ckpt.index -O model.ckpt.index\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/birds.ckpt.data-00000-of-00001 -O model.ckpt.data-00000-of-00001\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/birds_infer.meta -O infer.meta\n",
    "elif dataset == 'drums':\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/drums.ckpt.index -O model.ckpt.index\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/drums.ckpt.data-00000-of-00001 -O model.ckpt.data-00000-of-00001\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/drums_infer.meta -O infer.meta\n",
    "elif dataset == 'piano':\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/piano.ckpt.index -O model.ckpt.index\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/piano.ckpt.data-00000-of-00001 -O model.ckpt.data-00000-of-00001\n",
    "  !wget https://s3.amazonaws.com/wavegan-v1/models/piano_infer.meta -O infer.meta\n",
    "else:\n",
    "  raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRm2jpPisB3z"
   },
   "source": [
    "##### <a id = 'w3'>\n",
    "<font size = 10 color = 'midnightblue'> **Tensorflow Compatiility**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRm2jpPisB3z"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 4>\n",
    "\n",
    "**Note:**\n",
    "- The WaveGAN model was initially implemented using TensorFlow 1.x, but it isn't directly compatible with TensorFlow 2.x.\n",
    "- As Google Colab has phased out support for TensorFlow 1.x, we must utilize TensorFlow 1.x compatibility mode within TensorFlow 2.x for this notebook.\n",
    "- This mode, accessible through the tf.compat.v1 module, allows the execution of TensorFlow 1.x code in a TensorFlow 2.x environment.\n",
    "- The provided code snippet guarantees smooth operation with the WaveGAN model without encountering version conflicts.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkg8K8SlrvNh"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "if tf.executing_eagerly():\n",
    "   tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOksTNC7sboZ",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "\n",
    "**In this section, the loading of the pre-trained WaveGAN model will be executed.**\n",
    "- The TensorFlow session is initialized in the code cell below, and the model checkpoint, previously downloaded, is restored.\n",
    "- This crucial step involves loading the learned weights into the session, providing our environment with the generative capabilities of WaveGAN.\n",
    "- After the session is established, and the model is loaded, the environment will be prepared for audio generation from random noise vectors.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size =6 color = 'seagreen'> **Load Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HzeV6hwLsD9U"
   },
   "outputs": [],
   "source": [
    "saver = tf.compat.v1.train.import_meta_graph('infer.meta')\n",
    "graph = tf.get_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "saver.restore(sess, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLsBLdB_t1w9"
   },
   "source": [
    "##### <a id = 'w4'>\n",
    "<font size = 10 color = 'midnightblue'> **Audio Synthesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLsBLdB_t1w9"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "**The generation of audio**\n",
    "- With the successful loading of the model checkpoint and the activation of our TensorFlow session, we are poised to generate new sounds using the pre-trained WaveGAN model.\n",
    "- This creative process will be initiated in the upcoming code cell, synthesizing audio from the trained model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5XSHYkS8tgdD",
    "outputId": "888bffac-5e62-4ac3-985d-81be7f26ce10"
   },
   "outputs": [],
   "source": [
    "# Generate and display audio\n",
    "\n",
    "# CHANGE THESE to change number of examples generated/displayed\n",
    "ngenerate = 64\n",
    "ndisplay = 4\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from IPython.display import display, Audio\n",
    "import time as time\n",
    "\n",
    "# Sample latent vectors\n",
    "_z = (np.random.rand(ngenerate, 100) * 2.) - 1.\n",
    "\n",
    "# Generate\n",
    "z = graph.get_tensor_by_name('z:0')\n",
    "G_z = graph.get_tensor_by_name('G_z:0')[:, :, 0]\n",
    "G_z_spec = graph.get_tensor_by_name('G_z_spec:0')\n",
    "\n",
    "start = time.time()\n",
    "_G_z, _G_z_spec = sess.run([G_z, G_z_spec], {z: _z})\n",
    "print('Finished! (Took {} seconds)'.format(time.time() - start))\n",
    "\n",
    "for i in range(ndisplay):\n",
    "  print('-' * 80)\n",
    "  print('Example {}'.format(i))\n",
    "  display(PIL.Image.fromarray(_G_z_spec[i]))\n",
    "  display(Audio(_G_z[i], rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id = 'w5'>\n",
    "<font size = 10 color = 'midnightblue'> **Summary:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4-zQhDG1y_L"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "<font size = 4>\n",
    "    \n",
    "- In this notebook, the synthesis of audio samples across various sound categories using the WaveGAN model has been demonstrated.\n",
    "- The generated samples, as observed, were limited to a one-second duration.\n",
    "- It is important to note that WaveGAN can be trained for the production of longer audio clips, extending to several seconds.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 6>\n",
    "    <b>Side Note:</b>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4-zQhDG1y_L"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 4>\n",
    "    \n",
    "- For those interested in further exploration, you have the opportunity to train WaveGAN on your own dataset or experiment with existing ones. \n",
    "- For this, you can refer to the [official TensorFlow implementation of WaveGAN](https://github.com/chrisdonahue/wavegan). \n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4-zQhDG1y_L"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"> \n",
    "<font size = 4>\n",
    "\n",
    "**Please keep in mind the following prerequisites:**\n",
    "\n",
    "\n",
    "*   Access to a GPU: Since audio generation and training processes are\n",
    "computationally intensive, having a GPU will significantly speed up your experiments.\n",
    "*   TensorFlow 1.x for GPU: The official WaveGAN is not yet compatible with TensorFlow 2.x. Therefore, you will need to install TensorFlow 1.x specifically designed for GPU usage to ensure optimal performance and compatibility.\n",
    "\n",
    "\n",
    "By meeting these requirements, you'll be well-equipped to dive deeper into the audio synthesis with WaveGAN.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZRmUbcHvtZ4",
    "tags": []
   },
   "source": [
    "[top](#w0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
