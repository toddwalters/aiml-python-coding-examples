{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHsANDDZr12r"
   },
   "source": [
    "## __Model-Based Collaborative Filtering__ ##\n",
    "Let's understand the collaborative filtering in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8yAGAmK_in2"
   },
   "source": [
    "## Step 1: Import Required Libraries\n",
    "\n",
    "- Import pandas and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jrb3hVCn-vBQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcVMABrF_nrz"
   },
   "source": [
    "## Step 2: Load and Inspect the Data\n",
    "\n",
    "- Load the dataset with the given header\n",
    "- Print the head of the DataFrame\n",
    "- Calculate the number of unique users and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1683085202618,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "e3F5Ppct-vBR",
    "outputId": "b40cdb56-9c72-444e-e181-511a9b05a226"
   },
   "outputs": [],
   "source": [
    "header =['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df  = pd.read_csv('u.data', sep='\\t', names=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1IL5ulVPsjUq"
   },
   "source": [
    "__Observations:__\n",
    "- Here, we can see a few rows of the dataset.\n",
    "- The data contains user_id, item_id, rating, and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eEqPTFL-vBT"
   },
   "outputs": [],
   "source": [
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQoWI8sytDcg"
   },
   "source": [
    "__Observation:__\n",
    "- Here, we have created n users and n items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users,n_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU9FDxZG_ylj"
   },
   "source": [
    "## Step 3: Split the Data into Train and Test Sets\n",
    "\n",
    "- Import **train_test_split**\n",
    "- Split the data into **train_data** and **test_data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvwTw92Q-vBT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eKfLWhvtnPe"
   },
   "source": [
    "__Observation:__\n",
    "- Here, we have split the data into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkVttxmH_1PO"
   },
   "source": [
    "## Step 4: Create a Matrix for Train and Test Data\n",
    "\n",
    "- Initialize **train_data_mat** and **test_data_mat** with zeros\n",
    "- Fill the matrices with the corresponding ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWMXTzd1-vBT"
   },
   "outputs": [],
   "source": [
    "train_data_mat = np.zeros((n_users, n_items))\n",
    "for line in train_data.itertuples():\n",
    "    train_data_mat[line[1]-1, line[2]-1] = line[3]\n",
    "                      \n",
    "test_data_mat = np.zeros((n_users, n_items))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_mat[line[1]-1, line[2]-1] = line[3]                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4cAydDS_76A"
   },
   "source": [
    "## Step 5: Define the RMSE Function\n",
    "\n",
    "- Import mean_squared_error\n",
    "- Define the rmse function to calculate the root mean squared error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KqHx2xF-vBU"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwiWS6NxABWR"
   },
   "source": [
    "## Step 6: Check the Sparsity for the Dataset\n",
    "\n",
    "- Calculate the sparsity of the **MovieLens100K** dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 415,
     "status": "ok",
     "timestamp": 1683085671901,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "zTODJ9o9Br5w",
    "outputId": "000e6f36-a417-481e-96d5-5630c4353072"
   },
   "outputs": [],
   "source": [
    "sparsity = round(1.0-len(df)/float(n_users*n_items), 3)\n",
    "print('The sparsity level of MovieLens100K is ' + str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-55tMT1zuYCS"
   },
   "source": [
    "__Observation:__\n",
    "- As shown, the sparsity level of **MovieLens100K** is 93.7%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_sfOw95ADVb"
   },
   "source": [
    "## Step 7: Apply SVD and Calculate RMSE\n",
    "\n",
    "- Import svds\n",
    "- Apply SVD to the **train_data_mat** and choose k\n",
    "- Calculate the prediction matrix **X_pred**\n",
    "- Calculate the RMSE between **X_pred** and **test_data_mat**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1683085938401,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "80_SAsGWEC-Q",
    "outputId": "e75c1f97-ec2d-48ce-ae79-ad8426574660"
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "u, s, vt = svds(train_data_mat,k=20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt) # Generate\n",
    "print('User-based CF MSE: ' + str(rmse(X_pred, test_data_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGvi4oOKuya7"
   },
   "source": [
    "__Observation:__\n",
    "- Here, we have calculated the RMSE between X_pred and test_data_mat, which is 2.71."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
