{"cells":[{"cell_type":"markdown","source":["#**Demo: Text Generation**\n","\n","This demonstration employs the Natural Language Toolkit (NLTK) and the Brown corpus to demonstrate text generation through a Markov chain model using trigrams."],"metadata":{"id":"CHNX4Tn4cPb1"},"id":"CHNX4Tn4cPb1"},{"cell_type":"markdown","source":["##**Steps to Perform:**\n","\n","Step 1: Import the Necessary Libraries\n","\n","Step 2: Define Stopwords and Punctuation\n","\n","Step 3: Load Sentences and Generate N-grams\n","\n","Step 4: Remove Stopwords from N-grams\n","\n","Step 5: Calculate Frequency Distributions\n","\n","Step 6: Create a Dictionary of Trigram Frequencies\n","\n","Step 7: Define the Text Generation Function\n","\n","Step 8: Execute the Text Generation Function"],"metadata":{"id":"k-2DSxXRc1gn"},"id":"k-2DSxXRc1gn"},{"cell_type":"markdown","source":["###**Step 1: Import the Necessary Libraries**\n","\n","\n","\n","\n","\n","*   Import the necessary libraries and set up the OpenAI API key.\n","*   Download the necessary NLTK packages and corpus.\n","\n"],"metadata":{"id":"F77eQldddrgN"},"id":"F77eQldddrgN"},{"cell_type":"code","source":["# Import necessary libraries\n","import string\n","import random\n","import nltk\n","from nltk import FreqDist\n","from nltk.corpus import brown\n","from collections import defaultdict, Counter\n","from nltk.util import ngrams\n","\n","# Download necessary NLTK packages and corpus\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('brown')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgPYiaZsc-3O","outputId":"537d95f6-a6b4-4832-eb0c-b12618f5c381"},"id":"PgPYiaZsc-3O","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Package brown is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["###**Step 2: Define Stopwords and Punctuation**\n","\n","*   Stopwords are common words in a language that are often considered to be of little value in text analysis.\n","*   Punctuation refers to characters used to separate sentences, clauses, phrases, or words in writing.\n","\n","\n","\n"],"metadata":{"id":"QuDAtVJAeKPZ"},"id":"QuDAtVJAeKPZ"},{"cell_type":"code","source":["# Define stopwords and punctuation\n","stop_words = set(nltk.corpus.stopwords.words('english'))\n","string.punctuation += '\"\\'-â€”'\n","removal_list = list(stop_words) + list(string.punctuation) + ['lt', 'rt']\n"],"metadata":{"id":"2MHWS4tUeZYO"},"id":"2MHWS4tUeZYO","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 3: Load Sentences and Generate N-grams**\n","\n","*   Load sentences from the Brown corpus and generate N-grams.\n","*   By the end of this process, **unigram**, **bigram**, and **trigram** lists will contain the respective N-grams for the sentences in the Brown corpus.\n","\n","\n","\n"],"metadata":{"id":"BD7fr4rheeOW"},"id":"BD7fr4rheeOW"},{"cell_type":"code","source":["# Load sentences from the Brown corpus\n","sents = brown.sents()\n","\n","# Initialize lists for storing n-grams\n","unigram = []\n","bigram = []\n","trigram = []\n","\n","# Generate n-grams\n","for sentence in sents:\n","    sentence = [word.lower() for word in sentence if word not in string.punctuation]\n","    unigram.extend(sentence)\n","    bigram.extend(list(ngrams(sentence, 2, pad_left=True, pad_right=True)))\n","    trigram.extend(list(ngrams(sentence, 3, pad_left=True, pad_right=True)))\n"],"metadata":{"id":"pTKPSbw_elM2"},"id":"pTKPSbw_elM2","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 4: Remove Stopwords from N-grams**\n","\n","*   Define a function to remove stopwords from the N-grams.\n","*   Use it to clean the bigrams and trigrams.\n","\n","\n","\n"],"metadata":{"id":"oXbe4Qgpepzk"},"id":"oXbe4Qgpepzk"},{"cell_type":"code","source":["# Function to remove stopwords from n-grams\n","def remove_stopwords(ngrams, n):\n","    if n == 2:\n","        return [(a, b) for (a, b) in ngrams if a not in removal_list and b not in removal_list]\n","    elif n == 3:\n","        return [(a, b, c) for (a, b, c) in ngrams if a not in removal_list and b not in removal_list and c not in removal_list]\n","\n","# Remove stopwords from n-grams\n","bigram = remove_stopwords(bigram, 2)\n","trigram = remove_stopwords(trigram, 3)\n"],"metadata":{"id":"6VHX-QXhe86T"},"id":"6VHX-QXhe86T","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 5: Calculate Frequency Distributions**\n","\n","*   Calculate the frequency distributions of the bigrams and trigrams.\n","\n"],"metadata":{"id":"FLLxqiIufGp-"},"id":"FLLxqiIufGp-"},{"cell_type":"code","source":["# Calculate frequency distributions\n","freq_bi = FreqDist(bigram)\n","freq_tri = FreqDist(trigram)\n"],"metadata":{"id":"Zmq_1nIWfNg4"},"id":"Zmq_1nIWfNg4","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 6: Create a Dictionary of Trigram Frequencies**\n","\n","*   Create a dictionary of trigram frequencies to use it in the text generation function.\n","\n"],"metadata":{"id":"sB-t5lnjfP_V"},"id":"sB-t5lnjfP_V"},{"cell_type":"code","source":["# Create a dictionary of trigram frequencies\n","d = defaultdict(Counter)\n","for ngram in freq_tri:\n","    if None not in ngram:\n","        d[ngram[:-1]][ngram[-1]] += freq_tri[ngram]\n"],"metadata":{"id":"DyEVQsOxfaUq"},"id":"DyEVQsOxfaUq","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 7: Define the Text Generation Function**\n","\n","*   Define the **generate_text** function to generate text based on the trigram frequencies.\n","\n"],"metadata":{"id":"5tcWjGz8fd4l"},"id":"5tcWjGz8fd4l"},{"cell_type":"code","source":["# Function to generate text\n","def generate_text(prefix, n=20):\n","    for _ in range(n):\n","        suffix_candidates = list(d.get(prefix, Counter()).elements())\n","        if not suffix_candidates:\n","            new_prefix = random.choice(unigram), random.choice(unigram)\n","            yield new_prefix[0]  # Yield the first word of the new prefix\n","            prefix = new_prefix\n","        else:\n","            suffix = random.choice(suffix_candidates)\n","            yield suffix\n","            prefix = (*prefix[1:], suffix)\n"],"metadata":{"id":"45E4k0DEfnZM"},"id":"45E4k0DEfnZM","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Step 8: Execute the Text Generation Function**\n","\n","*   Call the **generate_text** function and print the generated text.\n","\n"],"metadata":{"id":"vdBJRj6AftiC"},"id":"vdBJRj6AftiC"},{"cell_type":"code","source":["# Generate text\n","prefix = (\"he\", \"said\")\n","generated_text = list(generate_text(prefix))\n","if generated_text:\n","    print(\" \".join(generated_text))\n","else:\n","    print(\"No text generated.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2OXd5-fVgDJX","outputId":"7c8cc821-c459-42ca-a22f-49c05ee1630a"},"id":"2OXd5-fVgDJX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["plague blue mortgage of not is tonight '' even women other glowed larger joined the the himself to of young\n"]}]},{"cell_type":"markdown","source":["##**Conclusion**\n","\n","This demo showcases NLTK and the Brown corpus for trigram-based Markov chain text generation. Users can run it multiple times to observe the varying generated outputs."],"metadata":{"id":"jozwTLaJUxPo"},"id":"jozwTLaJUxPo"}],"metadata":{"kernelspec":{"display_name":"Python 3 [3.10]","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}