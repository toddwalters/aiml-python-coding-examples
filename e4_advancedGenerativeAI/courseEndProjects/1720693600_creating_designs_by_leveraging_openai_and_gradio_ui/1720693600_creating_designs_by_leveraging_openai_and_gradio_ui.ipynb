{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Designs by Leveraging OpenAI and Gradio UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this project, we explore how to leverage OpenAI's API (specifically DALL-E) and Gradio's UI\n",
    "to create a platform that generates bespoke images from user-provided text prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Import Essential Libraries\n",
    "\n",
    "We need the following libraries:\n",
    "- openai: for accessing OpenAI's API (DALL-E),\n",
    "- requests: for making HTTP requests to retrieve generated images,\n",
    "- PIL (from Pillow): for manipulating and displaying images,\n",
    "- io.BytesIO: for handling binary data (image files in memory),\n",
    "- gradio: for building a user-friendly web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/1720693600_20241227_v2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai gradio  # Uncomment if you need to install in a fresh environment\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import logging\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for debugging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Configure OpenAI API Key\n",
    "\n",
    "Your API key is required for authenticating requests to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'Say this is a test'}], 'model': 'gpt-4'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1687c2da0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12df46e40> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1684bf130>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OpenAI API key is: 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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 28 Dec 2024 03:32:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-ztpe5ooam4prp064o0jksrvw'), (b'openai-processing-ms', b'429'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'40000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'39978'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'33ms'), (b'x-request-id', b'req_bc1d9cffd11c4ba05f3de281dfc8da1f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Ge2NyEUKKJsVqTCUGSs3LTPzzgLUeK4aqH3VNNwSRbs-1735356754-1.0.1.1-lu.45UEoG8rIcx.Zr0YITQVoLWvhUWyeH7Ky5vRvhCaiOoqW.zVLh70XZ.94IlEAm585hnyydj39ikAI2VQLlA; path=/; expires=Sat, 28-Dec-24 04:02:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=kDqubBxuPxrTTft7IOlzr4RAG9IjyQM5nouZqPAYkjM-1735356754797-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8e7be27f3ce806-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers([('date', 'Sat, 28 Dec 2024 03:32:34 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-ztpe5ooam4prp064o0jksrvw'), ('openai-processing-ms', '429'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '5000'), ('x-ratelimit-limit-tokens', '40000'), ('x-ratelimit-remaining-requests', '4999'), ('x-ratelimit-remaining-tokens', '39978'), ('x-ratelimit-reset-requests', '12ms'), ('x-ratelimit-reset-tokens', '33ms'), ('x-request-id', 'req_bc1d9cffd11c4ba05f3de281dfc8da1f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Ge2NyEUKKJsVqTCUGSs3LTPzzgLUeK4aqH3VNNwSRbs-1735356754-1.0.1.1-lu.45UEoG8rIcx.Zr0YITQVoLWvhUWyeH7Ky5vRvhCaiOoqW.zVLh70XZ.94IlEAm585hnyydj39ikAI2VQLlA; path=/; expires=Sat, 28-Dec-24 04:02:34 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=kDqubBxuPxrTTft7IOlzr4RAG9IjyQM5nouZqPAYkjM-1735356754797-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8f8e7be27f3ce806-ORD'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=\":443\"; ma=86400')])\n",
      "DEBUG:openai._base_client:request_id: req_bc1d9cffd11c4ba05f3de281dfc8da1f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(verbose=True, dotenv_path='.env', override=True)\n",
    "\n",
    "# Retrieve the API key from the environment\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"API key not found. Please ensure 'OPENAI_API_KEY' is set in your .env file.\")\n",
    "\n",
    "# Create the OpenAI client with the API key\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "def test_openai_api():\n",
    "    try:\n",
    "        # Create a chat completion\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": \"Say this is a test\"},\n",
    "            ],\n",
    "        )\n",
    "        # Print the response content\n",
    "        print(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the test function\n",
    "test_openai_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Define the Image Generation Function\n",
    "\n",
    "This function takes a text prompt, calls DALL-E to generate an image, \n",
    "retrieves the image from the returned URL, and returns it as a Pillow Image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/images/generations', 'files': None, 'json_data': {'prompt': 'a magical warrior using the mystical art of elemancy to create a magical shield', 'model': 'dall-e-3', 'n': 1, 'quality': 'standard', 'size': '1024x1024'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/images/generations\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1684c0fa0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12e7f2140> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a261300>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 28 Dec 2024 05:29:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-ztpe5ooam4prp064o0jksrvw'), (b'x-request-id', b'req_cdcff9a66326c8723b8ab6ed3bf1e6b8'), (b'openai-processing-ms', b'12928'), (b'access-control-allow-origin', b'*'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8f276a6c11eac2-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/images/generations \"200 OK\" Headers({'date': 'Sat, 28 Dec 2024 05:29:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-ztpe5ooam4prp064o0jksrvw', 'x-request-id': 'req_cdcff9a66326c8723b8ab6ed3bf1e6b8', 'openai-processing-ms': '12928', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f8f276a6c11eac2-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_cdcff9a66326c8723b8ab6ed3bf1e6b8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-Iq1uO7WbCp63z9DylfKy92ZE/user-Ztpe5OoAm4prp064o0jkSRVw/img-ytWm3pPGb0En6vdpsNRiuMdS.png?st=2024-12-28T04%3A29%3A53Z&se=2024-12-28T06%3A29%3A53Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-27T20%3A43%3A00Z&ske=2024-12-28T20%3A43%3A00Z&sks=b&skv=2024-08-04&sig=SpxOafjo%2B5vnENDM9dbt4nXk62L1ixuLvRmQjo7ntGw%3D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): oaidalleapiprodscus.blob.core.windows.net:443\n",
      "DEBUG:urllib3.connectionpool:https://oaidalleapiprodscus.blob.core.windows.net:443 \"GET /private/org-Iq1uO7WbCp63z9DylfKy92ZE/user-Ztpe5OoAm4prp064o0jkSRVw/img-ytWm3pPGb0En6vdpsNRiuMdS.png?st=2024-12-28T04%3A29%3A53Z&se=2024-12-28T06%3A29%3A53Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-27T20%3A43%3A00Z&ske=2024-12-28T20%3A43%3A00Z&sks=b&skv=2024-08-04&sig=SpxOafjo%2B5vnENDM9dbt4nXk62L1ixuLvRmQjo7ntGw%3D HTTP/1.1\" 200 1959002\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'caBX' 41 14823\n",
      "DEBUG:PIL.PngImagePlugin:b'caBX' 41 14823 (unknown)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 14876 65536\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "def generate_image(prompt):\n",
    "    \"\"\"\n",
    "    Generates an image based on the specified text prompt using OpenAI's image generation API.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The text prompt describing the desired image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: A PIL image generated from the prompt.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate the prompt input\n",
    "        if not prompt.strip():\n",
    "            raise ValueError(\"Prompt cannot be empty.\")\n",
    "\n",
    "        # Call OpenAI to create the image\n",
    "        response = client.images.generate(\n",
    "            model='dall-e-3',\n",
    "            prompt=prompt,\n",
    "            size=\"512x512\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "\n",
    "        # Extract the image URL from the response\n",
    "        image_url = response.data[0].url\n",
    "        # print(f\"Image URL: {image_url}\")\n",
    "\n",
    "        # Fetch the image from the URL\n",
    "        image_response = requests.get(image_url)\n",
    "        image_response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "        # Convert the image to a PIL object and return\n",
    "        img = Image.open(BytesIO(image_response.content))\n",
    "        return img\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error and return a placeholder image\n",
    "        print(f\"Error: {e}\")\n",
    "        return create_error_image(str(e))\n",
    "\n",
    "\n",
    "def create_error_image(message):\n",
    "    \"\"\"\n",
    "    Creates a placeholder image with an error message.\n",
    "    \"\"\"\n",
    "    from PIL import ImageDraw\n",
    "\n",
    "    img = Image.new('RGB', (512, 512), color=(255, 0, 0))  # Red background\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.text((10, 10), f\"Error: {message}\", fill=(255, 255, 255))  # White text\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt=\"A surreal landscape with floating islands and a pink sky\"\n",
    "# img = generate_image(prompt)\n",
    "# display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Create the Gradio Interface\n",
    "\n",
    "We'll set up a Gradio interface with:\n",
    "- A text input box for the user prompt\n",
    "- An image output to display the generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n",
      "DEBUG:urllib3.connectionpool:https://api.gradio.app:443 \"GET /pkg-version HTTP/1.1\" 200 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.50.2, however version 4.44.1 is available, please upgrade.\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.gradio.app:443 \"POST /gradio-initiated-analytics/ HTTP/1.1\" 200 None\n"
     ]
    }
   ],
   "source": [
    "# Set up the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=generate_image,     # The function that handles generation\n",
    "    inputs=\"text\",         # We'll take a simple text string as input\n",
    "    outputs=\"image\",       # We'll return a generated image\n",
    "    title=\"AI-Generated Designs for Netflix Campaigns\",\n",
    "    description=(\n",
    "        \"Enter a detailed text prompt describing the design you'd like to see. \"\n",
    "        \"For instance, 'a futuristic cityscape with neon lights, in the style of cyberpunk' \"\n",
    "        \"or 'a minimalist poster featuring a detective theme for a new Netflix series.'\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Launch the Gradio Interface\n",
    "\n",
    "Running `launch()` will start a local web server (and display a shareable link in some environments).\n",
    "Clicking the link will open the Gradio interface where you can enter prompts and see generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:asyncio:Using selector: KqueueSelector\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:7866\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:7866 \"GET /startup-events HTTP/1.1\" 200 5\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): 127.0.0.1:7866\n",
      "DEBUG:urllib3.connectionpool:http://127.0.0.1:7866 \"HEAD / HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.gradio.app:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://api.gradio.app:443 \"POST /gradio-launched-telemetry/ HTTP/1.1\" 200 None\n",
      "DEBUG:matplotlib.pyplot:Loaded backend agg version v2.2.\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/images/generations', 'files': None, 'json_data': {'prompt': 'a magical warrior using the mystical art of elemancy to create a magical shield', 'model': 'dall-e-3', 'n': 1, 'quality': 'standard', 'size': '1024x1024'}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/images/generations\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a4804c0>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12e7f2140> server_hostname='api.openai.com' timeout=5.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x16a83e6b0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sat, 28 Dec 2024 05:26:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'user-ztpe5ooam4prp064o0jksrvw'), (b'x-request-id', b'req_e05888f7f6f65842bf56c77dbb6b80f2'), (b'openai-processing-ms', b'13047'), (b'access-control-allow-origin', b'*'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8f8f22830b7a22c3-ORD'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/images/generations \"200 OK\" Headers({'date': 'Sat, 28 Dec 2024 05:26:32 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-version': '2020-10-01', 'openai-organization': 'user-ztpe5ooam4prp064o0jksrvw', 'x-request-id': 'req_e05888f7f6f65842bf56c77dbb6b80f2', 'openai-processing-ms': '13047', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8f8f22830b7a22c3-ORD', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_e05888f7f6f65842bf56c77dbb6b80f2\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): oaidalleapiprodscus.blob.core.windows.net:443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-Iq1uO7WbCp63z9DylfKy92ZE/user-Ztpe5OoAm4prp064o0jkSRVw/img-rPleViQzcDLMDLigdCVJIUUW.png?st=2024-12-28T04%3A26%3A32Z&se=2024-12-28T06%3A26%3A32Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-27T20%3A52%3A27Z&ske=2024-12-28T20%3A52%3A27Z&sks=b&skv=2024-08-04&sig=KO15x1QD0y9JhP4CIqRtS/lkjak7HDvACy1KWonUYkU%3D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://oaidalleapiprodscus.blob.core.windows.net:443 \"GET /private/org-Iq1uO7WbCp63z9DylfKy92ZE/user-Ztpe5OoAm4prp064o0jkSRVw/img-rPleViQzcDLMDLigdCVJIUUW.png?st=2024-12-28T04%3A26%3A32Z&se=2024-12-28T06%3A26%3A32Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-12-27T20%3A52%3A27Z&ske=2024-12-28T20%3A52%3A27Z&sks=b&skv=2024-08-04&sig=KO15x1QD0y9JhP4CIqRtS/lkjak7HDvACy1KWonUYkU%3D HTTP/1.1\" 200 2024602\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IHDR' 16 13\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'caBX' 41 14823\n",
      "DEBUG:PIL.PngImagePlugin:b'caBX' 41 14823 (unknown)\n",
      "DEBUG:PIL.PngImagePlugin:STREAM b'IDAT' 14876 65536\n",
      "DEBUG:matplotlib.pyplot:Loaded backend inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend agg version v2.2.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Result\n",
    "\n",
    "By completing this notebook, I have illustrated the powerful synergy between OpenAI’s DALL-E\n",
    "and Gradio’s UI. This platform enables designers to quickly prototype and generate custom \n",
    "visual content for high-profile marketing campaigns, such as those by Netflix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1720693600_20241227_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
