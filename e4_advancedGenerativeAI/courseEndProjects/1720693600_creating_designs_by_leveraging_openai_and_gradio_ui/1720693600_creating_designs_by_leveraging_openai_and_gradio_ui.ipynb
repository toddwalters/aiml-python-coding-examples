{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Netflix Campaign Design Generator\n",
    "\n",
    "## Using OpenAI DALL-E and Gradio UI\n",
    "\n",
    "This notebook implements an AI-powered design generation tool for Netflix marketing campaigns. We'll build this step by step with detailed explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup and Imports\n",
    "\n",
    "This section sets up our development environment by importing necessary Python libraries:\n",
    "\n",
    "Code Breakdown:\n",
    "- `os`: Provides functions for interacting with the operating system (used for environment variables)\n",
    "- `dataclasses`: Provides the @dataclass decorator for creating data classes\n",
    "- `typing`: Provides type hints (Dict, List, Optional, Tuple) for better code documentation\n",
    "- `dotenv`: Helps manage environment variables from a .env file\n",
    "- `openai`: The OpenAI API client for accessing DALL-E\n",
    "- `gradio`: Creates web-based interfaces for machine learning models\n",
    "- `requests`: Handles HTTP requests\n",
    "- `PIL`: Python Imaging Library for image processing\n",
    "- `BytesIO`: Handles binary data streams\n",
    "- `logging`: Provides logging capabilities\n",
    "- `time`: Provides time-related functions\n",
    "- `re`: Regular expressions for text processing\n",
    "\n",
    "The logging configuration sets up error tracking and debugging information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# !pip install openai gradio Pillow python-dotenv requests\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration Settings\n",
    "\n",
    "This section defines our application's configuration using a dataclass.\n",
    "\n",
    "Code Breakdown:\n",
    "- `@dataclass`: A decorator that automatically adds generated special methods to the class\n",
    "- `Config` class contains:\n",
    "  - `IMAGE_SIZES`: List of available image dimensions\n",
    "  - `DEFAULT_SIZE`: The default image size if none specified\n",
    "  - `STYLE_PRESETS`: Dictionary mapping style names to prompt templates\n",
    "  - `CACHE_EXPIRY`: How long cached images remain valid (in seconds)\n",
    "  - `MAX_CACHE_SIZE`: Maximum number of images to keep in cache\n",
    "  - `load_env()`: Static method that loads the OpenAI API key from environment variables\n",
    "\n",
    "The style presets use Python's string formatting with {prompt} as a placeholder that gets replaced with the user's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration settings for the application\"\"\"\n",
    "    IMAGE_SIZES: List[str] = field(default_factory=lambda: [\"1024x1024\", \"512x512\"])\n",
    "    DEFAULT_SIZE: str = \"1024x1024\"\n",
    "    STYLE_PRESETS: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"Standard\": \"Create a high-quality image of {prompt}\",\n",
    "        \"Movie Poster\": \"Create a dramatic movie poster style image with {prompt}. Include cinematic lighting and theatrical elements\",\n",
    "        \"Netflix Banner\": \"Create a wide Netflix-style banner featuring {prompt}. Use dramatic lighting and Netflix's signature look\",\n",
    "        \"Abstract Art\": \"Generate an abstract artistic interpretation of {prompt} with bold colors and striking composition\",\n",
    "    })\n",
    "    CACHE_EXPIRY: int = 3600  # Cache expiry in seconds (1 hour)\n",
    "    MAX_CACHE_SIZE: int = 100  # Maximum number of items in cache\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_env():\n",
    "        \"\"\"Load and validate environment variables\"\"\"\n",
    "        load_dotenv(verbose=True)\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "        return api_key\n",
    "\n",
    "# Create Config instance\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Caching System\n",
    "\n",
    "This section implements a simple caching system to store and retrieve generated images.\n",
    "\n",
    "Code Breakdown:\n",
    "- `ImageCache` class contains:\n",
    "  - `__init__`: Initializes an empty dictionary to store cached images\n",
    "  - `get(key)`: \n",
    "    - Checks if an image exists in cache\n",
    "    - Verifies if it hasn't expired\n",
    "    - Returns the image or None\n",
    "  - `set(key, value)`:\n",
    "    - Stores an image with timestamp\n",
    "    - Removes oldest items if cache is full\n",
    "    - Uses dictionary with nested structure: {key: {'data': image, 'timestamp': time}}\n",
    "\n",
    "The cache helps reduce API calls and improves response time for repeated requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCache:\n",
    "    \"\"\"Simple caching system for generated images\"\"\"\n",
    "    def __init__(self):\n",
    "        self._cache: Dict[str, Dict[str, Any]] = {}\n",
    "        \n",
    "    def get(self, key: str) -> Optional[Image.Image]:\n",
    "        \"\"\"Retrieve an image from cache if it exists and hasn't expired\"\"\"\n",
    "        if key in self._cache:\n",
    "            item = self._cache[key]\n",
    "            if time.time() - item['timestamp'] < Config.CACHE_EXPIRY:\n",
    "                return item['data']\n",
    "            else:\n",
    "                del self._cache[key]\n",
    "        return None\n",
    "        \n",
    "    def set(self, key: str, value: Image.Image):\n",
    "        \"\"\"Store an image in the cache\"\"\"\n",
    "        self._cache[key] = {\n",
    "            'data': value,\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        \n",
    "        # Remove oldest items if cache is too large\n",
    "        if len(self._cache) > Config.MAX_CACHE_SIZE:\n",
    "            oldest_key = min(self._cache.keys(), \n",
    "                           key=lambda k: self._cache[k]['timestamp'])\n",
    "            del self._cache[oldest_key]\n",
    "\n",
    "# Initialize cache\n",
    "image_cache = ImageCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Processing Utilities\n",
    "\n",
    "This section handles image processing tasks through the ImageProcessor class.\n",
    "\n",
    "Code Breakdown:\n",
    "- `ImageProcessor` class contains two static methods:\n",
    "  - `process_image(image_url)`:\n",
    "    - Downloads image from URL using requests\n",
    "    - Converts to PIL Image object\n",
    "    - Optimizes image format\n",
    "    - Handles errors with logging\n",
    "  - `create_error_image(message)`:\n",
    "    - Creates a new blank image\n",
    "    - Adds error message text\n",
    "    - Used when image generation fails\n",
    "\n",
    "Static methods are used because no instance state is needed for these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    \"\"\"Handles image processing operations\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_image(image_url: str) -> Optional[Image.Image]:\n",
    "        \"\"\"Download and process an image from a URL\"\"\"\n",
    "        try:\n",
    "            response = requests.get(image_url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Create PIL Image from response content\n",
    "            img = Image.open(BytesIO(response.content))\n",
    "            \n",
    "            # Optimize image\n",
    "            if img.mode in ('RGBA', 'P'):\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing image: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_error_image(message: str) -> Image.Image:\n",
    "        \"\"\"Create a professional-looking error image\"\"\"\n",
    "        img = Image.new('RGB', (512, 512), color=(240, 240, 240))\n",
    "        from PIL import ImageDraw\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((20, 20), f\"Error:\\n{message}\", fill=(33, 33, 33))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Utility Functions\n",
    "\n",
    "This section contains helper functions for input processing and validation.\n",
    "\n",
    "Code Breakdown:\n",
    "- `sanitize_prompt(prompt)`:\n",
    "  - Removes extra whitespace using split() and join()\n",
    "  - Removes special characters with regex\n",
    "  - Validates non-empty result\n",
    "- `apply_style_template(style, prompt)`:\n",
    "  - Looks up style template from Config\n",
    "  - Formats prompt into template\n",
    "  - Falls back to original prompt if style not found\n",
    "- `validate_size(size)`:\n",
    "  - Checks if size is in allowed list\n",
    "  - Returns default size if invalid\n",
    "\n",
    "These functions ensure clean, safe input before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_prompt(prompt: str) -> str:\n",
    "    \"\"\"Clean and validate the input prompt\"\"\"\n",
    "    # Remove extra whitespace\n",
    "    cleaned = ' '.join(prompt.split())\n",
    "    \n",
    "    # Remove any potentially harmful characters\n",
    "    cleaned = re.sub(r'[^\\w\\s,.!?-]', '', cleaned)\n",
    "    \n",
    "    if not cleaned:\n",
    "        raise ValueError(\"Prompt cannot be empty after sanitization\")\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def apply_style_template(style: str, prompt: str) -> str:\n",
    "    \"\"\"Apply a style template to the prompt\"\"\"\n",
    "    template = config.STYLE_PRESETS.get(style)  # Use instance attribute\n",
    "    if not template:\n",
    "        return prompt\n",
    "    return template.format(prompt=prompt)\n",
    "\n",
    "def validate_size(size: str) -> str:\n",
    "    \"\"\"Validate the requested image size\"\"\"\n",
    "    if size in config.IMAGE_SIZES:  # Use instance attribute\n",
    "        return size\n",
    "    return config.DEFAULT_SIZE  # Use instance attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Main Image Generation Function\n",
    "\n",
    "This is the core function that coordinates the entire image generation process.\n",
    "\n",
    "Code Breakdown:\n",
    "- Function accepts three parameters:\n",
    "  - prompt: User's text description\n",
    "  - size: Desired image size\n",
    "  - style: Selected style preset\n",
    "- Process flow:\n",
    "  1. Validates and sanitizes inputs\n",
    "  2. Checks cache for existing image\n",
    "  3. Initializes OpenAI client\n",
    "  4. Calls DALL-E API to generate image\n",
    "  5. Processes and caches the result\n",
    "- Error handling:\n",
    "  - Catches all exceptions\n",
    "  - Creates error image if something fails\n",
    "  - Returns tuple of (image, status message)\n",
    "\n",
    "The function uses type hints and returns a tuple containing the image and a status message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(\n",
    "    prompt: str,\n",
    "    size: str = config.DEFAULT_SIZE,  # Use instance attribute here\n",
    "    style: str = \"Standard\"\n",
    ") -> Tuple[Optional[Image.Image], str]:\n",
    "    \"\"\"Generate an image based on the prompt with specified size and style\"\"\"\n",
    "    try:\n",
    "        # Validate and sanitize inputs\n",
    "        cleaned_prompt = sanitize_prompt(prompt)\n",
    "        validated_size = validate_size(size)\n",
    "        styled_prompt = apply_style_template(style, cleaned_prompt)\n",
    "        \n",
    "        # Check cache\n",
    "        cache_key = f\"{styled_prompt}_{validated_size}\"\n",
    "        cached_image = image_cache.get(cache_key)\n",
    "        if cached_image:\n",
    "            return cached_image, \"Retrieved from cache\"\n",
    "        \n",
    "        # Initialize OpenAI client\n",
    "        client = OpenAI(api_key=Config.load_env())\n",
    "        \n",
    "        # Generate image\n",
    "        response = client.images.generate(\n",
    "            model='dall-e-3',\n",
    "            prompt=styled_prompt,\n",
    "            size=validated_size,\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        \n",
    "        # Process the image\n",
    "        image_url = response.data[0].url\n",
    "        processed_image = ImageProcessor.process_image(image_url)\n",
    "        \n",
    "        if not processed_image:\n",
    "            raise Exception(\"Failed to process generated image\")\n",
    "        \n",
    "        # Cache the result\n",
    "        image_cache.set(cache_key, processed_image)\n",
    "        \n",
    "        return processed_image, \"Successfully generated new image\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error generating image: {str(e)}\")\n",
    "        error_image = ImageProcessor.create_error_image(str(e))\n",
    "        return error_image, f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradio Interface Setup\n",
    "\n",
    "This section creates the web-based user interface using Gradio.\n",
    "\n",
    "Code Breakdown:\n",
    "- Creates Gradio Interface with:\n",
    "  - Input components:\n",
    "    - Textbox: Multi-line input for prompt\n",
    "    - Dropdown: Image size selection\n",
    "    - Dropdown: Style preset selection\n",
    "  - Output components:\n",
    "    - Image: Displays generated image\n",
    "    - Markdown: Shows status message\n",
    "  - Additional features:\n",
    "    - Title and description\n",
    "    - Example inputs for demonstration\n",
    "- The launch() method starts the web server\n",
    "\n",
    "Gradio automatically creates a user-friendly interface from these specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 11:17:27,762 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-12-28 11:17:27,771 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 11:17:27,886 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2024-12-28 11:18:29,884 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 400 Bad Request\"\n",
      "2024-12-28 11:18:29,889 - __main__ - ERROR - Error generating image: Error code: 400 - {'error': {'code': 'content_policy_violation', 'message': 'Your request was rejected as a result of our safety system. Your prompt may contain text that is not allowed by our safety system.', 'param': None, 'type': 'invalid_request_error'}}\n",
      "2024-12-28 11:18:59,443 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n",
      "2024-12-28 11:19:43,695 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/images/generations \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "interface = gr.Interface(\n",
    "    fn=generate_image,\n",
    "    inputs=[\n",
    "        gr.Textbox(\n",
    "            label=\"Prompt\",\n",
    "            placeholder=\"Describe your desired Netflix campaign image...\",\n",
    "            lines=3\n",
    "        ),\n",
    "        gr.Dropdown(\n",
    "            choices=config.IMAGE_SIZES,  # Use instance attribute\n",
    "            label=\"Image Size\",\n",
    "            value=config.DEFAULT_SIZE    # Use instance attribute\n",
    "        ),\n",
    "        gr.Dropdown(\n",
    "            choices=list(config.STYLE_PRESETS.keys()),  # Use instance attribute\n",
    "            label=\"Style Preset\",\n",
    "            value=\"Standard\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Image(label=\"Generated Image\"),\n",
    "        gr.Markdown(label=\"Generation Details\")\n",
    "    ],\n",
    "    title=\"Netflix Campaign Design Generator\",\n",
    "    description=(\n",
    "        \"Create professional campaign designs for Netflix content using AI. \"\n",
    "        \"Choose from different styles and customize your generation.\"\n",
    "    ),\n",
    "    examples=[\n",
    "        [\"A dramatic scene from a sci-fi series with dark atmosphere\", \"1024x1024\", \"Netflix Banner\"],\n",
    "        [\"A mysterious detective standing in rain at night\", \"1024x1024\", \"Movie Poster\"],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1720693600_20241227_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
