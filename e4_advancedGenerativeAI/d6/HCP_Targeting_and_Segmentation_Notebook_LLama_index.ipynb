{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9qbC4qJc-0au",
   "metadata": {
    "id": "9qbC4qJc-0au"
   },
   "source": [
    "# HCP Targeting and Segmentation Using Llama Index Framework\n",
    "\n",
    "## Problem Statement\n",
    "Healthcare organizations face challenges in analyzing large datasets from diverse sources, such as:\n",
    "- HCP records\n",
    "- Patient notes\n",
    "- Prescription trends\n",
    "- Engagement metrics\n",
    "\n",
    "The goal is to process complex data and provide actionable insights using the **Llama Index Framework**, incorporating the following components:\n",
    "1. Data Loaders\n",
    "2. Chunking/Tokenization\n",
    "3. Node Parser\n",
    "4. Embeddings\n",
    "5. Indexing & Retrieval\n",
    "6. Vector Databases\n",
    "7. LLMs for insights\n",
    "8. Response synthesis & Query Engine\n",
    "\n",
    "---\n",
    "\n",
    "# Dataset Overview\n",
    "\n",
    "The **HCP Targeting and Segmentation** dataset contains structured information about healthcare professionals (HCPs).\n",
    "It includes fields such as `HCP_ID`, `Specialty`, `Region`, and engagement-related metrics.\n",
    "\n",
    "## Key Features\n",
    "1. **HCP_ID**: A unique identifier for each healthcare professional.\n",
    "2. **Name**: The name of the HCP.\n",
    "3. **Specialty**: The medical specialty of the HCP (e.g., Pediatrics, Cardiology).\n",
    "4. **Region**: The geographic region where the HCP practices (e.g., North, East).\n",
    "5. **Prescribing_Trend**: Indicates the prescribing behavior of the HCP (e.g., Low, Medium, High).\n",
    "6. **Research_Involvement**: Specifies whether the HCP is involved in research activities (Yes/No).\n",
    "7. **Engagement_Score**: A qualitative measure of the HCP's engagement level (e.g., Low, Medium, High).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58KxQmzxvbwR",
   "metadata": {
    "id": "58KxQmzxvbwR"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from llama_index.core import Document, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter, SentenceWindowNodeParser\n",
    "import pandas as pd\n",
    "\n",
    "# Configure OpenAI API\n",
    "# openai.api_key = \"\"  # Replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1uHDnXykpRP",
   "metadata": {
    "id": "e1uHDnXykpRP"
   },
   "source": [
    "# Step 1: Load the CSV file into a DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "UtA8bljiknow",
   "metadata": {
    "id": "UtA8bljiknow"
   },
   "outputs": [],
   "source": [
    "file_path = \"data/HCP_Targeting_and_Segmentation.csv\"\n",
    "hcp_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eJgXRHSIku4y",
   "metadata": {
    "id": "eJgXRHSIku4y"
   },
   "source": [
    "# Step 2: Convert each row into a Document object (node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hqmyOCqteCto",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqmyOCqteCto",
    "outputId": "9e41082d-2d17-40a4-9c14-968d7c8beca1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows converted to documents: 50000\n",
      "Document 1:\n",
      "HCP_ID: HCP00001, Name: HCP_Name_1, Specialty: Pediatrics, Region: North, Prescribing_Trend: Low, Research_Involvement: Yes, Engagement_Score: Medium\n",
      "Metadata: {'row_index': 0}\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "HCP_ID: HCP00002, Name: HCP_Name_2, Specialty: Pediatrics, Region: North, Prescribing_Trend: Low, Research_Involvement: Yes, Engagement_Score: Low\n",
      "Metadata: {'row_index': 1}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        text=f\"HCP_ID: {row['HCP_ID']}, Name: {row['Name']}, Specialty: {row['Specialty']}, \"\n",
    "             f\"Region: {row['Region']}, Prescribing_Trend: {row['Prescribing_Trend']}, \"\n",
    "             f\"Research_Involvement: {row['Research_Involvement']}, Engagement_Score: {row['Engagement_Score']}\",\n",
    "        metadata={\"row_index\": idx}  # Add metadata for reference (optional)\n",
    "    )\n",
    "    for idx, row in hcp_data.iterrows()\n",
    "]\n",
    "\n",
    "# Step 3: Print the total number of documents created\n",
    "print(f\"Total rows converted to documents: {len(documents)}\")\n",
    "\n",
    "# Inspect the first few documents\n",
    "for i, doc in enumerate(documents[:2]):\n",
    "    print(f\"Document {i + 1}:\")\n",
    "    print(doc.text)\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VsXOIWzfki1B",
   "metadata": {
    "id": "VsXOIWzfki1B"
   },
   "source": [
    "# Step 3: Chunking and Tokenizing using TokenTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qtbVzcPigu3s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qtbVzcPigu3s",
    "outputId": "0caa8616-1c0c-4b20-d9e0-082db7d22bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created after chunking: 50000\n"
     ]
    }
   ],
   "source": [
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=512,        # Max tokens per chunk\n",
    "    chunk_overlap=50,      # Overlap between chunks\n",
    "    separator=\" \"          # Separator for splitting\n",
    ")\n",
    "\n",
    "chunks = splitter.get_nodes_from_documents(documents)\n",
    "print(f\"Total chunks created after chunking: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I8nh2NDikgMr",
   "metadata": {
    "id": "I8nh2NDikgMr"
   },
   "source": [
    "# Step 4: Node Parsing using SentenceWindowNodeParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "UqMlR-SnehC2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqMlR-SnehC2",
    "outputId": "771efdaf-0470-40ee-b3a8-983bd1268241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total nodes created after parsing: 50000\n"
     ]
    }
   ],
   "source": [
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,  # Number of surrounding sentences to include in context\n",
    "    window_metadata_key=\"window\",  # Metadata key for context\n",
    "    original_text_metadata_key=\"original_sentence\"  # Metadata key for the original sentence\n",
    ")\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(chunks)\n",
    "print(f\"Total nodes created after parsing: {len(nodes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YnfxkH15v3R8",
   "metadata": {
    "id": "YnfxkH15v3R8"
   },
   "source": [
    "## Step 4: Generate Vector Embeddings and Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fKi5Ss3Zv13G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKi5Ss3Zv13G",
    "outputId": "587d2538-ddc3-4721-da3f-65066fb3d8ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created with 50000 nodes.\n"
     ]
    }
   ],
   "source": [
    "parsed_documents = [\n",
    "    Document(\n",
    "        text=node.text,\n",
    "        metadata=node.metadata  # Include metadata like doc_id, row_index, etc.\n",
    "    )\n",
    "    for node in nodes\n",
    "]\n",
    "index = VectorStoreIndex.from_documents(parsed_documents)\n",
    "print(f\"Index created with {len(nodes)} nodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "Bc6R3ppPXmV9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc6R3ppPXmV9",
    "outputId": "70d3cab1-06a4-4666-88eb-bfd923193f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents indexed: 50000\n"
     ]
    }
   ],
   "source": [
    "def get_total_index_count(index):\n",
    "    \"\"\"Returns the total number of documents in the VectorStoreIndex.\"\"\"\n",
    "    try:\n",
    "        # Access the document store\n",
    "        docstore = index.storage_context.docstore\n",
    "\n",
    "        # Count the number of documents\n",
    "        total_count = len(docstore.docs)\n",
    "        print(f\"Total number of documents indexed: {total_count}\")\n",
    "        return total_count\n",
    "    except AttributeError as e:\n",
    "        print(\"Unable to fetch the total count. Ensure the index is correctly initialized.\")\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Example usage\n",
    "total_indexes = get_total_index_count(index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ajr-suyvySA",
   "metadata": {
    "id": "8ajr-suyvySA"
   },
   "source": [
    "## Step 5: Query Index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "Sjrpr8ezvwkD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sjrpr8ezvwkD",
    "outputId": "f0b55dee-c2e1-4165-95c1-9bd2c31a6d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Response:\n",
      "The key prescription trends for the healthcare providers (HCPs) mentioned in the context are high prescribing trend for the HCP specializing in Oncology and medium prescribing trend for the HCP specializing in Cardiology.\n"
     ]
    }
   ],
   "source": [
    "# Query the index\n",
    "def query_index(index, query):\n",
    "\n",
    "    query_engine = index.as_query_engine()\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return response\n",
    "\n",
    "query_text = \"What are the key prescription trends for HCPs?\"\n",
    "response = query_index(index, query_text)\n",
    "print(\"Query Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IcdyH74Kvt4l",
   "metadata": {
    "id": "IcdyH74Kvt4l"
   },
   "source": [
    "## Step 6: Dynamically Update Index with New Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ESfDL0vQvrjg",
   "metadata": {
    "id": "ESfDL0vQvrjg"
   },
   "outputs": [],
   "source": [
    "def dynamic_update_index(data_dir=\"data\"):\n",
    "    \"\"\"Reloads documents from the specified directory and updates the index.\"\"\"\n",
    "    print(\"Updating index with new data...\")\n",
    "    documents = SimpleDirectoryReader(data_dir).load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    print(\"Index updated successfully.\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "T8rIsymYvo0D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T8rIsymYvo0D",
    "outputId": "cdb622b9-692f-4b73-c068-95351bee3b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating index with new data...\n",
      "Index updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add new data\n",
    "new_data = pd.DataFrame({\n",
    "    \"HCP_ID\": [101, 102, 103],\n",
    "    \"Specialty\": [\"Pediatrics\", \"Cardiology\", \"Orthopedics\"],\n",
    "    \"Engagement_Score\": [85, 65, 45],\n",
    "    \"Notes\": [\n",
    "        \"Highly engaged with pediatric programs.\",\n",
    "        \"Needs follow-up for engagement.\",\n",
    "        \"Minimal interaction recorded.\"\n",
    "    ]\n",
    "})\n",
    "new_data_filepath = \"new_hcp_data.csv\"\n",
    "new_data.to_csv(new_data_filepath, index=False)\n",
    "\n",
    "# Update index\n",
    "updated_index = dynamic_update_index(data_dir=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7VaP_0H-vkXY",
   "metadata": {
    "id": "7VaP_0H-vkXY"
   },
   "source": [
    "## Step 7: Query Updated Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "G4jL6GiTviwS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4jL6GiTviwS",
    "outputId": "a2e96215-19e1-4041-fedf-34dd90cdc334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Query Response:\n",
      "HCP18075 and HCP36020 are the healthcare professionals with high engagement scores.\n"
     ]
    }
   ],
   "source": [
    "# Query the updated index\n",
    "updated_query_text = \"Who are the HCPs with high engagement scores?\"\n",
    "updated_response = query_index(index, updated_query_text)\n",
    "print(\"Updated Query Response:\")\n",
    "print(updated_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "I_Ys-qt7oJ2C",
   "metadata": {
    "id": "I_Ys-qt7oJ2C"
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "This end-to-end solution demonstrates how to efficiently process a structured dataset, such as a CSV file, using **Llama Index** for indexing and querying. The key steps include:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - The rows from the CSV file were converted into `Document` objects, preserving relevant metadata like `HCP_ID` and `row_index`.\n",
    "\n",
    "2. **Chunking and Tokenization**:\n",
    "   - Large text content was split into smaller, manageable chunks using `TokenTextSplitter`, ensuring consistent size and overlap for optimal retrieval.\n",
    "\n",
    "3. **Node Parsing**:\n",
    "   - Sentence-level parsing was applied using `SentenceWindowNodeParser` to create granular nodes while retaining context through metadata.\n",
    "\n",
    "4. **Compatibility with VectorStoreIndex**:\n",
    "   - The parsed nodes were transformed back into `Document` objects, making them compatible with the `VectorStoreIndex` for seamless indexing.\n",
    "\n",
    "5. **Efficient Querying**:\n",
    "   - The processed and indexed dataset allowed for precise queries, such as identifying HCPs based on their specialties and engagement scores.\n",
    "\n",
    "## Benefits\n",
    "- **Scalability**: The pipeline supports large datasets with fine-grained chunking and parsing.\n",
    "- **Flexibility**: Metadata allows for advanced filtering and contextual retrieval.\n",
    "- **Actionable Insights**: The indexed dataset enables natural language queries, transforming raw data into meaningful insights.\n",
    "\n",
    "## Key Takeaways\n",
    "This workflow combines the power of Llama Index's **tokenization**, **parsing**, and **indexing** capabilities to handle structured datasets efficiently. By ensuring compatibility and leveraging metadata, this approach provides a robust foundation for advanced querying and decision-making.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
