data:
  train_dir: "structures_dataset"
  test_dir: "dataset_test"
  batch_size: 32
  target_size: [128, 128]
  preprocessing_function: "resnet_preprocess"

augmentation:
  rotation_range: 0
  # width_shift_range: 0.1
  # height_shift_range: 0.1
  # horizontal_flip: true
  # vertical_flip: false
  # zoom_range: 0.1
  # brightness_range: 0.1
  # contrast_range: 0.1
  # saturation_range: 0.1
  # hue_range: 0.05
  # gaussian_blur: 0.5
  # shear_range: 0.2
  # cutout_size: [10, 10]

model:
  architecture: "ResNet50V2"
  input_shape: [128, 128, 3]
  initial_learning_rate: 0.001
  decay_steps: 100
  decay_rate: 0.96
  dense_units: 512
  dropout_rate: 0.5
  additional_metrics: ["Precision", "Recall", "AUC"]

training:
  epochs: 25
  patience: 5
  target_accuracy: 0.95
  find_lr: false
  pretrain_model_eval: true
  model_checkpoint_path: "checkpoint.h5.keras"

lr_finder:
  start_lr: 1e-7
  end_lr: 1
  epochs: 5
  stop_factor: 4
  beta: 0.98

visualization:
  figure_size: [12, 4]
  history_plot_path: "history_plot.png"

gpu:
# ARCHITECTURES = {
#   'ResNet50V2': ResNet50V2,
#   'VGG16': VGG16,
#   'InceptionV3': InceptionV3,
#   'MobileNetV2': MobileNetV2,
#   'EfficientNetB0': EfficientNetB0
# }
#
# ARCHITECTURE_INPUT_SHAPES = {
#   'ResNet50V2': (128, 128, 3),
#   'VGG16': (224, 224, 3),
#   'InceptionV3': (299, 299, 3),
#   'MobileNetV2': (224, 224, 3),
#   'EfficientNetB0': (224, 224, 3)
# }
#
# PREPROCESSING_FUNCTIONS = {
#   'ResNet50V2': resnet_preprocess,
#   'VGG16': vgg_preprocess,
#   'InceptionV3': inception_preprocess,
#   'MobileNetV2': mobilenet_preprocess,
#   'EfficientNetB0': efficientnet_preprocess
# }
