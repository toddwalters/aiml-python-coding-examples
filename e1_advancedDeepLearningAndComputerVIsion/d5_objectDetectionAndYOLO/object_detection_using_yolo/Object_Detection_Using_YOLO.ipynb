{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HqVBsx9f6Oz"
   },
   "source": [
    "# Object Detection Using YOLO\n",
    "- Environment Used: TensorFlow 2.6 Python 3.8 CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4yn1Hna-NTX"
   },
   "source": [
    "## Problem Statement:\n",
    "You have been provided with a trained model of YOLOv3 on the MS COCO dataset. Your task is to create an object detection program using this model for the various objects in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8AtTscM-NTY"
   },
   "source": [
    "## Step 1: Importing the Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkq5F_bO-NTa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61FW3RGq-NTg"
   },
   "source": [
    "## Step 2: Creating Bounding Boxes\n",
    "- Define the bounding box's coordinates (**xmin**, **ymin**, **xmax**, **ymax**)\n",
    "- Set optional parameters like objness (Objectiveness score) and classes (List or array of class probabilities)\n",
    "- Initialize label and score attributes to **-1**, indicating their uninitialized state\n",
    "- Calculate the label by finding the index with the maximum class probability if not previously computed\n",
    "- Return the identified label\n",
    "- Determine the score using the probability of the detected label if not previously determined\n",
    "- Return the computed score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VF_N51US-NTh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY8evVgGhNzW"
   },
   "source": [
    "## Step 3: Performing Bounding Box Decoding for YOLO Object Detection\n",
    "\n",
    "- Define a function to apply sigmoid activation function to a given value\n",
    "\n",
    "- Define a function to decode the network output and generate bounding boxes\n",
    "- Get the dimensions of the network output\n",
    "- Reshape the network output\n",
    "- Apply sigmoid activation to the relevant elements in the network output\n",
    "- Iterate over each grid cell and anchor box\n",
    "- Check the objectness score of the bounding box\n",
    "- Skip if objectness score is below the threshold\n",
    "- Retrieve the x, y, w, h values of the bounding box\n",
    "- Calculate the center position and unit in terms of image width and height\n",
    "- Calculate the width and height of the bounding box in terms of image width and height\n",
    "- Retrieve the class probabilities\n",
    "- Create a bounding box object with the calculated values\n",
    "- Append the bounding box to the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqCroPiA-NTm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ccy6u4H0-NTq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voUrZp95-NTv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JS-9LCNe-NT0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjXBwo8--NT5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSUQrwX4-NT9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJckR0gA-NUB"
   },
   "source": [
    "## Step 4: Loading and Preparing an Image\n",
    "- Use the **load_img** function to read the image specified by the filename\n",
    "- Extract the original width and height of the image\n",
    "- Use the **img_to_array** function to transform the image into a numpy array\n",
    "- Convert the image data type to float32\n",
    "- Scale the pixel values to the range [0, 1] by dividing them by 255\n",
    "- The function should return the processed image ready for model input, as well as the original width and height of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2NlNPrq0-NUC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image_pixels(filename, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(filename)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(filename, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd4F3r1Y-NUG"
   },
   "source": [
    "## Step 5: Applying Threshold to Obtain Previous Results\n",
    "\n",
    "- Define a function to filter and retrieve boxes, labels, and scores based on a threshold\n",
    "- Enumerate all boxes\n",
    "- Enumerate all possible labels\n",
    "- Check if the threshold for the label is high enough\n",
    "- Append the box, label, and score to the respective lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ikt3yn1M-NUH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QO6iQj8-NUM"
   },
   "source": [
    "## Step 6: Visualizing All Results\n",
    "- Load and plot the image\n",
    "- Get the context for drawing boxes\n",
    "- Plot each box\n",
    "- Get coordinates and calculate width and height of the box\n",
    "- Create the shape\n",
    "- Draw the box\n",
    "- Draw text and score in the top-left corner\n",
    "- Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGXqfYbo-NUO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
    "    data = pyplot.imread(filename)\n",
    "    # plot the image\n",
    "    pyplot.imshow(data)\n",
    "    # get the context for drawing boxes\n",
    "    ax = pyplot.gca()\n",
    "    # plot each box\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        # create the shape\n",
    "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "        # draw the box\n",
    "        ax.add_patch(rect)\n",
    "        # draw text and score in top left corner\n",
    "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "        pyplot.text(x1, y1, label, color='white')\n",
    "    # show the plot\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thrI5nYq-NUT"
   },
   "source": [
    "## Step 7: Loading the Pretrained YOLO v3 Model\n",
    "- Utilize the **load_model** function from the Keras library\n",
    "- Load the saved YOLOv3 model from the file **yolov3.h5** into a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBxfsMf_-NUT",
    "outputId": "23b27a8c-7e30-4674-9722-96c7d9fcff82",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('yolov3.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDCJF8Dl-NUZ"
   },
   "source": [
    "## Step 8: Defining the Expected Input Shape for the Model\n",
    "\n",
    "- Define the expected input width (input_w) and height (input_h) for the model. For YOLOv3, it is often set to 416x416.\n",
    "- Specify the path and filename of the image you want to process\n",
    "- Use the load_image_pixels function (defined earlier) to resize and normalize the image\n",
    "- Utilize the predict method of the loaded YOLOv3 model to make predictions on the processed image. This returns a list of arrays corresponding to the detection outputs.\n",
    "- Print the shapes of the returned arrays using a list comprehension\n",
    "- This will give an insight into how many detections were made, the number of bounding boxes, class probabilities, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52r4KX0H-NUa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_w, input_h = 416, 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "itk_Ae9Q-NUe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "photo_filename = 'zebra.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3LKvQ-S-NUi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECLfgxZ3-NUp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat = model.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ9cIMN2-NUv",
    "outputId": "6b042c7e-c57d-4be3-c4ee-f4becbb8562e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print([a.shape for a in yhat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXTfca7O-NUz"
   },
   "source": [
    "## Step 9: Defining the Anchors\n",
    "- The anchors is a list containing three sublists, corresponding to the different scales at which detections are made in the YOLOv3 model.\n",
    "- Each sub-list contains pairs of width and height values for the anchor boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I16msXyD-NU0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8C3zkiu-NU4"
   },
   "source": [
    "## Step 10: Defining Probability Threshold for Detected Objects\n",
    "- Set a class detection threshold at 0.6\n",
    "- Initialize an empty list for storing bounding boxes\n",
    "- Iterate over network outputs, decode bounding boxes using anchors, and append to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bX9XHDq_-NU5"
   },
   "outputs": [],
   "source": [
    "class_threshold = 0.6\n",
    "boxes = list()\n",
    "for i in range(len(yhat)):\n",
    "    # decode the output of the network\n",
    "    boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zE9saNjN-NU9"
   },
   "source": [
    "## Step 11: Adjusting Bounding Box Dimensions\n",
    "- Invoke the __correct_yolo_boxes__ function\n",
    "- Pass the bounding boxes, original image dimensions, and expected input dimensions\n",
    "- Adjust the bounding box coordinates to align with the original image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e17LvsbP-NU9"
   },
   "outputs": [],
   "source": [
    "correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4l3vc8--NVB"
   },
   "source": [
    "## Step 12: Eliminating Redundant Bounding Boxes\n",
    "- Invoke the do_nms function\n",
    "- Provide the list of bounding boxes and a threshold of 0.5\n",
    "- Filter out boxes based on Non-Maximum Suppression to retain the most relevant predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmzVu1ZU-NVC"
   },
   "outputs": [],
   "source": [
    "do_nms(boxes, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gnon-aJ-NVH"
   },
   "source": [
    "## Step 13:  Establishing Object Labels for Prediction Results\n",
    "- List all potential object names that the YOLO model can identify\n",
    "- Assign this list to the variable named **labels**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_471F_4y-NVO"
   },
   "outputs": [],
   "source": [
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\",\n",
    "    \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\",\n",
    "    \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\",\n",
    "    \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\",\n",
    "    \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\",\n",
    "    \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n",
    "    \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\",\n",
    "    \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\",\n",
    "    \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rs6Myz3R-NVW"
   },
   "source": [
    "## Step 14: Obtaining Details of Detected Objects\n",
    "- Invoke the get_boxes function to filter and retrieve boxes, associated labels, and confidence scores based on the defined threshold\n",
    "- Store these details in v_boxes, v_labels, and v_scores for visualization and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48L_d1G2-NVW"
   },
   "outputs": [],
   "source": [
    "v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SexThfIA-NVa"
   },
   "source": [
    "## Step 15: Displaying Detected Objects and Confidence Scores\n",
    "- Iterate over the list of detected objects\n",
    "- Print the label and confidence score of each recognized object to summarize the findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2E4zXphm-NVa",
    "outputId": "419df389-e4db-487e-ce0f-2071dd364b5b"
   },
   "outputs": [],
   "source": [
    "for i in range(len(v_boxes)):\n",
    "    print(v_labels[i], v_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "id": "Jud71Ee1-NVe",
    "outputId": "d538d7a5-8620-4ec7-b7ca-01cdf6b7ffb8"
   },
   "outputs": [],
   "source": [
    "draw_boxes(photo_filename, v_boxes, v_labels, v_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWE1H9TZmgvz"
   },
   "source": [
    "**Observation**\n",
    "- The code detects objects in the image, assigns them a confidence score, and labels them with the appropriate name."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "colab": {
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
