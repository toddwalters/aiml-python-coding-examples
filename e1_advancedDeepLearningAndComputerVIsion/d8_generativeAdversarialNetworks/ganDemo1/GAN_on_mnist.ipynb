{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbvWJqWSBMTL"
   },
   "source": [
    "# Generative Adversarial Network for an MNIST Handwritten Digits From Scratch in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXmHPeNpBMTN",
    "outputId": "b0b966c8-d38b-464d-d761-4f86df49e280"
   },
   "outputs": [],
   "source": [
    "# loading the mnist dataset\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "\n",
    "# load the images into memory\n",
    "(trainX, trainy), (testX, testy) = load_data()\n",
    "\n",
    "# summarize the shape of the dataset\n",
    "print('Train', trainX.shape, trainy.shape)\n",
    "print('Test', testX.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "Th3GE8Y3BMTP",
    "outputId": "876b02c4-d88d-49fa-e655-e778bdcc675b"
   },
   "outputs": [],
   "source": [
    "#plot of 25 images from the MNIST training dataset, arranged in a 5×5 square.\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from matplotlib import pyplot\n",
    "# load the images into memory\n",
    "(trainX, trainy), (testX, testy) = load_data()\n",
    "# plot images from the training dataset\n",
    "for i in range(25):\n",
    "\t# define subplot\n",
    "\tpyplot.subplot(5, 5, 1 + i)\n",
    "\t# turn off axis\n",
    "\tpyplot.axis('off')\n",
    "\t# plot raw pixel data\n",
    "\tpyplot.imshow(trainX[i], cmap='gray_r')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRwgZN7FBMTQ"
   },
   "source": [
    "\n",
    "##  MNIST dataset to train the generator and the discriminator. The generator will generate Unique handwritten digits resembling the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSnjBR7HBMTQ"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-_qzFvrmBMTR"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7akN56ECBMTR"
   },
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n",
    "# The reason for subtracting 127.5 is to center the pixel values around 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hEbJxq0fBMTS"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLsXKonDBMTS"
   },
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT-pSCGeBMTT"
   },
   "source": [
    "# The Generator\n",
    "\n",
    "The generator uses <b>tf.keras.layers.Conv2DTranspose (upsampling) layers </b> to produce an image from a random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKn989-mBMTT"
   },
   "outputs": [],
   "source": [
    "# input 7*7*256 (low resolution version of the output image)\n",
    "# outputs a single 28×28 grayscale image\n",
    "# this generator takes a vector of size 100 and first reshape that into (7, 7, 128) vector then applied transpose\n",
    "# convolution in combination with batch normalization.\n",
    "\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) #Bias terms can introduce additional computations during training and inference\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "\n",
    "#The code snippet assert model.output_shape == (None, 7, 7, 256) is used to check\n",
    "# if the output shape of the neural network model matches the expected shape.\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "   # upsample to 14x14\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    # upsample to 28x28\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK6mnpVBBMTU"
   },
   "source": [
    "# Use the (as yet untrained) generator to create an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "aUbb5GWDBMTU",
    "outputId": "7fdd0764-3f2a-4a2b-8f44-219db0a378c4"
   },
   "outputs": [],
   "source": [
    "# sample image generated by the the generator\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100]) #latent space\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray') #This extracts the first image from a batch of generated images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r5kGbcbHBMTU"
   },
   "source": [
    "# The Discriminator\n",
    "### The discriminator is a CNN-based image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TnjMQ2zOBMTV"
   },
   "outputs": [],
   "source": [
    "# Input to discriminator = 28*28*1   grayscale image\n",
    "# Output  binary prediction (image is real (class=1) or fake (class=0))\n",
    "# no pooling layers\n",
    "# single node in the output layer with the sigmoid activation function to predict whether the input sample is real or fake.\n",
    "# Downsampling from 28×28 to 14×14, then to 7×7, before the model makes an output prediction\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[28, 28, 1])) #2×2 stride to downsample\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')) #downsampling  2×2 stride to downsample\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())  # classifier real (class=1) or fake (class=0))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUvw2_WYBMTV"
   },
   "source": [
    "###  Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfIff9OPBMTV",
    "outputId": "1ffae6e1-115f-40a2-c0c2-6f4c769824c5"
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbLi72WnBMTV"
   },
   "source": [
    "# Define the loss and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ea4emtIoBMTW"
   },
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# from_logits=True: This argument indicates that the input to the loss function is a logits tensor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNswKd0jXgZu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "428YcQRDBMTW"
   },
   "source": [
    "# Discriminator loss\n",
    "\n",
    "#### This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTK8HEpqBMTW"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPRBpYtWBMTW"
   },
   "source": [
    "# Generator loss\n",
    "\n",
    "### The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, compare the discriminators decisions on the generated images to an array of 1s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fofqNDjxBMTW"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vjlOZ2bBMTW"
   },
   "source": [
    "### The discriminator and the generator optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0e4qITUBMTX"
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)  # 0.0001\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4) #0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McUo3jyHBMTX"
   },
   "source": [
    "# Save checkpoints\n",
    "This notebook also demonstrates how to save and restore models, which can be helpful in case a long running training task is interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L5vuSGWJBMTX"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hq_4gwjeBMTX"
   },
   "source": [
    "# Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQKTJgebBMTX"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGPwox22BMTX"
   },
   "source": [
    "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kJx88TBBMTY"
   },
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "# @tf.function is a decorator provided by TensorFlow that converts a Python function into a TensorFlow graph,\n",
    "# allowing it to be executed more efficiently using TensorFlow's runtime.\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    # calculates the gradients of the loss function with respect to the specified variables.\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvO9VWw8BMTY"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwWLioy_BMTY"
   },
   "source": [
    "# Generate and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8qQetSKBMTY"
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYeHspOxBMTZ"
   },
   "source": [
    "# Train the model\n",
    "Call the train() method defined above to train the generator and discriminator simultaneously. Note, training GANs can be tricky. It's important that the generator and discriminator do not overpower each other (e.g., that they train at a similar rate).\n",
    "\n",
    "At the beginning of the training, the generated images look like random noise. As training progresses, the generated digits will look increasingly real. After about 50 epochs, they resemble MNIST digits. This may take about one minute / epoch with the default settings on Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "CKs0KoKQBMTZ",
    "outputId": "1483e5e1-18d5-4cd6-a9b8-a9e17218e897"
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LL7Oow2BMTZ",
    "outputId": "9b915cf0-00f1-4687-8705-3c92579175aa"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpRYi1X5BMTZ"
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "X3i8vIVnBMTZ",
    "outputId": "4b59b117-e0f7-4ca2-d97c-57315c9b30a1"
   },
   "outputs": [],
   "source": [
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLwjcTFoBMTg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9n9fpxIBMTh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE6bG8BwBMTh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JcyXEQhBMTh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
